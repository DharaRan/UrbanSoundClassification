Running  1  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:18:40
forest model fit end:  2018-04-14 02:19:25
forest model predict start:  2018-04-14 02:19:25
forest model predict end:  2018-04-14 02:19:25
accuracy:  0.502702702703   465 / 925
Testing folds:  [ 3.]
Training folds:  [1, 2, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.19      0.08      0.11       100
          2       0.89      0.91      0.90        43
          3       0.31      0.57      0.40       100
          4       0.50      0.62      0.56       100
          5       0.86      0.50      0.63       100
          6       0.34      0.20      0.25       107
          7       0.91      0.86      0.89        36
          8       0.47      0.88      0.61       120
          9       0.71      0.42      0.53       119
         10       0.49      0.42      0.45       100

avg / total       0.52      0.50      0.49       925

============================================
Running  2  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:19:25
forest model fit end:  2018-04-14 02:20:10
forest model predict start:  2018-04-14 02:20:10
forest model predict end:  2018-04-14 02:20:11
accuracy:  0.52   481 / 925
Testing folds:  [ 3.]
Training folds:  [1, 2, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.38      0.20      0.26       100
          2       0.93      0.88      0.90        43
          3       0.29      0.56      0.38       100
          4       0.55      0.61      0.58       100
          5       0.81      0.48      0.60       100
          6       0.47      0.21      0.29       107
          7       0.94      0.86      0.90        36
          8       0.46      0.88      0.61       120
          9       0.73      0.48      0.58       119
         10       0.50      0.42      0.46       100

avg / total       0.56      0.52      0.51       925

============================================
Running  3  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:20:11
forest model fit end:  2018-04-14 02:20:56
forest model predict start:  2018-04-14 02:20:56
forest model predict end:  2018-04-14 02:20:56
accuracy:  0.509189189189   471 / 925
Testing folds:  [ 3.]
Training folds:  [1, 2, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.14      0.05      0.07       100
          2       0.89      0.91      0.90        43
          3       0.30      0.56      0.39       100
          4       0.53      0.63      0.57       100
          5       0.88      0.63      0.73       100
          6       0.38      0.23      0.29       107
          7       0.91      0.86      0.89        36
          8       0.46      0.87      0.60       120
          9       0.89      0.35      0.51       119
         10       0.45      0.43      0.44       100

avg / total       0.54      0.51      0.49       925

============================================
Running  4  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:20:56
forest model fit end:  2018-04-14 02:21:41
forest model predict start:  2018-04-14 02:21:41
forest model predict end:  2018-04-14 02:21:42
accuracy:  0.500540540541   463 / 925
Testing folds:  [ 3.]
Training folds:  [1, 2, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.15      0.07      0.10       100
          2       0.89      0.93      0.91        43
          3       0.31      0.56      0.40       100
          4       0.55      0.63      0.59       100
          5       0.83      0.52      0.64       100
          6       0.36      0.21      0.27       107
          7       0.91      0.86      0.89        36
          8       0.45      0.82      0.58       120
          9       0.71      0.43      0.53       119
         10       0.49      0.42      0.45       100

avg / total       0.52      0.50      0.49       925

============================================
Running  5  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:21:42
forest model fit end:  2018-04-14 02:22:27
forest model predict start:  2018-04-14 02:22:27
forest model predict end:  2018-04-14 02:22:27
accuracy:  0.498378378378   461 / 925
Testing folds:  [ 3.]
Training folds:  [1, 2, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.16      0.07      0.10       100
          2       0.89      0.93      0.91        43
          3       0.29      0.56      0.38       100
          4       0.53      0.59      0.56       100
          5       0.80      0.52      0.63       100
          6       0.32      0.19      0.24       107
          7       0.91      0.86      0.89        36
          8       0.47      0.87      0.61       120
          9       0.76      0.42      0.54       119
         10       0.49      0.42      0.45       100

avg / total       0.52      0.50      0.48       925

============================================
Running  6  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:22:28
forest model fit end:  2018-04-14 02:23:13
forest model predict start:  2018-04-14 02:23:13
forest model predict end:  2018-04-14 02:23:13
accuracy:  0.531891891892   492 / 925
Testing folds:  [ 3.]
Training folds:  [1, 2, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.30      0.14      0.19       100
          2       0.89      0.93      0.91        43
          3       0.31      0.55      0.40       100
          4       0.56      0.66      0.61       100
          5       0.84      0.61      0.71       100
          6       0.38      0.21      0.27       107
          7       0.91      0.86      0.89        36
          8       0.46      0.88      0.61       120
          9       0.88      0.47      0.61       119
         10       0.51      0.42      0.46       100

avg / total       0.57      0.53      0.52       925

============================================
Running  7  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:23:13
forest model fit end:  2018-04-14 02:23:58
forest model predict start:  2018-04-14 02:23:58
forest model predict end:  2018-04-14 02:23:59
accuracy:  0.523243243243   484 / 925
Testing folds:  [ 3.]
Training folds:  [1, 2, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.24      0.10      0.14       100
          2       0.89      0.95      0.92        43
          3       0.30      0.56      0.39       100
          4       0.53      0.64      0.58       100
          5       0.87      0.55      0.67       100
          6       0.40      0.21      0.27       107
          7       0.89      0.86      0.87        36
          8       0.47      0.88      0.61       120
          9       0.81      0.48      0.60       119
         10       0.52      0.43      0.47       100

avg / total       0.55      0.52      0.51       925

============================================
Running  8  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:23:59
forest model fit end:  2018-04-14 02:24:44
forest model predict start:  2018-04-14 02:24:44
forest model predict end:  2018-04-14 02:24:44
accuracy:  0.522162162162   483 / 925
Testing folds:  [ 3.]
Training folds:  [1, 2, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.39      0.21      0.27       100
          2       0.95      0.93      0.94        43
          3       0.31      0.55      0.40       100
          4       0.50      0.59      0.54       100
          5       0.84      0.56      0.67       100
          6       0.51      0.23      0.32       107
          7       0.94      0.86      0.90        36
          8       0.47      0.87      0.61       120
          9       0.77      0.41      0.54       119
         10       0.43      0.43      0.43       100

avg / total       0.57      0.52      0.51       925

============================================
Running  9  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:24:45
forest model fit end:  2018-04-14 02:25:30
forest model predict start:  2018-04-14 02:25:30
forest model predict end:  2018-04-14 02:25:30
accuracy:  0.507027027027   469 / 925
Testing folds:  [ 3.]
Training folds:  [1, 2, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.16      0.06      0.09       100
          2       0.93      0.91      0.92        43
          3       0.30      0.58      0.39       100
          4       0.54      0.59      0.56       100
          5       0.84      0.56      0.67       100
          6       0.40      0.21      0.27       107
          7       0.89      0.86      0.87        36
          8       0.47      0.88      0.61       120
          9       0.77      0.39      0.52       119
         10       0.45      0.45      0.45       100

avg / total       0.53      0.51      0.49       925

============================================
Running  10  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:25:30
forest model fit end:  2018-04-14 02:26:15
forest model predict start:  2018-04-14 02:26:15
forest model predict end:  2018-04-14 02:26:16
accuracy:  0.503783783784   466 / 925
Testing folds:  [ 3.]
Training folds:  [1, 2, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.21      0.07      0.10       100
          2       0.90      0.88      0.89        43
          3       0.31      0.57      0.40       100
          4       0.53      0.59      0.56       100
          5       0.87      0.54      0.67       100
          6       0.38      0.23      0.29       107
          7       0.89      0.86      0.87        36
          8       0.46      0.88      0.61       120
          9       0.69      0.38      0.49       119
         10       0.45      0.45      0.45       100

avg / total       0.53      0.50      0.49       925

============================================
Running  11  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:26:16
forest model fit end:  2018-04-14 02:27:01
forest model predict start:  2018-04-14 02:27:01
forest model predict end:  2018-04-14 02:27:01
accuracy:  0.514594594595   476 / 925
Testing folds:  [ 3.]
Training folds:  [1, 2, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.20      0.09      0.12       100
          2       0.87      0.91      0.89        43
          3       0.31      0.55      0.39       100
          4       0.54      0.61      0.57       100
          5       0.87      0.54      0.67       100
          6       0.39      0.21      0.27       107
          7       0.91      0.86      0.89        36
          8       0.47      0.88      0.61       120
          9       0.77      0.48      0.59       119
         10       0.48      0.42      0.45       100

avg / total       0.54      0.51      0.50       925

============================================
Running  12  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:27:01
forest model fit end:  2018-04-14 02:27:47
forest model predict start:  2018-04-14 02:27:47
forest model predict end:  2018-04-14 02:27:47
accuracy:  0.516756756757   478 / 925
Testing folds:  [ 3.]
Training folds:  [1, 2, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.24      0.10      0.14       100
          2       0.84      0.88      0.86        43
          3       0.31      0.57      0.40       100
          4       0.52      0.64      0.57       100
          5       0.87      0.60      0.71       100
          6       0.37      0.22      0.28       107
          7       0.91      0.86      0.89        36
          8       0.47      0.87      0.61       120
          9       0.84      0.40      0.55       119
         10       0.49      0.42      0.45       100

avg / total       0.55      0.52      0.50       925

============================================
Running  13  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:27:47
forest model fit end:  2018-04-14 02:28:32
forest model predict start:  2018-04-14 02:28:32
forest model predict end:  2018-04-14 02:28:32
accuracy:  0.487567567568   451 / 925
Testing folds:  [ 3.]
Training folds:  [1, 2, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.15      0.05      0.07       100
          2       0.86      0.88      0.87        43
          3       0.29      0.56      0.38       100
          4       0.53      0.59      0.56       100
          5       0.77      0.47      0.58       100
          6       0.41      0.22      0.29       107
          7       0.89      0.86      0.87        36
          8       0.47      0.87      0.61       120
          9       0.68      0.37      0.48       119
         10       0.43      0.43      0.43       100

avg / total       0.50      0.49      0.47       925

============================================
Running  14  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:28:33
forest model fit end:  2018-04-14 02:29:18
forest model predict start:  2018-04-14 02:29:18
forest model predict end:  2018-04-14 02:29:18
accuracy:  0.51027027027   472 / 925
Testing folds:  [ 3.]
Training folds:  [1, 2, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.35      0.17      0.23       100
          2       0.83      0.93      0.88        43
          3       0.30      0.56      0.39       100
          4       0.57      0.65      0.61       100
          5       0.81      0.46      0.59       100
          6       0.42      0.21      0.28       107
          7       0.89      0.86      0.87        36
          8       0.46      0.87      0.60       120
          9       0.70      0.41      0.52       119
         10       0.48      0.42      0.45       100

avg / total       0.54      0.51      0.50       925

============================================
Running  15  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:29:18
forest model fit end:  2018-04-14 02:30:03
forest model predict start:  2018-04-14 02:30:03
forest model predict end:  2018-04-14 02:30:04
accuracy:  0.517837837838   479 / 925
Testing folds:  [ 3.]
Training folds:  [1, 2, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.36      0.20      0.26       100
          2       0.93      0.95      0.94        43
          3       0.31      0.57      0.40       100
          4       0.51      0.56      0.53       100
          5       0.84      0.53      0.65       100
          6       0.47      0.23      0.31       107
          7       0.94      0.86      0.90        36
          8       0.47      0.86      0.61       120
          9       0.72      0.42      0.53       119
         10       0.46      0.43      0.45       100

avg / total       0.56      0.52      0.51       925

============================================
Running  16  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:30:04
forest model fit end:  2018-04-14 02:30:49
forest model predict start:  2018-04-14 02:30:49
forest model predict end:  2018-04-14 02:30:49
accuracy:  0.501621621622   464 / 925
Testing folds:  [ 3.]
Training folds:  [1, 2, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.17      0.08      0.11       100
          2       0.90      0.88      0.89        43
          3       0.31      0.57      0.40       100
          4       0.50      0.62      0.56       100
          5       0.86      0.60      0.71       100
          6       0.36      0.20      0.25       107
          7       0.89      0.86      0.87        36
          8       0.46      0.86      0.60       120
          9       0.79      0.34      0.48       119
         10       0.47      0.43      0.45       100

avg / total       0.53      0.50      0.48       925

============================================
Running  17  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:30:49
forest model fit end:  2018-04-14 02:31:35
forest model predict start:  2018-04-14 02:31:35
forest model predict end:  2018-04-14 02:31:35
accuracy:  0.508108108108   470 / 925
Testing folds:  [ 3.]
Training folds:  [1, 2, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.27      0.12      0.17       100
          2       0.85      0.93      0.89        43
          3       0.30      0.56      0.39       100
          4       0.54      0.61      0.57       100
          5       0.87      0.52      0.65       100
          6       0.36      0.18      0.24       107
          7       0.89      0.86      0.87        36
          8       0.46      0.87      0.60       120
          9       0.76      0.45      0.57       119
         10       0.46      0.41      0.43       100

avg / total       0.54      0.51      0.49       925

============================================
Running  18  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:31:35
forest model fit end:  2018-04-14 02:32:20
forest model predict start:  2018-04-14 02:32:20
forest model predict end:  2018-04-14 02:32:21
accuracy:  0.514594594595   476 / 925
Testing folds:  [ 3.]
Training folds:  [1, 2, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.26      0.12      0.16       100
          2       0.91      0.93      0.92        43
          3       0.29      0.55      0.38       100
          4       0.57      0.63      0.60       100
          5       0.88      0.51      0.65       100
          6       0.36      0.21      0.27       107
          7       0.91      0.86      0.89        36
          8       0.47      0.87      0.61       120
          9       0.71      0.45      0.55       119
         10       0.52      0.43      0.47       100

avg / total       0.54      0.51      0.50       925

============================================
Running  19  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:32:21
forest model fit end:  2018-04-14 02:33:06
forest model predict start:  2018-04-14 02:33:06
forest model predict end:  2018-04-14 02:33:06
accuracy:  0.507027027027   469 / 925
Testing folds:  [ 3.]
Training folds:  [1, 2, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.19      0.08      0.11       100
          2       0.95      0.95      0.95        43
          3       0.31      0.57      0.40       100
          4       0.55      0.64      0.59       100
          5       0.84      0.48      0.61       100
          6       0.37      0.21      0.27       107
          7       0.89      0.86      0.87        36
          8       0.47      0.88      0.61       120
          9       0.69      0.41      0.52       119
         10       0.48      0.43      0.45       100

avg / total       0.53      0.51      0.49       925

============================================
Running  20  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:33:06
forest model fit end:  2018-04-14 02:33:52
forest model predict start:  2018-04-14 02:33:52
forest model predict end:  2018-04-14 02:33:52
accuracy:  0.530810810811   491 / 925
Testing folds:  [ 3.]
Training folds:  [1, 2, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.47      0.27      0.34       100
          2       0.85      0.93      0.89        43
          3       0.32      0.61      0.42       100
          4       0.57      0.64      0.60       100
          5       0.82      0.45      0.58       100
          6       0.57      0.23      0.33       107
          7       0.91      0.86      0.89        36
          8       0.46      0.84      0.59       120
          9       0.71      0.46      0.56       119
         10       0.47      0.42      0.44       100

avg / total       0.58      0.53      0.52       925

============================================
Running  21  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:33:52
forest model fit end:  2018-04-14 02:34:37
forest model predict start:  2018-04-14 02:34:37
forest model predict end:  2018-04-14 02:34:38
accuracy:  0.518918918919   480 / 925
Testing folds:  [ 3.]
Training folds:  [1, 2, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.16      0.07      0.10       100
          2       0.91      0.93      0.92        43
          3       0.31      0.57      0.40       100
          4       0.54      0.61      0.58       100
          5       0.89      0.64      0.74       100
          6       0.37      0.21      0.27       107
          7       0.91      0.86      0.89        36
          8       0.47      0.86      0.60       120
          9       0.88      0.43      0.58       119
         10       0.47      0.43      0.45       100

avg / total       0.55      0.52      0.51       925

============================================
Running  22  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:34:38
forest model fit end:  2018-04-14 02:35:23
forest model predict start:  2018-04-14 02:35:23
forest model predict end:  2018-04-14 02:35:23
accuracy:  0.502702702703   465 / 925
Testing folds:  [ 3.]
Training folds:  [1, 2, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.31      0.15      0.20       100
          2       0.88      0.88      0.88        43
          3       0.29      0.58      0.39       100
          4       0.52      0.59      0.55       100
          5       0.79      0.54      0.64       100
          6       0.48      0.22      0.31       107
          7       0.91      0.86      0.89        36
          8       0.46      0.85      0.60       120
          9       0.78      0.36      0.49       119
         10       0.43      0.41      0.42       100

avg / total       0.55      0.50      0.49       925

============================================
Running  23  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:35:23
forest model fit end:  2018-04-14 02:36:08
forest model predict start:  2018-04-14 02:36:08
forest model predict end:  2018-04-14 02:36:09
accuracy:  0.503783783784   466 / 925
Testing folds:  [ 3.]
Training folds:  [1, 2, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.30      0.16      0.21       100
          2       0.91      0.91      0.91        43
          3       0.30      0.57      0.39       100
          4       0.52      0.59      0.55       100
          5       0.89      0.51      0.65       100
          6       0.43      0.21      0.28       107
          7       0.91      0.86      0.89        36
          8       0.46      0.84      0.59       120
          9       0.68      0.40      0.51       119
         10       0.46      0.42      0.44       100

avg / total       0.54      0.50      0.49       925

============================================
Running  24  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:36:09
forest model fit end:  2018-04-14 02:36:54
forest model predict start:  2018-04-14 02:36:54
forest model predict end:  2018-04-14 02:36:54
accuracy:  0.515675675676   477 / 925
Testing folds:  [ 3.]
Training folds:  [1, 2, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.12      0.04      0.06       100
          2       0.89      0.95      0.92        43
          3       0.29      0.56      0.38       100
          4       0.58      0.62      0.60       100
          5       0.86      0.63      0.73       100
          6       0.37      0.22      0.28       107
          7       0.91      0.86      0.89        36
          8       0.46      0.88      0.61       120
          9       0.86      0.43      0.57       119
         10       0.45      0.40      0.42       100

avg / total       0.54      0.52      0.50       925

============================================
Running  25  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:36:54
forest model fit end:  2018-04-14 02:37:40
forest model predict start:  2018-04-14 02:37:40
forest model predict end:  2018-04-14 02:37:40
accuracy:  0.518918918919   480 / 925
Testing folds:  [ 3.]
Training folds:  [1, 2, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.15      0.06      0.09       100
          2       0.89      0.91      0.90        43
          3       0.30      0.57      0.39       100
          4       0.56      0.63      0.59       100
          5       0.86      0.59      0.70       100
          6       0.39      0.22      0.28       107
          7       0.91      0.86      0.89        36
          8       0.46      0.85      0.59       120
          9       0.83      0.49      0.61       119
         10       0.51      0.41      0.45       100

avg / total       0.54      0.52      0.51       925

============================================
Running  26  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:37:40
forest model fit end:  2018-04-14 02:38:25
forest model predict start:  2018-04-14 02:38:25
forest model predict end:  2018-04-14 02:38:25
accuracy:  0.513513513514   475 / 925
Testing folds:  [ 3.]
Training folds:  [1, 2, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.21      0.08      0.12       100
          2       0.83      0.88      0.85        43
          3       0.32      0.58      0.42       100
          4       0.55      0.65      0.60       100
          5       0.82      0.49      0.61       100
          6       0.34      0.22      0.27       107
          7       0.91      0.86      0.89        36
          8       0.45      0.83      0.59       120
          9       0.77      0.49      0.60       119
         10       0.52      0.44      0.48       100

avg / total       0.53      0.51      0.50       925

============================================
Running  27  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:38:26
forest model fit end:  2018-04-14 02:39:11
forest model predict start:  2018-04-14 02:39:11
forest model predict end:  2018-04-14 02:39:11
accuracy:  0.527567567568   488 / 925
Testing folds:  [ 3.]
Training folds:  [1, 2, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.24      0.10      0.14       100
          2       0.91      0.93      0.92        43
          3       0.32      0.57      0.41       100
          4       0.55      0.62      0.58       100
          5       0.87      0.58      0.69       100
          6       0.40      0.22      0.29       107
          7       0.89      0.86      0.87        36
          8       0.47      0.88      0.61       120
          9       0.80      0.47      0.59       119
         10       0.49      0.44      0.47       100

avg / total       0.55      0.53      0.51       925

============================================
Running  28  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:39:11
forest model fit end:  2018-04-14 02:39:56
forest model predict start:  2018-04-14 02:39:56
forest model predict end:  2018-04-14 02:39:57
accuracy:  0.518918918919   480 / 925
Testing folds:  [ 3.]
Training folds:  [1, 2, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.29      0.15      0.20       100
          2       0.95      0.91      0.93        43
          3       0.32      0.58      0.41       100
          4       0.50      0.59      0.54       100
          5       0.90      0.61      0.73       100
          6       0.42      0.21      0.28       107
          7       0.89      0.86      0.87        36
          8       0.47      0.88      0.61       120
          9       0.81      0.40      0.54       119
         10       0.45      0.42      0.44       100

avg / total       0.56      0.52      0.51       925

============================================
Running  29  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:39:57
forest model fit end:  2018-04-14 02:40:42
forest model predict start:  2018-04-14 02:40:42
forest model predict end:  2018-04-14 02:40:43
accuracy:  0.515675675676   477 / 925
Testing folds:  [ 3.]
Training folds:  [1, 2, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.23      0.09      0.13       100
          2       0.93      0.91      0.92        43
          3       0.32      0.58      0.41       100
          4       0.52      0.63      0.57       100
          5       0.81      0.58      0.67       100
          6       0.43      0.24      0.31       107
          7       0.94      0.86      0.90        36
          8       0.47      0.86      0.60       120
          9       0.79      0.41      0.54       119
         10       0.44      0.41      0.42       100

avg / total       0.54      0.52      0.50       925

============================================
Running  30  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:40:43
forest model fit end:  2018-04-14 02:41:28
forest model predict start:  2018-04-14 02:41:28
forest model predict end:  2018-04-14 02:41:28
accuracy:  0.526486486486   487 / 925
Testing folds:  [ 3.]
Training folds:  [1, 2, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.40      0.23      0.29       100
          2       0.91      0.93      0.92        43
          3       0.32      0.58      0.41       100
          4       0.52      0.62      0.56       100
          5       0.87      0.59      0.70       100
          6       0.44      0.20      0.27       107
          7       0.91      0.86      0.89        36
          8       0.46      0.84      0.59       120
          9       0.80      0.43      0.56       119
         10       0.48      0.41      0.44       100

avg / total       0.57      0.53      0.52       925

============================================
Running  31  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:41:29
forest model fit end:  2018-04-14 02:42:14
forest model predict start:  2018-04-14 02:42:14
forest model predict end:  2018-04-14 02:42:14
accuracy:  0.500540540541   463 / 925
Testing folds:  [ 3.]
Training folds:  [1, 2, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.16      0.06      0.09       100
          2       0.85      0.93      0.89        43
          3       0.30      0.56      0.39       100
          4       0.53      0.62      0.57       100
          5       0.84      0.51      0.63       100
          6       0.36      0.21      0.27       107
          7       0.89      0.86      0.87        36
          8       0.46      0.86      0.60       120
          9       0.79      0.41      0.54       119
         10       0.45      0.42      0.44       100

avg / total       0.52      0.50      0.48       925

============================================
Running  32  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:42:14
forest model fit end:  2018-04-14 02:43:00
forest model predict start:  2018-04-14 02:43:00
forest model predict end:  2018-04-14 02:43:00
accuracy:  0.507027027027   469 / 925
Testing folds:  [ 3.]
Training folds:  [1, 2, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.23      0.11      0.15       100
          2       0.95      0.88      0.92        43
          3       0.31      0.56      0.40       100
          4       0.51      0.61      0.56       100
          5       0.77      0.55      0.64       100
          6       0.40      0.21      0.28       107
          7       0.89      0.86      0.87        36
          8       0.46      0.83      0.60       120
          9       0.75      0.43      0.55       119
         10       0.47      0.43      0.45       100

avg / total       0.53      0.51      0.49       925

============================================
Running  33  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:43:00
forest model fit end:  2018-04-14 02:43:46
forest model predict start:  2018-04-14 02:43:46
forest model predict end:  2018-04-14 02:43:46
accuracy:  0.531891891892   492 / 925
Testing folds:  [ 3.]
Training folds:  [1, 2, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.54      0.30      0.38       100
          2       0.87      0.91      0.89        43
          3       0.33      0.59      0.42       100
          4       0.52      0.60      0.56       100
          5       0.81      0.48      0.60       100
          6       0.60      0.23      0.34       107
          7       0.91      0.86      0.89        36
          8       0.46      0.88      0.61       120
          9       0.72      0.44      0.54       119
         10       0.45      0.43      0.44       100

avg / total       0.58      0.53      0.52       925

============================================
Running  34  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:43:46
forest model fit end:  2018-04-14 02:44:31
forest model predict start:  2018-04-14 02:44:31
forest model predict end:  2018-04-14 02:44:32
accuracy:  0.495135135135   458 / 925
Testing folds:  [ 3.]
Training folds:  [1, 2, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.08      0.03      0.04       100
          2       0.91      0.93      0.92        43
          3       0.29      0.56      0.38       100
          4       0.56      0.60      0.58       100
          5       0.81      0.55      0.65       100
          6       0.32      0.21      0.25       107
          7       0.88      0.83      0.86        36
          8       0.45      0.84      0.59       120
          9       0.77      0.42      0.54       119
         10       0.48      0.41      0.44       100

avg / total       0.51      0.50      0.48       925

============================================
Running  35  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:44:32
forest model fit end:  2018-04-14 02:45:17
forest model predict start:  2018-04-14 02:45:17
forest model predict end:  2018-04-14 02:45:17
accuracy:  0.513513513514   475 / 925
Testing folds:  [ 3.]
Training folds:  [1, 2, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.24      0.11      0.15       100
          2       0.87      0.91      0.89        43
          3       0.32      0.57      0.41       100
          4       0.59      0.63      0.61       100
          5       0.80      0.47      0.59       100
          6       0.40      0.23      0.29       107
          7       0.89      0.86      0.87        36
          8       0.47      0.87      0.61       120
          9       0.71      0.45      0.55       119
         10       0.48      0.45      0.47       100

avg / total       0.53      0.51      0.50       925

============================================
Running  36  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:45:18
forest model fit end:  2018-04-14 02:46:03
forest model predict start:  2018-04-14 02:46:03
forest model predict end:  2018-04-14 02:46:03
accuracy:  0.498378378378   461 / 925
Testing folds:  [ 3.]
Training folds:  [1, 2, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.14      0.05      0.07       100
          2       0.89      0.93      0.91        43
          3       0.30      0.57      0.40       100
          4       0.55      0.59      0.57       100
          5       0.86      0.49      0.62       100
          6       0.37      0.23      0.29       107
          7       0.89      0.86      0.87        36
          8       0.46      0.87      0.60       120
          9       0.67      0.41      0.51       119
         10       0.45      0.42      0.44       100

avg / total       0.51      0.50      0.48       925

============================================
Running  37  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:46:03
forest model fit end:  2018-04-14 02:46:49
forest model predict start:  2018-04-14 02:46:49
forest model predict end:  2018-04-14 02:46:49
accuracy:  0.513513513514   475 / 925
Testing folds:  [ 3.]
Training folds:  [1, 2, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.18      0.07      0.10       100
          2       0.87      0.93      0.90        43
          3       0.30      0.56      0.39       100
          4       0.55      0.61      0.58       100
          5       0.86      0.55      0.67       100
          6       0.36      0.21      0.27       107
          7       0.94      0.86      0.90        36
          8       0.47      0.88      0.61       120
          9       0.82      0.46      0.59       119
         10       0.48      0.42      0.45       100

avg / total       0.54      0.51      0.50       925

============================================
Running  38  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:46:49
forest model fit end:  2018-04-14 02:47:35
forest model predict start:  2018-04-14 02:47:35
forest model predict end:  2018-04-14 02:47:35
accuracy:  0.508108108108   470 / 925
Testing folds:  [ 3.]
Training folds:  [1, 2, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.16      0.06      0.09       100
          2       0.84      0.88      0.86        43
          3       0.32      0.57      0.41       100
          4       0.53      0.63      0.58       100
          5       0.81      0.57      0.67       100
          6       0.33      0.21      0.26       107
          7       0.89      0.86      0.87        36
          8       0.46      0.84      0.60       120
          9       0.78      0.43      0.55       119
         10       0.49      0.43      0.46       100

avg / total       0.52      0.51      0.49       925

============================================
Running  39  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:47:35
forest model fit end:  2018-04-14 02:48:20
forest model predict start:  2018-04-14 02:48:20
forest model predict end:  2018-04-14 02:48:21
accuracy:  0.52   481 / 925
Testing folds:  [ 3.]
Training folds:  [1, 2, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.33      0.14      0.20       100
          2       0.91      0.93      0.92        43
          3       0.30      0.57      0.39       100
          4       0.52      0.57      0.55       100
          5       0.82      0.53      0.64       100
          6       0.47      0.24      0.32       107
          7       0.94      0.86      0.90        36
          8       0.46      0.88      0.60       120
          9       0.76      0.45      0.57       119
         10       0.51      0.44      0.47       100

avg / total       0.56      0.52      0.51       925

============================================
Running  40  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:48:21
forest model fit end:  2018-04-14 02:49:06
forest model predict start:  2018-04-14 02:49:06
forest model predict end:  2018-04-14 02:49:06
accuracy:  0.527567567568   488 / 925
Testing folds:  [ 3.]
Training folds:  [1, 2, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.40      0.21      0.27       100
          2       0.85      0.91      0.88        43
          3       0.30      0.56      0.39       100
          4       0.54      0.62      0.58       100
          5       0.85      0.53      0.65       100
          6       0.48      0.21      0.30       107
          7       0.91      0.86      0.89        36
          8       0.46      0.88      0.61       120
          9       0.77      0.47      0.58       119
         10       0.51      0.41      0.45       100

avg / total       0.57      0.53      0.52       925

============================================
Running  41  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:49:07
forest model fit end:  2018-04-14 02:49:52
forest model predict start:  2018-04-14 02:49:52
forest model predict end:  2018-04-14 02:49:52
accuracy:  0.532972972973   493 / 925
Testing folds:  [ 3.]
Training folds:  [1, 2, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.43      0.26      0.33       100
          2       0.90      0.88      0.89        43
          3       0.30      0.56      0.39       100
          4       0.55      0.60      0.57       100
          5       0.86      0.55      0.67       100
          6       0.50      0.22      0.31       107
          7       0.91      0.86      0.89        36
          8       0.45      0.83      0.58       120
          9       0.76      0.51      0.61       119
         10       0.51      0.42      0.46       100

avg / total       0.58      0.53      0.53       925

============================================
Running  42  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:49:52
forest model fit end:  2018-04-14 02:50:38
forest model predict start:  2018-04-14 02:50:38
forest model predict end:  2018-04-14 02:50:38
accuracy:  0.511351351351   473 / 925
Testing folds:  [ 3.]
Training folds:  [1, 2, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.21      0.08      0.12       100
          2       0.91      0.95      0.93        43
          3       0.30      0.56      0.39       100
          4       0.54      0.61      0.57       100
          5       0.88      0.57      0.69       100
          6       0.37      0.21      0.27       107
          7       0.91      0.86      0.89        36
          8       0.45      0.84      0.59       120
          9       0.78      0.45      0.57       119
         10       0.47      0.42      0.44       100

avg / total       0.54      0.51      0.50       925

============================================
Running  43  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:50:38
forest model fit end:  2018-04-14 02:51:24
forest model predict start:  2018-04-14 02:51:24
forest model predict end:  2018-04-14 02:51:24
accuracy:  0.500540540541   463 / 925
Testing folds:  [ 3.]
Training folds:  [1, 2, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.18      0.07      0.10       100
          2       0.93      0.93      0.93        43
          3       0.31      0.60      0.41       100
          4       0.57      0.61      0.59       100
          5       0.88      0.50      0.64       100
          6       0.38      0.22      0.28       107
          7       0.94      0.86      0.90        36
          8       0.46      0.86      0.60       120
          9       0.70      0.39      0.50       119
         10       0.42      0.41      0.41       100

avg / total       0.53      0.50      0.48       925

============================================
Running  44  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:51:24
forest model fit end:  2018-04-14 02:52:09
forest model predict start:  2018-04-14 02:52:09
forest model predict end:  2018-04-14 02:52:10
accuracy:  0.51027027027   472 / 925
Testing folds:  [ 3.]
Training folds:  [1, 2, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.22      0.11      0.15       100
          2       0.87      0.91      0.89        43
          3       0.29      0.56      0.39       100
          4       0.53      0.59      0.56       100
          5       0.82      0.51      0.63       100
          6       0.38      0.21      0.27       107
          7       0.89      0.86      0.87        36
          8       0.46      0.86      0.60       120
          9       0.77      0.48      0.59       119
         10       0.54      0.43      0.48       100

avg / total       0.54      0.51      0.50       925

============================================
Running  45  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:52:10
forest model fit end:  2018-04-14 02:52:55
forest model predict start:  2018-04-14 02:52:55
forest model predict end:  2018-04-14 02:52:55
accuracy:  0.488648648649   452 / 925
Testing folds:  [ 3.]
Training folds:  [1, 2, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.15      0.05      0.07       100
          2       0.86      0.86      0.86        43
          3       0.29      0.56      0.38       100
          4       0.53      0.59      0.56       100
          5       0.85      0.50      0.63       100
          6       0.34      0.21      0.26       107
          7       0.91      0.86      0.89        36
          8       0.46      0.88      0.61       120
          9       0.70      0.38      0.49       119
         10       0.43      0.41      0.42       100

avg / total       0.51      0.49      0.47       925

============================================
Running  46  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:52:56
forest model fit end:  2018-04-14 02:53:41
forest model predict start:  2018-04-14 02:53:41
forest model predict end:  2018-04-14 02:53:41
accuracy:  0.503783783784   466 / 925
Testing folds:  [ 3.]
Training folds:  [1, 2, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.23      0.10      0.14       100
          2       0.82      0.93      0.87        43
          3       0.31      0.57      0.40       100
          4       0.56      0.58      0.57       100
          5       0.85      0.55      0.67       100
          6       0.34      0.21      0.26       107
          7       0.89      0.86      0.87        36
          8       0.47      0.86      0.61       120
          9       0.75      0.39      0.51       119
         10       0.46      0.43      0.44       100

avg / total       0.53      0.50      0.49       925

============================================
Running  47  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:53:41
forest model fit end:  2018-04-14 02:54:27
forest model predict start:  2018-04-14 02:54:27
forest model predict end:  2018-04-14 02:54:27
accuracy:  0.503783783784   466 / 925
Testing folds:  [ 3.]
Training folds:  [1, 2, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.23      0.11      0.15       100
          2       0.89      0.93      0.91        43
          3       0.30      0.56      0.39       100
          4       0.55      0.60      0.57       100
          5       0.86      0.50      0.63       100
          6       0.38      0.19      0.25       107
          7       0.89      0.86      0.87        36
          8       0.46      0.87      0.60       120
          9       0.69      0.42      0.52       119
         10       0.46      0.44      0.45       100

avg / total       0.53      0.50      0.49       925

============================================
Running  48  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:54:27
forest model fit end:  2018-04-14 02:55:12
forest model predict start:  2018-04-14 02:55:12
forest model predict end:  2018-04-14 02:55:13
accuracy:  0.511351351351   473 / 925
Testing folds:  [ 3.]
Training folds:  [1, 2, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.20      0.09      0.12       100
          2       0.87      0.93      0.90        43
          3       0.29      0.55      0.38       100
          4       0.57      0.59      0.58       100
          5       0.87      0.52      0.65       100
          6       0.38      0.22      0.28       107
          7       0.86      0.86      0.86        36
          8       0.47      0.85      0.60       120
          9       0.78      0.48      0.59       119
         10       0.49      0.44      0.47       100

avg / total       0.54      0.51      0.50       925

============================================
Running  49  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:55:13
forest model fit end:  2018-04-14 02:55:58
forest model predict start:  2018-04-14 02:55:58
forest model predict end:  2018-04-14 02:55:59
accuracy:  0.503783783784   466 / 925
Testing folds:  [ 3.]
Training folds:  [1, 2, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.18      0.06      0.09       100
          2       0.87      0.93      0.90        43
          3       0.31      0.58      0.40       100
          4       0.54      0.65      0.59       100
          5       0.90      0.47      0.62       100
          6       0.40      0.22      0.29       107
          7       0.91      0.86      0.89        36
          8       0.46      0.88      0.61       120
          9       0.68      0.39      0.49       119
         10       0.46      0.43      0.45       100

avg / total       0.53      0.50      0.48       925

============================================
Running  50  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:55:59
forest model fit end:  2018-04-14 02:56:44
forest model predict start:  2018-04-14 02:56:44
forest model predict end:  2018-04-14 02:56:44
accuracy:  0.513513513514   475 / 925
Testing folds:  [ 3.]
Training folds:  [1, 2, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.15      0.06      0.09       100
          2       0.86      0.88      0.87        43
          3       0.30      0.56      0.39       100
          4       0.55      0.62      0.58       100
          5       0.78      0.54      0.64       100
          6       0.35      0.22      0.27       107
          7       0.94      0.86      0.90        36
          8       0.46      0.84      0.59       120
          9       0.85      0.51      0.64       119
         10       0.54      0.42      0.47       100

avg / total       0.54      0.51      0.50       925

============================================
[0.50270270270270268, 0.52000000000000002, 0.50918918918918921, 0.50054054054054054, 0.49837837837837839, 0.5318918918918919, 0.52324324324324323, 0.52216216216216216, 0.50702702702702707, 0.50378378378378375, 0.51459459459459456, 0.51675675675675681, 0.48756756756756758, 0.51027027027027028, 0.51783783783783788, 0.50162162162162161, 0.50810810810810814, 0.51459459459459456, 0.50702702702702707, 0.53081081081081083, 0.51891891891891895, 0.50270270270270268, 0.50378378378378375, 0.51567567567567563, 0.51891891891891895, 0.51351351351351349, 0.52756756756756762, 0.51891891891891895, 0.51567567567567563, 0.52648648648648644, 0.50054054054054054, 0.50702702702702707, 0.5318918918918919, 0.49513513513513513, 0.51351351351351349, 0.49837837837837839, 0.51351351351351349, 0.50810810810810814, 0.52000000000000002, 0.52756756756756762, 0.53297297297297297, 0.51135135135135135, 0.50054054054054054, 0.51027027027027028, 0.48864864864864865, 0.50378378378378375, 0.50378378378378375, 0.51135135135135135, 0.50378378378378375, 0.51351351351351349]
Avg accuracy:  0.511718918919
