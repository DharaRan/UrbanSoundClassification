Running  1  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:20:12
forest model fit end:  2018-04-14 02:20:58
forest model predict start:  2018-04-14 02:20:58
forest model predict end:  2018-04-14 02:20:58
accuracy:  0.642679900744   518 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.46      0.33      0.39       100
          2       0.96      0.90      0.93        30
          3       0.53      0.64      0.58       100
          4       0.60      0.56      0.58       100
          5       0.80      0.74      0.77       100
          6       0.65      0.57      0.61        88
          7       0.77      0.57      0.65        30
          8       0.58      0.87      0.69        78
          9       0.77      0.89      0.83        80
         10       0.64      0.58      0.61       100

avg / total       0.64      0.64      0.64       806

============================================
Running  2  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:20:58
forest model fit end:  2018-04-14 02:21:44
forest model predict start:  2018-04-14 02:21:44
forest model predict end:  2018-04-14 02:21:44
accuracy:  0.60794044665   490 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.14      0.05      0.07       100
          2       1.00      0.87      0.93        30
          3       0.53      0.64      0.58       100
          4       0.58      0.59      0.59       100
          5       0.78      0.72      0.75       100
          6       0.49      0.60      0.54        88
          7       0.81      0.57      0.67        30
          8       0.57      0.86      0.69        78
          9       0.76      0.86      0.81        80
         10       0.62      0.58      0.60       100

avg / total       0.58      0.61      0.59       806

============================================
Running  3  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:21:44
forest model fit end:  2018-04-14 02:22:30
forest model predict start:  2018-04-14 02:22:30
forest model predict end:  2018-04-14 02:22:30
accuracy:  0.630272952854   508 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.42      0.32      0.36       100
          2       0.96      0.90      0.93        30
          3       0.57      0.65      0.61       100
          4       0.56      0.54      0.55       100
          5       0.76      0.73      0.74       100
          6       0.65      0.57      0.61        88
          7       0.73      0.53      0.62        30
          8       0.60      0.85      0.70        78
          9       0.74      0.88      0.80        80
         10       0.60      0.55      0.58       100

avg / total       0.63      0.63      0.62       806

============================================
Running  4  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:22:30
forest model fit end:  2018-04-14 02:23:15
forest model predict start:  2018-04-14 02:23:15
forest model predict end:  2018-04-14 02:23:16
accuracy:  0.653846153846   527 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.51      0.34      0.41       100
          2       1.00      0.90      0.95        30
          3       0.54      0.65      0.59       100
          4       0.61      0.58      0.59       100
          5       0.78      0.76      0.77       100
          6       0.65      0.64      0.64        88
          7       0.74      0.57      0.64        30
          8       0.59      0.85      0.69        78
          9       0.75      0.86      0.80        80
         10       0.68      0.59      0.63       100

avg / total       0.65      0.65      0.65       806

============================================
Running  5  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:23:16
forest model fit end:  2018-04-14 02:24:01
forest model predict start:  2018-04-14 02:24:01
forest model predict end:  2018-04-14 02:24:02
accuracy:  0.64888337469   523 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.51      0.34      0.41       100
          2       1.00      0.90      0.95        30
          3       0.56      0.66      0.61       100
          4       0.59      0.54      0.56       100
          5       0.79      0.73      0.76       100
          6       0.59      0.62      0.61        88
          7       0.75      0.60      0.67        30
          8       0.61      0.87      0.72        78
          9       0.74      0.88      0.80        80
         10       0.67      0.58      0.62       100

avg / total       0.65      0.65      0.64       806

============================================
Running  6  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:24:02
forest model fit end:  2018-04-14 02:24:47
forest model predict start:  2018-04-14 02:24:47
forest model predict end:  2018-04-14 02:24:47
accuracy:  0.633995037221   511 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.49      0.25      0.33       100
          2       1.00      0.93      0.97        30
          3       0.51      0.65      0.57       100
          4       0.57      0.54      0.55       100
          5       0.79      0.71      0.75       100
          6       0.59      0.61      0.60        88
          7       0.77      0.57      0.65        30
          8       0.60      0.87      0.71        78
          9       0.77      0.86      0.81        80
         10       0.61      0.60      0.61       100

avg / total       0.63      0.63      0.62       806

============================================
Running  7  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:24:47
forest model fit end:  2018-04-14 02:25:33
forest model predict start:  2018-04-14 02:25:33
forest model predict end:  2018-04-14 02:25:33
accuracy:  0.650124069479   524 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.51      0.37      0.43       100
          2       1.00      0.90      0.95        30
          3       0.52      0.63      0.57       100
          4       0.64      0.58      0.61       100
          5       0.82      0.80      0.81       100
          6       0.61      0.55      0.57        88
          7       0.74      0.57      0.64        30
          8       0.59      0.87      0.70        78
          9       0.77      0.86      0.81        80
         10       0.63      0.57      0.60       100

avg / total       0.65      0.65      0.64       806

============================================
Running  8  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:25:33
forest model fit end:  2018-04-14 02:26:19
forest model predict start:  2018-04-14 02:26:19
forest model predict end:  2018-04-14 02:26:19
accuracy:  0.622828784119   502 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.44      0.25      0.32       100
          2       0.97      0.97      0.97        30
          3       0.55      0.63      0.59       100
          4       0.57      0.56      0.57       100
          5       0.77      0.72      0.74       100
          6       0.51      0.51      0.51        88
          7       0.77      0.57      0.65        30
          8       0.54      0.83      0.65        78
          9       0.75      0.88      0.81        80
         10       0.68      0.60      0.64       100

avg / total       0.62      0.62      0.61       806

============================================
Running  9  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:26:19
forest model fit end:  2018-04-14 02:27:05
forest model predict start:  2018-04-14 02:27:05
forest model predict end:  2018-04-14 02:27:05
accuracy:  0.625310173697   504 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.17      0.05      0.08       100
          2       1.00      0.90      0.95        30
          3       0.55      0.67      0.61       100
          4       0.60      0.55      0.57       100
          5       0.78      0.76      0.77       100
          6       0.49      0.68      0.57        88
          7       0.77      0.57      0.65        30
          8       0.62      0.87      0.73        78
          9       0.74      0.88      0.80        80
         10       0.63      0.59      0.61       100

avg / total       0.59      0.63      0.60       806

============================================
Running  10  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:27:05
forest model fit end:  2018-04-14 02:27:50
forest model predict start:  2018-04-14 02:27:50
forest model predict end:  2018-04-14 02:27:51
accuracy:  0.651364764268   525 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.53      0.35      0.42       100
          2       1.00      0.93      0.97        30
          3       0.55      0.64      0.59       100
          4       0.64      0.56      0.60       100
          5       0.79      0.81      0.80       100
          6       0.64      0.56      0.60        88
          7       0.75      0.60      0.67        30
          8       0.58      0.85      0.69        78
          9       0.72      0.88      0.79        80
         10       0.60      0.58      0.59       100

avg / total       0.65      0.65      0.64       806

============================================
Running  11  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:27:51
forest model fit end:  2018-04-14 02:28:36
forest model predict start:  2018-04-14 02:28:36
forest model predict end:  2018-04-14 02:28:37
accuracy:  0.637717121588   514 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.43      0.30      0.35       100
          2       1.00      0.87      0.93        30
          3       0.52      0.63      0.57       100
          4       0.60      0.58      0.59       100
          5       0.81      0.75      0.78       100
          6       0.63      0.56      0.59        88
          7       0.74      0.57      0.64        30
          8       0.58      0.86      0.69        78
          9       0.78      0.88      0.82        80
         10       0.63      0.59      0.61       100

avg / total       0.64      0.64      0.63       806

============================================
Running  12  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:28:37
forest model fit end:  2018-04-14 02:29:22
forest model predict start:  2018-04-14 02:29:22
forest model predict end:  2018-04-14 02:29:22
accuracy:  0.636476426799   513 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.43      0.26      0.33       100
          2       0.93      0.90      0.92        30
          3       0.52      0.65      0.58       100
          4       0.59      0.55      0.57       100
          5       0.77      0.75      0.76       100
          6       0.63      0.59      0.61        88
          7       0.77      0.57      0.65        30
          8       0.59      0.86      0.70        78
          9       0.74      0.88      0.80        80
         10       0.66      0.59      0.62       100

avg / total       0.63      0.64      0.63       806

============================================
Running  13  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:29:23
forest model fit end:  2018-04-14 02:30:08
forest model predict start:  2018-04-14 02:30:08
forest model predict end:  2018-04-14 02:30:08
accuracy:  0.64888337469   523 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.55      0.32      0.41       100
          2       1.00      0.93      0.97        30
          3       0.55      0.65      0.59       100
          4       0.60      0.56      0.58       100
          5       0.78      0.76      0.77       100
          6       0.61      0.60      0.61        88
          7       0.77      0.57      0.65        30
          8       0.58      0.87      0.70        78
          9       0.74      0.86      0.80        80
         10       0.64      0.59      0.61       100

avg / total       0.65      0.65      0.64       806

============================================
Running  14  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:30:08
forest model fit end:  2018-04-14 02:30:54
forest model predict start:  2018-04-14 02:30:54
forest model predict end:  2018-04-14 02:30:54
accuracy:  0.661290322581   533 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.49      0.34      0.40       100
          2       1.00      0.93      0.97        30
          3       0.57      0.63      0.60       100
          4       0.64      0.59      0.61       100
          5       0.81      0.80      0.80       100
          6       0.63      0.61      0.62        88
          7       0.74      0.57      0.64        30
          8       0.60      0.87      0.71        78
          9       0.74      0.88      0.80        80
         10       0.66      0.60      0.63       100

avg / total       0.66      0.66      0.65       806

============================================
Running  15  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:30:54
forest model fit end:  2018-04-14 02:31:40
forest model predict start:  2018-04-14 02:31:40
forest model predict end:  2018-04-14 02:31:40
accuracy:  0.632754342432   510 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.40      0.22      0.28       100
          2       0.97      0.93      0.95        30
          3       0.56      0.64      0.60       100
          4       0.58      0.57      0.58       100
          5       0.78      0.72      0.75       100
          6       0.53      0.59      0.56        88
          7       0.75      0.60      0.67        30
          8       0.59      0.86      0.70        78
          9       0.74      0.88      0.80        80
         10       0.68      0.60      0.64       100

avg / total       0.63      0.63      0.62       806

============================================
Running  16  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:31:40
forest model fit end:  2018-04-14 02:32:25
forest model predict start:  2018-04-14 02:32:25
forest model predict end:  2018-04-14 02:32:26
accuracy:  0.620347394541   500 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.22      0.10      0.14       100
          2       1.00      0.93      0.97        30
          3       0.55      0.64      0.59       100
          4       0.60      0.56      0.58       100
          5       0.82      0.75      0.78       100
          6       0.48      0.61      0.54        88
          7       0.78      0.60      0.68        30
          8       0.59      0.86      0.70        78
          9       0.73      0.89      0.80        80
         10       0.67      0.57      0.62       100

avg / total       0.60      0.62      0.60       806

============================================
Running  17  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:32:26
forest model fit end:  2018-04-14 02:33:11
forest model predict start:  2018-04-14 02:33:11
forest model predict end:  2018-04-14 02:33:12
accuracy:  0.624069478908   503 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.46      0.29      0.36       100
          2       1.00      0.90      0.95        30
          3       0.49      0.66      0.56       100
          4       0.57      0.55      0.56       100
          5       0.79      0.73      0.76       100
          6       0.60      0.48      0.53        88
          7       0.77      0.57      0.65        30
          8       0.56      0.88      0.69        78
          9       0.74      0.86      0.80        80
         10       0.67      0.56      0.61       100

avg / total       0.63      0.62      0.62       806

============================================
Running  18  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:33:12
forest model fit end:  2018-04-14 02:33:57
forest model predict start:  2018-04-14 02:33:57
forest model predict end:  2018-04-14 02:33:58
accuracy:  0.64888337469   523 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.57      0.37      0.45       100
          2       1.00      0.90      0.95        30
          3       0.53      0.64      0.58       100
          4       0.59      0.57      0.58       100
          5       0.81      0.71      0.76       100
          6       0.60      0.60      0.60        88
          7       0.65      0.57      0.61        30
          8       0.60      0.87      0.71        78
          9       0.78      0.86      0.82        80
         10       0.65      0.60      0.63       100

avg / total       0.65      0.65      0.64       806

============================================
Running  19  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:33:58
forest model fit end:  2018-04-14 02:34:43
forest model predict start:  2018-04-14 02:34:43
forest model predict end:  2018-04-14 02:34:43
accuracy:  0.622828784119   502 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.23      0.09      0.13       100
          2       1.00      0.87      0.93        30
          3       0.53      0.63      0.57       100
          4       0.62      0.55      0.59       100
          5       0.78      0.79      0.79       100
          6       0.48      0.62      0.54        88
          7       0.77      0.57      0.65        30
          8       0.60      0.87      0.71        78
          9       0.77      0.89      0.83        80
         10       0.66      0.59      0.62       100

avg / total       0.60      0.62      0.60       806

============================================
Running  20  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:34:44
forest model fit end:  2018-04-14 02:35:29
forest model predict start:  2018-04-14 02:35:29
forest model predict end:  2018-04-14 02:35:29
accuracy:  0.62158808933   501 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.30      0.13      0.18       100
          2       1.00      0.90      0.95        30
          3       0.51      0.63      0.57       100
          4       0.59      0.57      0.58       100
          5       0.78      0.72      0.75       100
          6       0.53      0.60      0.56        88
          7       0.74      0.57      0.64        30
          8       0.59      0.88      0.71        78
          9       0.76      0.89      0.82        80
         10       0.65      0.59      0.62       100

avg / total       0.61      0.62      0.61       806

============================================
Running  21  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:35:29
forest model fit end:  2018-04-14 02:36:15
forest model predict start:  2018-04-14 02:36:15
forest model predict end:  2018-04-14 02:36:15
accuracy:  0.599255583127   483 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.06      0.02      0.03       100
          2       1.00      0.90      0.95        30
          3       0.54      0.66      0.59       100
          4       0.60      0.57      0.58       100
          5       0.78      0.70      0.74       100
          6       0.42      0.56      0.48        88
          7       0.74      0.57      0.64        30
          8       0.57      0.87      0.69        78
          9       0.75      0.86      0.80        80
         10       0.64      0.58      0.61       100

avg / total       0.57      0.60      0.57       806

============================================
Running  22  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:36:15
forest model fit end:  2018-04-14 02:37:01
forest model predict start:  2018-04-14 02:37:01
forest model predict end:  2018-04-14 02:37:01
accuracy:  0.655086848635   528 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.54      0.33      0.41       100
          2       0.96      0.87      0.91        30
          3       0.51      0.64      0.57       100
          4       0.64      0.60      0.62       100
          5       0.76      0.77      0.77       100
          6       0.64      0.65      0.64        88
          7       0.78      0.60      0.68        30
          8       0.62      0.85      0.71        78
          9       0.76      0.86      0.81        80
         10       0.66      0.58      0.62       100

avg / total       0.66      0.66      0.65       806

============================================
Running  23  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:37:01
forest model fit end:  2018-04-14 02:37:47
forest model predict start:  2018-04-14 02:37:47
forest model predict end:  2018-04-14 02:37:47
accuracy:  0.637717121588   514 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.45      0.33      0.38       100
          2       1.00      0.93      0.97        30
          3       0.54      0.67      0.60       100
          4       0.59      0.57      0.58       100
          5       0.79      0.70      0.74       100
          6       0.66      0.51      0.58        88
          7       0.77      0.57      0.65        30
          8       0.56      0.88      0.68        78
          9       0.74      0.86      0.80        80
         10       0.67      0.59      0.63       100

avg / total       0.64      0.64      0.63       806

============================================
Running  24  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:37:47
forest model fit end:  2018-04-14 02:38:32
forest model predict start:  2018-04-14 02:38:32
forest model predict end:  2018-04-14 02:38:33
accuracy:  0.630272952854   508 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.35      0.16      0.22       100
          2       0.93      0.93      0.93        30
          3       0.54      0.63      0.58       100
          4       0.60      0.56      0.58       100
          5       0.80      0.77      0.79       100
          6       0.53      0.61      0.57        88
          7       0.74      0.57      0.64        30
          8       0.58      0.87      0.70        78
          9       0.74      0.88      0.80        80
         10       0.66      0.59      0.62       100

avg / total       0.62      0.63      0.61       806

============================================
Running  25  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:38:33
forest model fit end:  2018-04-14 02:39:18
forest model predict start:  2018-04-14 02:39:18
forest model predict end:  2018-04-14 02:39:19
accuracy:  0.624069478908   503 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.38      0.21      0.27       100
          2       0.97      0.93      0.95        30
          3       0.52      0.64      0.58       100
          4       0.63      0.56      0.59       100
          5       0.82      0.76      0.79       100
          6       0.51      0.52      0.52        88
          7       0.77      0.57      0.65        30
          8       0.57      0.88      0.70        78
          9       0.71      0.88      0.78        80
         10       0.64      0.56      0.60       100

avg / total       0.62      0.62      0.61       806

============================================
Running  26  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:39:19
forest model fit end:  2018-04-14 02:40:05
forest model predict start:  2018-04-14 02:40:05
forest model predict end:  2018-04-14 02:40:05
accuracy:  0.652605459057   526 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.53      0.33      0.41       100
          2       1.00      0.90      0.95        30
          3       0.55      0.65      0.60       100
          4       0.62      0.57      0.59       100
          5       0.80      0.79      0.79       100
          6       0.58      0.56      0.57        88
          7       0.77      0.57      0.65        30
          8       0.58      0.88      0.70        78
          9       0.75      0.89      0.81        80
         10       0.66      0.59      0.62       100

avg / total       0.65      0.65      0.64       806

============================================
Running  27  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:40:05
forest model fit end:  2018-04-14 02:40:51
forest model predict start:  2018-04-14 02:40:51
forest model predict end:  2018-04-14 02:40:51
accuracy:  0.656327543424   529 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.53      0.35      0.42       100
          2       1.00      0.87      0.93        30
          3       0.54      0.63      0.58       100
          4       0.59      0.58      0.59       100
          5       0.80      0.76      0.78       100
          6       0.66      0.65      0.66        88
          7       0.74      0.57      0.64        30
          8       0.59      0.86      0.70        78
          9       0.75      0.88      0.81        80
         10       0.67      0.60      0.63       100

avg / total       0.66      0.66      0.65       806

============================================
Running  28  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:40:51
forest model fit end:  2018-04-14 02:41:37
forest model predict start:  2018-04-14 02:41:37
forest model predict end:  2018-04-14 02:41:37
accuracy:  0.643920595533   519 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.47      0.28      0.35       100
          2       1.00      0.93      0.97        30
          3       0.50      0.61      0.55       100
          4       0.63      0.57      0.60       100
          5       0.80      0.75      0.77       100
          6       0.60      0.59      0.59        88
          7       0.78      0.60      0.68        30
          8       0.61      0.87      0.72        78
          9       0.73      0.90      0.80        80
         10       0.67      0.60      0.63       100

avg / total       0.64      0.64      0.64       806

============================================
Running  29  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:41:38
forest model fit end:  2018-04-14 02:42:24
forest model predict start:  2018-04-14 02:42:24
forest model predict end:  2018-04-14 02:42:24
accuracy:  0.640198511166   516 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.50      0.34      0.40       100
          2       1.00      0.93      0.97        30
          3       0.53      0.62      0.57       100
          4       0.58      0.56      0.57       100
          5       0.81      0.76      0.78       100
          6       0.60      0.51      0.55        88
          7       0.74      0.57      0.64        30
          8       0.56      0.86      0.68        78
          9       0.75      0.86      0.80        80
         10       0.66      0.62      0.64       100

avg / total       0.64      0.64      0.63       806

============================================
Running  30  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:42:24
forest model fit end:  2018-04-14 02:43:11
forest model predict start:  2018-04-14 02:43:11
forest model predict end:  2018-04-14 02:43:11
accuracy:  0.640198511166   516 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.51      0.35      0.41       100
          2       1.00      0.93      0.97        30
          3       0.53      0.62      0.57       100
          4       0.60      0.56      0.58       100
          5       0.78      0.72      0.75       100
          6       0.57      0.53      0.55        88
          7       0.78      0.60      0.68        30
          8       0.58      0.86      0.69        78
          9       0.73      0.86      0.79        80
         10       0.67      0.62      0.65       100

avg / total       0.64      0.64      0.63       806

============================================
Running  31  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:43:11
forest model fit end:  2018-04-14 02:43:57
forest model predict start:  2018-04-14 02:43:57
forest model predict end:  2018-04-14 02:43:57
accuracy:  0.643920595533   519 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.48      0.29      0.36       100
          2       1.00      0.93      0.97        30
          3       0.51      0.64      0.57       100
          4       0.60      0.55      0.58       100
          5       0.79      0.77      0.78       100
          6       0.60      0.59      0.60        88
          7       0.74      0.57      0.64        30
          8       0.61      0.87      0.72        78
          9       0.77      0.86      0.81        80
         10       0.65      0.60      0.62       100

avg / total       0.64      0.64      0.64       806

============================================
Running  32  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:43:58
forest model fit end:  2018-04-14 02:44:44
forest model predict start:  2018-04-14 02:44:44
forest model predict end:  2018-04-14 02:44:44
accuracy:  0.658808933002   531 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.52      0.33      0.40       100
          2       1.00      0.87      0.93        30
          3       0.53      0.61      0.56       100
          4       0.61      0.59      0.60       100
          5       0.81      0.77      0.79       100
          6       0.71      0.68      0.69        88
          7       0.75      0.60      0.67        30
          8       0.59      0.87      0.70        78
          9       0.75      0.86      0.80        80
         10       0.65      0.60      0.62       100

avg / total       0.66      0.66      0.65       806

============================================
Running  33  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:44:44
forest model fit end:  2018-04-14 02:45:31
forest model predict start:  2018-04-14 02:45:31
forest model predict end:  2018-04-14 02:45:31
accuracy:  0.637717121588   514 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.45      0.32      0.37       100
          2       1.00      0.93      0.97        30
          3       0.54      0.64      0.58       100
          4       0.61      0.56      0.58       100
          5       0.77      0.75      0.76       100
          6       0.63      0.50      0.56        88
          7       0.77      0.57      0.65        30
          8       0.56      0.86      0.68        78
          9       0.78      0.89      0.83        80
         10       0.62      0.60      0.61       100

avg / total       0.64      0.64      0.63       806

============================================
Running  34  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:45:31
forest model fit end:  2018-04-14 02:46:17
forest model predict start:  2018-04-14 02:46:17
forest model predict end:  2018-04-14 02:46:17
accuracy:  0.63523573201   512 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.51      0.36      0.42       100
          2       1.00      0.87      0.93        30
          3       0.54      0.63      0.58       100
          4       0.57      0.54      0.55       100
          5       0.74      0.72      0.73       100
          6       0.59      0.53      0.56        88
          7       0.74      0.57      0.64        30
          8       0.59      0.83      0.69        78
          9       0.75      0.90      0.82        80
         10       0.66      0.60      0.63       100

avg / total       0.63      0.64      0.63       806

============================================
Running  35  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:46:17
forest model fit end:  2018-04-14 02:47:03
forest model predict start:  2018-04-14 02:47:03
forest model predict end:  2018-04-14 02:47:03
accuracy:  0.63523573201   512 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.50      0.35      0.41       100
          2       1.00      0.93      0.97        30
          3       0.55      0.63      0.59       100
          4       0.58      0.57      0.58       100
          5       0.81      0.72      0.76       100
          6       0.61      0.52      0.56        88
          7       0.74      0.57      0.64        30
          8       0.54      0.86      0.66        78
          9       0.74      0.88      0.80        80
         10       0.65      0.57      0.61       100

avg / total       0.64      0.64      0.63       806

============================================
Running  36  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:47:04
forest model fit end:  2018-04-14 02:47:49
forest model predict start:  2018-04-14 02:47:49
forest model predict end:  2018-04-14 02:47:50
accuracy:  0.643920595533   519 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.58      0.35      0.44       100
          2       0.96      0.90      0.93        30
          3       0.53      0.63      0.58       100
          4       0.58      0.56      0.57       100
          5       0.79      0.71      0.75       100
          6       0.65      0.62      0.64        88
          7       0.77      0.57      0.65        30
          8       0.57      0.88      0.69        78
          9       0.73      0.86      0.79        80
         10       0.63      0.57      0.60       100

avg / total       0.65      0.64      0.64       806

============================================
Running  37  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:47:50
forest model fit end:  2018-04-14 02:48:36
forest model predict start:  2018-04-14 02:48:36
forest model predict end:  2018-04-14 02:48:36
accuracy:  0.650124069479   524 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.51      0.29      0.37       100
          2       0.97      0.93      0.95        30
          3       0.50      0.68      0.57       100
          4       0.64      0.58      0.61       100
          5       0.80      0.75      0.77       100
          6       0.63      0.59      0.61        88
          7       0.77      0.57      0.65        30
          8       0.58      0.85      0.69        78
          9       0.78      0.88      0.82        80
         10       0.67      0.61      0.64       100

avg / total       0.65      0.65      0.64       806

============================================
Running  38  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:48:36
forest model fit end:  2018-04-14 02:49:22
forest model predict start:  2018-04-14 02:49:22
forest model predict end:  2018-04-14 02:49:22
accuracy:  0.637717121588   514 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.55      0.34      0.42       100
          2       1.00      0.93      0.97        30
          3       0.52      0.62      0.57       100
          4       0.58      0.58      0.58       100
          5       0.78      0.73      0.76       100
          6       0.61      0.53      0.57        88
          7       0.74      0.57      0.64        30
          8       0.57      0.87      0.69        78
          9       0.75      0.88      0.81        80
         10       0.63      0.57      0.60       100

avg / total       0.64      0.64      0.63       806

============================================
Running  39  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:49:22
forest model fit end:  2018-04-14 02:50:08
forest model predict start:  2018-04-14 02:50:08
forest model predict end:  2018-04-14 02:50:09
accuracy:  0.604218362283   487 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.11      0.04      0.06       100
          2       1.00      0.90      0.95        30
          3       0.52      0.63      0.57       100
          4       0.59      0.56      0.57       100
          5       0.81      0.74      0.77       100
          6       0.46      0.57      0.51        88
          7       0.77      0.57      0.65        30
          8       0.58      0.87      0.70        78
          9       0.74      0.88      0.80        80
         10       0.62      0.58      0.60       100

avg / total       0.57      0.60      0.58       806

============================================
Running  40  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:50:09
forest model fit end:  2018-04-14 02:50:55
forest model predict start:  2018-04-14 02:50:55
forest model predict end:  2018-04-14 02:50:55
accuracy:  0.657568238213   530 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.52      0.32      0.40       100
          2       0.96      0.87      0.91        30
          3       0.54      0.62      0.58       100
          4       0.60      0.57      0.58       100
          5       0.81      0.79      0.80       100
          6       0.70      0.66      0.68        88
          7       0.74      0.57      0.64        30
          8       0.58      0.86      0.69        78
          9       0.78      0.88      0.82        80
         10       0.63      0.62      0.63       100

avg / total       0.66      0.66      0.65       806

============================================
Running  41  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:50:55
forest model fit end:  2018-04-14 02:51:41
forest model predict start:  2018-04-14 02:51:41
forest model predict end:  2018-04-14 02:51:41
accuracy:  0.643920595533   519 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.51      0.31      0.39       100
          2       1.00      0.90      0.95        30
          3       0.51      0.63      0.57       100
          4       0.58      0.56      0.57       100
          5       0.76      0.74      0.75       100
          6       0.63      0.61      0.62        88
          7       0.77      0.57      0.65        30
          8       0.58      0.85      0.69        78
          9       0.76      0.88      0.81        80
         10       0.70      0.61      0.65       100

avg / total       0.65      0.64      0.64       806

============================================
Running  42  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:51:41
forest model fit end:  2018-04-14 02:52:27
forest model predict start:  2018-04-14 02:52:27
forest model predict end:  2018-04-14 02:52:27
accuracy:  0.609181141439   491 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.07      0.02      0.03       100
          2       1.00      0.93      0.97        30
          3       0.54      0.62      0.58       100
          4       0.62      0.59      0.61       100
          5       0.81      0.75      0.78       100
          6       0.45      0.58      0.50        88
          7       0.77      0.57      0.65        30
          8       0.56      0.87      0.68        78
          9       0.73      0.88      0.80        80
         10       0.63      0.59      0.61       100

avg / total       0.57      0.61      0.58       806

============================================
Running  43  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:52:28
forest model fit end:  2018-04-14 02:53:14
forest model predict start:  2018-04-14 02:53:14
forest model predict end:  2018-04-14 02:53:14
accuracy:  0.653846153846   527 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.60      0.37      0.46       100
          2       0.97      0.93      0.95        30
          3       0.53      0.61      0.56       100
          4       0.57      0.56      0.57       100
          5       0.80      0.70      0.75       100
          6       0.66      0.69      0.68        88
          7       0.74      0.57      0.64        30
          8       0.58      0.86      0.69        78
          9       0.80      0.88      0.83        80
         10       0.63      0.60      0.62       100

avg / total       0.66      0.65      0.65       806

============================================
Running  44  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:53:14
forest model fit end:  2018-04-14 02:54:00
forest model predict start:  2018-04-14 02:54:00
forest model predict end:  2018-04-14 02:54:01
accuracy:  0.627791563275   506 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.35      0.16      0.22       100
          2       1.00      0.93      0.97        30
          3       0.52      0.65      0.58       100
          4       0.64      0.57      0.60       100
          5       0.80      0.74      0.77       100
          6       0.52      0.57      0.54        88
          7       0.74      0.57      0.64        30
          8       0.59      0.90      0.71        78
          9       0.74      0.86      0.80        80
         10       0.64      0.60      0.62       100

avg / total       0.62      0.63      0.61       806

============================================
Running  45  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:54:01
forest model fit end:  2018-04-14 02:54:46
forest model predict start:  2018-04-14 02:54:46
forest model predict end:  2018-04-14 02:54:47
accuracy:  0.642679900744   518 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.52      0.30      0.38       100
          2       1.00      0.87      0.93        30
          3       0.54      0.65      0.59       100
          4       0.61      0.57      0.59       100
          5       0.80      0.78      0.79       100
          6       0.60      0.55      0.57        88
          7       0.78      0.60      0.68        30
          8       0.58      0.86      0.69        78
          9       0.76      0.86      0.81        80
         10       0.60      0.60      0.60       100

avg / total       0.64      0.64      0.63       806

============================================
Running  46  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:54:47
forest model fit end:  2018-04-14 02:55:33
forest model predict start:  2018-04-14 02:55:33
forest model predict end:  2018-04-14 02:55:33
accuracy:  0.616625310174   497 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.08      0.03      0.04       100
          2       1.00      0.93      0.97        30
          3       0.56      0.64      0.60       100
          4       0.63      0.56      0.59       100
          5       0.80      0.74      0.77       100
          6       0.49      0.64      0.55        88
          7       0.77      0.57      0.65        30
          8       0.59      0.87      0.70        78
          9       0.76      0.89      0.82        80
         10       0.60      0.60      0.60       100

avg / total       0.58      0.62      0.59       806

============================================
Running  47  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:55:33
forest model fit end:  2018-04-14 02:56:19
forest model predict start:  2018-04-14 02:56:19
forest model predict end:  2018-04-14 02:56:20
accuracy:  0.636476426799   513 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.54      0.32      0.40       100
          2       1.00      0.90      0.95        30
          3       0.50      0.64      0.56       100
          4       0.60      0.56      0.58       100
          5       0.77      0.72      0.75       100
          6       0.59      0.57      0.58        88
          7       0.77      0.57      0.65        30
          8       0.58      0.86      0.69        78
          9       0.76      0.88      0.81        80
         10       0.64      0.58      0.61       100

avg / total       0.64      0.64      0.63       806

============================================
Running  48  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:56:20
forest model fit end:  2018-04-14 02:57:05
forest model predict start:  2018-04-14 02:57:05
forest model predict end:  2018-04-14 02:57:06
accuracy:  0.651364764268   525 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.52      0.35      0.42       100
          2       0.96      0.90      0.93        30
          3       0.56      0.65      0.60       100
          4       0.58      0.59      0.59       100
          5       0.82      0.71      0.76       100
          6       0.62      0.60      0.61        88
          7       0.71      0.57      0.63        30
          8       0.58      0.88      0.70        78
          9       0.76      0.88      0.81        80
         10       0.69      0.59      0.63       100

avg / total       0.65      0.65      0.65       806

============================================
Running  49  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:57:06
forest model fit end:  2018-04-14 02:57:51
forest model predict start:  2018-04-14 02:57:51
forest model predict end:  2018-04-14 02:57:52
accuracy:  0.650124069479   524 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.53      0.35      0.42       100
          2       0.93      0.93      0.93        30
          3       0.52      0.64      0.58       100
          4       0.63      0.55      0.59       100
          5       0.81      0.75      0.78       100
          6       0.63      0.61      0.62        88
          7       0.74      0.57      0.64        30
          8       0.59      0.86      0.70        78
          9       0.71      0.86      0.78        80
         10       0.68      0.60      0.64       100

avg / total       0.65      0.65      0.64       806

============================================
Running  50  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:57:52
forest model fit end:  2018-04-14 02:58:37
forest model predict start:  2018-04-14 02:58:37
forest model predict end:  2018-04-14 02:58:37
accuracy:  0.643920595533   519 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.41      0.22      0.29       100
          2       1.00      0.90      0.95        30
          3       0.54      0.63      0.58       100
          4       0.60      0.59      0.59       100
          5       0.81      0.77      0.79       100
          6       0.61      0.68      0.65        88
          7       0.74      0.57      0.64        30
          8       0.60      0.86      0.71        78
          9       0.78      0.86      0.82        80
         10       0.62      0.58      0.60       100

avg / total       0.64      0.64      0.63       806

============================================
[0.64267990074441683, 0.60794044665012403, 0.63027295285359797, 0.65384615384615385, 0.64888337468982626, 0.63399503722084372, 0.65012406947890822, 0.62282878411910669, 0.62531017369727049, 0.65136476426799006, 0.63771712158808935, 0.6364764267990074, 0.64888337468982626, 0.66129032258064513, 0.63275434243176176, 0.6203473945409429, 0.62406947890818854, 0.64888337468982626, 0.62282878411910669, 0.62158808933002485, 0.59925558312655092, 0.6550868486352357, 0.63771712158808935, 0.63027295285359797, 0.62406947890818854, 0.65260545905707201, 0.65632754342431765, 0.64392059553349879, 0.64019851116625315, 0.64019851116625315, 0.64392059553349879, 0.65880893300248144, 0.63771712158808935, 0.63523573200992556, 0.63523573200992556, 0.64392059553349879, 0.65012406947890822, 0.63771712158808935, 0.6042183622828784, 0.65756823821339949, 0.64392059553349879, 0.60918114143920599, 0.65384615384615385, 0.62779156327543428, 0.64267990074441683, 0.61662531017369726, 0.6364764267990074, 0.65136476426799006, 0.65012406947890822, 0.64392059553349879]
Avg accuracy:  0.637642679901
