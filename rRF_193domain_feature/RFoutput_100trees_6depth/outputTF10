Running  1  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:21:28
forest model fit end:  2018-04-14 02:22:17
forest model predict start:  2018-04-14 02:22:17
forest model predict end:  2018-04-14 02:22:17
accuracy:  0.585424133811   490 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.72      0.76      0.74       100
          2       0.88      0.67      0.76        33
          3       0.48      0.77      0.59       100
          4       0.71      0.53      0.61       100
          5       0.37      0.36      0.37       100
          6       0.81      0.68      0.74        93
          7       1.00      0.44      0.61        32
          8       0.51      0.54      0.53        96
          9       0.59      0.36      0.45        83
         10       0.52      0.67      0.59       100

avg / total       0.61      0.59      0.58       837

============================================
Running  2  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:22:17
forest model fit end:  2018-04-14 02:23:06
forest model predict start:  2018-04-14 02:23:06
forest model predict end:  2018-04-14 02:23:06
accuracy:  0.561529271207   470 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.61      0.83      0.70       100
          2       0.79      0.67      0.72        33
          3       0.49      0.82      0.62       100
          4       0.74      0.55      0.63       100
          5       0.32      0.33      0.32       100
          6       0.69      0.35      0.47        93
          7       1.00      0.59      0.75        32
          8       0.55      0.46      0.50        96
          9       0.60      0.37      0.46        83
         10       0.52      0.68      0.59       100

avg / total       0.59      0.56      0.55       837

============================================
Running  3  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:23:06
forest model fit end:  2018-04-14 02:23:55
forest model predict start:  2018-04-14 02:23:55
forest model predict end:  2018-04-14 02:23:56
accuracy:  0.590203106332   494 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.60      0.77      0.68       100
          2       0.85      0.70      0.77        33
          3       0.45      0.81      0.58       100
          4       0.74      0.54      0.62       100
          5       0.45      0.42      0.43       100
          6       0.87      0.42      0.57        93
          7       1.00      0.62      0.77        32
          8       0.69      0.67      0.68        96
          9       0.62      0.37      0.47        83
         10       0.50      0.63      0.56       100

avg / total       0.64      0.59      0.59       837

============================================
Running  4  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:23:56
forest model fit end:  2018-04-14 02:24:46
forest model predict start:  2018-04-14 02:24:46
forest model predict end:  2018-04-14 02:24:46
accuracy:  0.567502986858   475 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.55      0.80      0.65       100
          2       0.79      0.67      0.72        33
          3       0.48      0.80      0.60       100
          4       0.71      0.54      0.61       100
          5       0.43      0.39      0.41       100
          6       0.67      0.26      0.37        93
          7       1.00      0.56      0.72        32
          8       0.62      0.64      0.63        96
          9       0.60      0.37      0.46        83
         10       0.52      0.66      0.58       100

avg / total       0.60      0.57      0.56       837

============================================
Running  5  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:24:46
forest model fit end:  2018-04-14 02:25:38
forest model predict start:  2018-04-14 02:25:38
forest model predict end:  2018-04-14 02:25:38
accuracy:  0.583034647551   488 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.69      0.83      0.75       100
          2       0.79      0.67      0.72        33
          3       0.46      0.79      0.58       100
          4       0.77      0.56      0.65       100
          5       0.36      0.33      0.34       100
          6       0.75      0.48      0.59        93
          7       1.00      0.50      0.67        32
          8       0.56      0.58      0.57        96
          9       0.63      0.37      0.47        83
         10       0.53      0.67      0.59       100

avg / total       0.61      0.58      0.58       837

============================================
Running  6  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:25:38
forest model fit end:  2018-04-14 02:26:27
forest model predict start:  2018-04-14 02:26:27
forest model predict end:  2018-04-14 02:26:28
accuracy:  0.593787335723   497 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.68      0.78      0.73       100
          2       0.79      0.67      0.72        33
          3       0.48      0.78      0.60       100
          4       0.69      0.54      0.61       100
          5       0.40      0.37      0.38       100
          6       0.75      0.54      0.62        93
          7       1.00      0.62      0.77        32
          8       0.64      0.62      0.63        96
          9       0.61      0.36      0.45        83
         10       0.52      0.68      0.59       100

avg / total       0.62      0.59      0.59       837

============================================
Running  7  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:26:28
forest model fit end:  2018-04-14 02:27:17
forest model predict start:  2018-04-14 02:27:17
forest model predict end:  2018-04-14 02:27:17
accuracy:  0.571087216249   478 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.67      0.80      0.73       100
          2       0.81      0.67      0.73        33
          3       0.46      0.81      0.59       100
          4       0.76      0.56      0.64       100
          5       0.33      0.32      0.32       100
          6       0.75      0.46      0.57        93
          7       1.00      0.50      0.67        32
          8       0.55      0.54      0.54        96
          9       0.65      0.37      0.47        83
         10       0.50      0.65      0.57       100

avg / total       0.61      0.57      0.57       837

============================================
Running  8  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:27:17
forest model fit end:  2018-04-14 02:28:06
forest model predict start:  2018-04-14 02:28:06
forest model predict end:  2018-04-14 02:28:07
accuracy:  0.585424133811   490 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.61      0.81      0.70       100
          2       0.92      0.70      0.79        33
          3       0.47      0.83      0.60       100
          4       0.75      0.55      0.64       100
          5       0.41      0.41      0.41       100
          6       0.76      0.38      0.50        93
          7       1.00      0.62      0.77        32
          8       0.65      0.55      0.60        96
          9       0.62      0.39      0.47        83
         10       0.51      0.67      0.58       100

avg / total       0.62      0.59      0.58       837

============================================
Running  9  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:28:07
forest model fit end:  2018-04-14 02:28:56
forest model predict start:  2018-04-14 02:28:56
forest model predict end:  2018-04-14 02:28:56
accuracy:  0.572281959379   479 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.73      0.78      0.75       100
          2       0.79      0.67      0.72        33
          3       0.41      0.79      0.54       100
          4       0.72      0.55      0.63       100
          5       0.36      0.33      0.34       100
          6       0.76      0.41      0.53        93
          7       1.00      0.59      0.75        32
          8       0.58      0.56      0.57        96
          9       0.64      0.39      0.48        83
         10       0.53      0.69      0.60       100

avg / total       0.61      0.57      0.57       837

============================================
Running  10  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:28:56
forest model fit end:  2018-04-14 02:29:44
forest model predict start:  2018-04-14 02:29:44
forest model predict end:  2018-04-14 02:29:45
accuracy:  0.572281959379   479 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.65      0.83      0.73       100
          2       0.92      0.70      0.79        33
          3       0.44      0.81      0.57       100
          4       0.73      0.55      0.63       100
          5       0.38      0.34      0.36       100
          6       0.67      0.34      0.45        93
          7       1.00      0.59      0.75        32
          8       0.60      0.55      0.57        96
          9       0.62      0.37      0.47        83
         10       0.53      0.68      0.59       100

avg / total       0.60      0.57      0.57       837

============================================
Running  11  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:29:45
forest model fit end:  2018-04-14 02:30:33
forest model predict start:  2018-04-14 02:30:33
forest model predict end:  2018-04-14 02:30:33
accuracy:  0.57825567503   484 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.61      0.75      0.67       100
          2       0.79      0.67      0.72        33
          3       0.45      0.80      0.58       100
          4       0.72      0.53      0.61       100
          5       0.41      0.36      0.38       100
          6       0.86      0.39      0.53        93
          7       1.00      0.56      0.72        32
          8       0.60      0.69      0.64        96
          9       0.62      0.36      0.46        83
         10       0.53      0.68      0.59       100

avg / total       0.62      0.58      0.57       837

============================================
Running  12  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:30:33
forest model fit end:  2018-04-14 02:31:22
forest model predict start:  2018-04-14 02:31:22
forest model predict end:  2018-04-14 02:31:22
accuracy:  0.594982078853   498 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.71      0.83      0.76       100
          2       0.79      0.70      0.74        33
          3       0.48      0.80      0.60       100
          4       0.75      0.54      0.63       100
          5       0.37      0.38      0.38       100
          6       0.80      0.57      0.67        93
          7       1.00      0.56      0.72        32
          8       0.58      0.52      0.55        96
          9       0.64      0.39      0.48        83
         10       0.52      0.67      0.58       100

avg / total       0.63      0.59      0.59       837

============================================
Running  13  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:31:22
forest model fit end:  2018-04-14 02:32:10
forest model predict start:  2018-04-14 02:32:10
forest model predict end:  2018-04-14 02:32:11
accuracy:  0.604540023895   506 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.72      0.79      0.76       100
          2       0.83      0.73      0.77        33
          3       0.47      0.80      0.59       100
          4       0.78      0.53      0.63       100
          5       0.41      0.42      0.42       100
          6       0.78      0.57      0.66        93
          7       1.00      0.59      0.75        32
          8       0.58      0.56      0.57        96
          9       0.61      0.37      0.46        83
         10       0.55      0.71      0.62       100

avg / total       0.64      0.60      0.60       837

============================================
Running  14  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:32:11
forest model fit end:  2018-04-14 02:32:59
forest model predict start:  2018-04-14 02:32:59
forest model predict end:  2018-04-14 02:32:59
accuracy:  0.605734767025   507 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.71      0.84      0.77       100
          2       0.79      0.70      0.74        33
          3       0.49      0.78      0.60       100
          4       0.74      0.55      0.63       100
          5       0.37      0.38      0.38       100
          6       0.80      0.65      0.71        93
          7       1.00      0.59      0.75        32
          8       0.65      0.54      0.59        96
          9       0.61      0.37      0.46        83
         10       0.51      0.67      0.58       100

avg / total       0.63      0.61      0.60       837

============================================
Running  15  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:32:59
forest model fit end:  2018-04-14 02:33:47
forest model predict start:  2018-04-14 02:33:47
forest model predict end:  2018-04-14 02:33:48
accuracy:  0.610513739546   511 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.75      0.79      0.77       100
          2       0.79      0.67      0.72        33
          3       0.48      0.80      0.60       100
          4       0.75      0.55      0.64       100
          5       0.38      0.34      0.36       100
          6       0.83      0.73      0.78        93
          7       1.00      0.59      0.75        32
          8       0.60      0.58      0.59        96
          9       0.62      0.37      0.47        83
         10       0.52      0.67      0.59       100

avg / total       0.64      0.61      0.61       837

============================================
Running  16  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:33:48
forest model fit end:  2018-04-14 02:34:36
forest model predict start:  2018-04-14 02:34:36
forest model predict end:  2018-04-14 02:34:36
accuracy:  0.603345280765   505 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.75      0.77      0.76       100
          2       0.88      0.67      0.76        33
          3       0.47      0.78      0.58       100
          4       0.78      0.54      0.64       100
          5       0.39      0.39      0.39       100
          6       0.80      0.69      0.74        93
          7       1.00      0.59      0.75        32
          8       0.62      0.55      0.58        96
          9       0.60      0.39      0.47        83
         10       0.50      0.67      0.57       100

avg / total       0.64      0.60      0.61       837

============================================
Running  17  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:34:36
forest model fit end:  2018-04-14 02:35:24
forest model predict start:  2018-04-14 02:35:24
forest model predict end:  2018-04-14 02:35:25
accuracy:  0.592592592593   496 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.70      0.83      0.76       100
          2       0.88      0.67      0.76        33
          3       0.48      0.78      0.59       100
          4       0.75      0.54      0.63       100
          5       0.38      0.37      0.37       100
          6       0.80      0.60      0.69        93
          7       1.00      0.47      0.64        32
          8       0.54      0.52      0.53        96
          9       0.61      0.37      0.46        83
         10       0.53      0.70      0.60       100

avg / total       0.62      0.59      0.59       837

============================================
Running  18  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:35:25
forest model fit end:  2018-04-14 02:36:13
forest model predict start:  2018-04-14 02:36:13
forest model predict end:  2018-04-14 02:36:13
accuracy:  0.593787335723   497 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.70      0.83      0.76       100
          2       0.79      0.67      0.72        33
          3       0.47      0.78      0.59       100
          4       0.79      0.55      0.65       100
          5       0.38      0.40      0.39       100
          6       0.77      0.55      0.64        93
          7       1.00      0.56      0.72        32
          8       0.60      0.52      0.56        96
          9       0.60      0.37      0.46        83
         10       0.52      0.69      0.59       100

avg / total       0.63      0.59      0.59       837

============================================
Running  19  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:36:13
forest model fit end:  2018-04-14 02:37:02
forest model predict start:  2018-04-14 02:37:02
forest model predict end:  2018-04-14 02:37:02
accuracy:  0.5770609319   483 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.69      0.83      0.75       100
          2       0.79      0.67      0.72        33
          3       0.43      0.80      0.56       100
          4       0.75      0.54      0.63       100
          5       0.39      0.41      0.40       100
          6       0.69      0.39      0.50        93
          7       1.00      0.56      0.72        32
          8       0.60      0.53      0.56        96
          9       0.62      0.37      0.47        83
         10       0.55      0.67      0.61       100

avg / total       0.61      0.58      0.57       837

============================================
Running  20  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:37:02
forest model fit end:  2018-04-14 02:37:50
forest model predict start:  2018-04-14 02:37:50
forest model predict end:  2018-04-14 02:37:50
accuracy:  0.605734767025   507 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.75      0.80      0.77       100
          2       0.76      0.67      0.71        33
          3       0.48      0.79      0.60       100
          4       0.73      0.56      0.63       100
          5       0.39      0.35      0.37       100
          6       0.81      0.66      0.73        93
          7       1.00      0.50      0.67        32
          8       0.58      0.62      0.60        96
          9       0.63      0.37      0.47        83
         10       0.53      0.67      0.59       100

avg / total       0.63      0.61      0.60       837

============================================
Running  21  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:37:50
forest model fit end:  2018-04-14 02:38:41
forest model predict start:  2018-04-14 02:38:41
forest model predict end:  2018-04-14 02:38:41
accuracy:  0.575866188769   482 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.69      0.82      0.75       100
          2       0.79      0.67      0.72        33
          3       0.45      0.77      0.57       100
          4       0.70      0.54      0.61       100
          5       0.36      0.38      0.37       100
          6       0.75      0.45      0.56        93
          7       1.00      0.59      0.75        32
          8       0.61      0.52      0.56        96
          9       0.62      0.37      0.47        83
         10       0.52      0.67      0.59       100

avg / total       0.61      0.58      0.57       837

============================================
Running  22  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:38:41
forest model fit end:  2018-04-14 02:39:31
forest model predict start:  2018-04-14 02:39:31
forest model predict end:  2018-04-14 02:39:31
accuracy:  0.583034647551   488 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.77      0.78      0.78       100
          2       0.85      0.67      0.75        33
          3       0.45      0.82      0.58       100
          4       0.71      0.54      0.61       100
          5       0.33      0.30      0.31       100
          6       0.82      0.58      0.68        93
          7       1.00      0.53      0.69        32
          8       0.53      0.56      0.55        96
          9       0.62      0.37      0.47        83
         10       0.52      0.66      0.58       100

avg / total       0.62      0.58      0.58       837

============================================
Running  23  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:39:31
forest model fit end:  2018-04-14 02:40:20
forest model predict start:  2018-04-14 02:40:20
forest model predict end:  2018-04-14 02:40:20
accuracy:  0.57825567503   484 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.70      0.72      0.71       100
          2       0.79      0.70      0.74        33
          3       0.47      0.80      0.59       100
          4       0.71      0.55      0.62       100
          5       0.36      0.35      0.36       100
          6       0.77      0.58      0.66        93
          7       1.00      0.53      0.69        32
          8       0.56      0.55      0.55        96
          9       0.61      0.37      0.46        83
         10       0.50      0.64      0.56       100

avg / total       0.61      0.58      0.58       837

============================================
Running  24  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:40:21
forest model fit end:  2018-04-14 02:41:12
forest model predict start:  2018-04-14 02:41:12
forest model predict end:  2018-04-14 02:41:12
accuracy:  0.602150537634   504 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.76      0.75      0.75       100
          2       0.79      0.67      0.72        33
          3       0.48      0.81      0.60       100
          4       0.76      0.54      0.63       100
          5       0.37      0.37      0.37       100
          6       0.83      0.72      0.77        93
          7       1.00      0.53      0.69        32
          8       0.59      0.56      0.58        96
          9       0.62      0.37      0.47        83
         10       0.50      0.66      0.57       100

avg / total       0.63      0.60      0.60       837

============================================
Running  25  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:41:12
forest model fit end:  2018-04-14 02:42:01
forest model predict start:  2018-04-14 02:42:01
forest model predict end:  2018-04-14 02:42:01
accuracy:  0.591397849462   495 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.66      0.73      0.70       100
          2       0.79      0.70      0.74        33
          3       0.48      0.78      0.59       100
          4       0.72      0.55      0.63       100
          5       0.43      0.43      0.43       100
          6       0.77      0.53      0.62        93
          7       1.00      0.66      0.79        32
          8       0.58      0.55      0.57        96
          9       0.64      0.39      0.48        83
         10       0.51      0.68      0.58       100

avg / total       0.62      0.59      0.59       837

============================================
Running  26  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:42:02
forest model fit end:  2018-04-14 02:42:51
forest model predict start:  2018-04-14 02:42:51
forest model predict end:  2018-04-14 02:42:51
accuracy:  0.555555555556   465 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.75      0.69      0.72       100
          2       0.79      0.67      0.72        33
          3       0.41      0.79      0.54       100
          4       0.72      0.54      0.62       100
          5       0.37      0.38      0.38       100
          6       0.71      0.40      0.51        93
          7       0.94      0.53      0.68        32
          8       0.57      0.52      0.54        96
          9       0.58      0.36      0.44        83
         10       0.51      0.69      0.58       100

avg / total       0.60      0.56      0.56       837

============================================
Running  27  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:42:51
forest model fit end:  2018-04-14 02:43:40
forest model predict start:  2018-04-14 02:43:40
forest model predict end:  2018-04-14 02:43:41
accuracy:  0.624850657109   523 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.73      0.80      0.76       100
          2       0.81      0.67      0.73        33
          3       0.49      0.81      0.61       100
          4       0.74      0.53      0.62       100
          5       0.47      0.40      0.43       100
          6       0.79      0.69      0.74        93
          7       1.00      0.56      0.72        32
          8       0.69      0.71      0.70        96
          9       0.62      0.37      0.47        83
         10       0.50      0.66      0.57       100

avg / total       0.65      0.62      0.62       837

============================================
Running  28  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:43:41
forest model fit end:  2018-04-14 02:44:29
forest model predict start:  2018-04-14 02:44:29
forest model predict end:  2018-04-14 02:44:29
accuracy:  0.593787335723   497 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.72      0.78      0.75       100
          2       0.79      0.67      0.72        33
          3       0.46      0.80      0.59       100
          4       0.73      0.54      0.62       100
          5       0.41      0.37      0.39       100
          6       0.76      0.51      0.61        93
          7       1.00      0.59      0.75        32
          8       0.61      0.61      0.61        96
          9       0.61      0.37      0.46        83
         10       0.53      0.70      0.60       100

avg / total       0.62      0.59      0.59       837

============================================
Running  29  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:44:29
forest model fit end:  2018-04-14 02:45:17
forest model predict start:  2018-04-14 02:45:17
forest model predict end:  2018-04-14 02:45:18
accuracy:  0.5770609319   483 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.64      0.82      0.72       100
          2       0.86      0.73      0.79        33
          3       0.48      0.81      0.60       100
          4       0.73      0.54      0.62       100
          5       0.37      0.39      0.38       100
          6       0.73      0.43      0.54        93
          7       1.00      0.59      0.75        32
          8       0.60      0.48      0.53        96
          9       0.61      0.37      0.46        83
         10       0.52      0.67      0.59       100

avg / total       0.61      0.58      0.57       837

============================================
Running  30  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:45:18
forest model fit end:  2018-04-14 02:46:06
forest model predict start:  2018-04-14 02:46:06
forest model predict end:  2018-04-14 02:46:06
accuracy:  0.568697729988   476 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.57      0.77      0.66       100
          2       0.89      0.73      0.80        33
          3       0.49      0.79      0.61       100
          4       0.73      0.55      0.63       100
          5       0.36      0.33      0.34       100
          6       0.69      0.38      0.49        93
          7       1.00      0.59      0.75        32
          8       0.57      0.57      0.57        96
          9       0.60      0.37      0.46        83
         10       0.52      0.68      0.59       100

avg / total       0.59      0.57      0.56       837

============================================
Running  31  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:46:06
forest model fit end:  2018-04-14 02:46:54
forest model predict start:  2018-04-14 02:46:54
forest model predict end:  2018-04-14 02:46:54
accuracy:  0.57945041816   485 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.65      0.82      0.72       100
          2       0.81      0.67      0.73        33
          3       0.46      0.78      0.58       100
          4       0.72      0.55      0.63       100
          5       0.40      0.41      0.40       100
          6       0.71      0.42      0.53        93
          7       1.00      0.59      0.75        32
          8       0.65      0.55      0.60        96
          9       0.62      0.37      0.47        83
         10       0.51      0.65      0.57       100

avg / total       0.61      0.58      0.58       837

============================================
Running  32  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:46:54
forest model fit end:  2018-04-14 02:47:43
forest model predict start:  2018-04-14 02:47:43
forest model predict end:  2018-04-14 02:47:43
accuracy:  0.571087216249   478 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.59      0.78      0.67       100
          2       0.85      0.67      0.75        33
          3       0.49      0.80      0.61       100
          4       0.74      0.54      0.62       100
          5       0.38      0.33      0.35       100
          6       0.69      0.40      0.50        93
          7       1.00      0.53      0.69        32
          8       0.57      0.62      0.60        96
          9       0.60      0.36      0.45        83
         10       0.51      0.67      0.58       100

avg / total       0.60      0.57      0.56       837

============================================
Running  33  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:47:43
forest model fit end:  2018-04-14 02:48:31
forest model predict start:  2018-04-14 02:48:31
forest model predict end:  2018-04-14 02:48:32
accuracy:  0.608124253286   509 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.76      0.77      0.77       100
          2       0.79      0.70      0.74        33
          3       0.49      0.80      0.61       100
          4       0.75      0.54      0.63       100
          5       0.40      0.40      0.40       100
          6       0.83      0.70      0.76        93
          7       1.00      0.59      0.75        32
          8       0.58      0.53      0.55        96
          9       0.58      0.36      0.44        83
         10       0.52      0.70      0.60       100

avg / total       0.63      0.61      0.61       837

============================================
Running  34  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:48:32
forest model fit end:  2018-04-14 02:49:20
forest model predict start:  2018-04-14 02:49:20
forest model predict end:  2018-04-14 02:49:20
accuracy:  0.617682198327   517 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.75      0.80      0.78       100
          2       0.77      0.70      0.73        33
          3       0.48      0.80      0.60       100
          4       0.74      0.54      0.62       100
          5       0.44      0.41      0.42       100
          6       0.79      0.67      0.73        93
          7       1.00      0.62      0.77        32
          8       0.65      0.62      0.64        96
          9       0.62      0.36      0.46        83
         10       0.51      0.67      0.58       100

avg / total       0.64      0.62      0.62       837

============================================
Running  35  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:49:20
forest model fit end:  2018-04-14 02:50:08
forest model predict start:  2018-04-14 02:50:08
forest model predict end:  2018-04-14 02:50:08
accuracy:  0.621266427718   520 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.79      0.77      0.78       100
          2       0.85      0.67      0.75        33
          3       0.49      0.80      0.61       100
          4       0.74      0.55      0.63       100
          5       0.42      0.43      0.43       100
          6       0.85      0.72      0.78        93
          7       1.00      0.59      0.75        32
          8       0.62      0.58      0.60        96
          9       0.61      0.36      0.45        83
         10       0.52      0.71      0.60       100

avg / total       0.65      0.62      0.62       837

============================================
Running  36  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:50:08
forest model fit end:  2018-04-14 02:50:56
forest model predict start:  2018-04-14 02:50:56
forest model predict end:  2018-04-14 02:50:57
accuracy:  0.587813620072   492 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.61      0.77      0.68       100
          2       0.79      0.67      0.72        33
          3       0.48      0.81      0.60       100
          4       0.67      0.56      0.61       100
          5       0.46      0.46      0.46       100
          6       0.68      0.37      0.48        93
          7       1.00      0.59      0.75        32
          8       0.69      0.58      0.63        96
          9       0.63      0.37      0.47        83
         10       0.53      0.70      0.60       100

avg / total       0.62      0.59      0.58       837

============================================
Running  37  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:50:57
forest model fit end:  2018-04-14 02:51:46
forest model predict start:  2018-04-14 02:51:46
forest model predict end:  2018-04-14 02:51:46
accuracy:  0.560334528076   469 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.55      0.67      0.60       100
          2       0.89      0.73      0.80        33
          3       0.49      0.82      0.61       100
          4       0.74      0.55      0.63       100
          5       0.40      0.40      0.40       100
          6       0.62      0.40      0.48        93
          7       0.95      0.59      0.73        32
          8       0.54      0.51      0.52        96
          9       0.64      0.39      0.48        83
         10       0.52      0.64      0.57       100

avg / total       0.59      0.56      0.56       837

============================================
Running  38  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:51:46
forest model fit end:  2018-04-14 02:52:35
forest model predict start:  2018-04-14 02:52:35
forest model predict end:  2018-04-14 02:52:35
accuracy:  0.573476702509   480 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.60      0.77      0.68       100
          2       0.79      0.67      0.72        33
          3       0.49      0.80      0.61       100
          4       0.75      0.54      0.63       100
          5       0.41      0.42      0.42       100
          6       0.69      0.40      0.50        93
          7       1.00      0.59      0.75        32
          8       0.59      0.54      0.57        96
          9       0.61      0.36      0.45        83
         10       0.50      0.67      0.57       100

avg / total       0.60      0.57      0.57       837

============================================
Running  39  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:52:35
forest model fit end:  2018-04-14 02:53:23
forest model predict start:  2018-04-14 02:53:23
forest model predict end:  2018-04-14 02:53:24
accuracy:  0.615292712067   515 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.69      0.81      0.75       100
          2       0.79      0.67      0.72        33
          3       0.49      0.80      0.61       100
          4       0.74      0.53      0.62       100
          5       0.46      0.44      0.45       100
          6       0.81      0.62      0.70        93
          7       1.00      0.59      0.75        32
          8       0.68      0.66      0.67        96
          9       0.61      0.37      0.46        83
         10       0.50      0.64      0.56       100

avg / total       0.64      0.62      0.61       837

============================================
Running  40  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:53:24
forest model fit end:  2018-04-14 02:54:12
forest model predict start:  2018-04-14 02:54:12
forest model predict end:  2018-04-14 02:54:12
accuracy:  0.571087216249   478 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.61      0.80      0.69       100
          2       0.88      0.70      0.78        33
          3       0.46      0.78      0.58       100
          4       0.71      0.56      0.63       100
          5       0.42      0.44      0.43       100
          6       0.61      0.29      0.39        93
          7       1.00      0.53      0.69        32
          8       0.59      0.53      0.56        96
          9       0.61      0.37      0.46        83
         10       0.55      0.71      0.62       100

avg / total       0.60      0.57      0.56       837

============================================
Running  41  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:54:12
forest model fit end:  2018-04-14 02:55:00
forest model predict start:  2018-04-14 02:55:00
forest model predict end:  2018-04-14 02:55:01
accuracy:  0.590203106332   494 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.75      0.78      0.76       100
          2       0.88      0.67      0.76        33
          3       0.49      0.81      0.61       100
          4       0.68      0.54      0.60       100
          5       0.36      0.38      0.37       100
          6       0.73      0.66      0.69        93
          7       1.00      0.50      0.67        32
          8       0.59      0.51      0.55        96
          9       0.62      0.39      0.47        83
         10       0.50      0.63      0.56       100

avg / total       0.62      0.59      0.59       837

============================================
Running  42  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:55:01
forest model fit end:  2018-04-14 02:55:49
forest model predict start:  2018-04-14 02:55:49
forest model predict end:  2018-04-14 02:55:49
accuracy:  0.567502986858   475 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.64      0.83      0.72       100
          2       0.79      0.67      0.72        33
          3       0.46      0.80      0.58       100
          4       0.75      0.53      0.62       100
          5       0.38      0.41      0.39       100
          6       0.73      0.38      0.50        93
          7       1.00      0.59      0.75        32
          8       0.54      0.48      0.51        96
          9       0.61      0.37      0.46        83
         10       0.53      0.65      0.59       100

avg / total       0.60      0.57      0.56       837

============================================
Running  43  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:55:49
forest model fit end:  2018-04-14 02:56:38
forest model predict start:  2018-04-14 02:56:38
forest model predict end:  2018-04-14 02:56:38
accuracy:  0.605734767025   507 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.75      0.82      0.78       100
          2       0.81      0.67      0.73        33
          3       0.46      0.81      0.59       100
          4       0.75      0.53      0.62       100
          5       0.41      0.45      0.43       100
          6       0.85      0.59      0.70        93
          7       1.00      0.56      0.72        32
          8       0.69      0.55      0.61        96
          9       0.61      0.37      0.46        83
         10       0.50      0.67      0.57       100

avg / total       0.65      0.61      0.61       837

============================================
Running  44  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:56:38
forest model fit end:  2018-04-14 02:57:27
forest model predict start:  2018-04-14 02:57:27
forest model predict end:  2018-04-14 02:57:27
accuracy:  0.568697729988   476 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.63      0.78      0.70       100
          2       0.88      0.67      0.76        33
          3       0.47      0.80      0.59       100
          4       0.70      0.54      0.61       100
          5       0.36      0.36      0.36       100
          6       0.75      0.39      0.51        93
          7       1.00      0.59      0.75        32
          8       0.57      0.54      0.56        96
          9       0.62      0.37      0.47        83
         10       0.51      0.68      0.58       100

avg / total       0.60      0.57      0.56       837

============================================
Running  45  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:57:27
forest model fit end:  2018-04-14 02:58:16
forest model predict start:  2018-04-14 02:58:16
forest model predict end:  2018-04-14 02:58:16
accuracy:  0.614097968937   514 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.70      0.78      0.74       100
          2       0.83      0.73      0.77        33
          3       0.48      0.81      0.60       100
          4       0.73      0.55      0.63       100
          5       0.48      0.44      0.46       100
          6       0.73      0.56      0.63        93
          7       1.00      0.56      0.72        32
          8       0.67      0.67      0.67        96
          9       0.64      0.36      0.46        83
         10       0.53      0.68      0.60       100

avg / total       0.64      0.61      0.61       837

============================================
Running  46  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:58:16
forest model fit end:  2018-04-14 02:59:05
forest model predict start:  2018-04-14 02:59:05
forest model predict end:  2018-04-14 02:59:05
accuracy:  0.604540023895   506 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.70      0.70      0.70       100
          2       0.79      0.67      0.72        33
          3       0.51      0.80      0.62       100
          4       0.71      0.54      0.61       100
          5       0.43      0.37      0.40       100
          6       0.74      0.65      0.69        93
          7       1.00      0.59      0.75        32
          8       0.62      0.68      0.65        96
          9       0.61      0.37      0.46        83
         10       0.51      0.68      0.58       100

avg / total       0.62      0.60      0.60       837

============================================
Running  47  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:59:05
forest model fit end:  2018-04-14 02:59:53
forest model predict start:  2018-04-14 02:59:53
forest model predict end:  2018-04-14 02:59:53
accuracy:  0.590203106332   494 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.70      0.73      0.71       100
          2       0.79      0.70      0.74        33
          3       0.45      0.81      0.57       100
          4       0.74      0.54      0.62       100
          5       0.39      0.39      0.39       100
          6       0.81      0.55      0.65        93
          7       1.00      0.59      0.75        32
          8       0.59      0.57      0.58        96
          9       0.63      0.37      0.47        83
         10       0.54      0.68      0.60       100

avg / total       0.63      0.59      0.59       837

============================================
Running  48  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:59:53
forest model fit end:  2018-04-14 03:00:41
forest model predict start:  2018-04-14 03:00:41
forest model predict end:  2018-04-14 03:00:41
accuracy:  0.592592592593   496 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.67      0.76      0.71       100
          2       0.79      0.67      0.72        33
          3       0.50      0.79      0.61       100
          4       0.75      0.56      0.64       100
          5       0.42      0.43      0.42       100
          6       0.72      0.53      0.61        93
          7       1.00      0.59      0.75        32
          8       0.61      0.57      0.59        96
          9       0.61      0.37      0.46        83
         10       0.51      0.66      0.57       100

avg / total       0.62      0.59      0.59       837

============================================
Running  49  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 03:00:41
forest model fit end:  2018-04-14 03:01:28
forest model predict start:  2018-04-14 03:01:28
forest model predict end:  2018-04-14 03:01:28
accuracy:  0.609318996416   510 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.76      0.81      0.78       100
          2       0.79      0.67      0.72        33
          3       0.47      0.78      0.59       100
          4       0.75      0.55      0.64       100
          5       0.38      0.36      0.37       100
          6       0.81      0.67      0.73        93
          7       1.00      0.62      0.77        32
          8       0.57      0.57      0.57        96
          9       0.65      0.40      0.49        83
         10       0.54      0.68      0.60       100

avg / total       0.64      0.61      0.61       837

============================================
Running  50  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 03:01:28
forest model fit end:  2018-04-14 03:02:16
forest model predict start:  2018-04-14 03:02:16
forest model predict end:  2018-04-14 03:02:16
accuracy:  0.598566308244   501 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.78      0.73      0.76       100
          2       0.88      0.70      0.78        33
          3       0.48      0.80      0.60       100
          4       0.71      0.55      0.62       100
          5       0.37      0.35      0.36       100
          6       0.77      0.67      0.71        93
          7       1.00      0.62      0.77        32
          8       0.60      0.58      0.59        96
          9       0.58      0.36      0.44        83
         10       0.50      0.67      0.58       100

avg / total       0.62      0.60      0.60       837

============================================
[0.5854241338112306, 0.56152927120669061, 0.59020310633213857, 0.56750298685782552, 0.58303464755077661, 0.59378733572281961, 0.57108721624850656, 0.5854241338112306, 0.57228195937873361, 0.57228195937873361, 0.57825567502986863, 0.59498207885304655, 0.60454002389486261, 0.60573476702508966, 0.61051373954599764, 0.60334528076463556, 0.59259259259259256, 0.59378733572281961, 0.57706093189964158, 0.60573476702508966, 0.57586618876941453, 0.58303464755077661, 0.57825567502986863, 0.60215053763440862, 0.59139784946236562, 0.55555555555555558, 0.62485065710872167, 0.59378733572281961, 0.57706093189964158, 0.56869772998805257, 0.57945041816009557, 0.57108721624850656, 0.60812425328554365, 0.6176821983273596, 0.62126642771804064, 0.58781362007168458, 0.56033452807646356, 0.57347670250896055, 0.61529271206690561, 0.57108721624850656, 0.59020310633213857, 0.56750298685782552, 0.60573476702508966, 0.56869772998805257, 0.61409796893667856, 0.60454002389486261, 0.59020310633213857, 0.59259259259259256, 0.60931899641577059, 0.59856630824372759]
Avg accuracy:  0.588936678614
