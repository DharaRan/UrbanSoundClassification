Running  1  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:20:28
forest model fit end:  2018-04-14 02:21:17
forest model predict start:  2018-04-14 02:21:17
forest model predict end:  2018-04-14 02:21:17
accuracy:  0.647642679901   522 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.48      0.34      0.40       100
          2       1.00      0.90      0.95        30
          3       0.52      0.65      0.58       100
          4       0.61      0.55      0.58       100
          5       0.79      0.76      0.78       100
          6       0.66      0.60      0.63        88
          7       0.77      0.57      0.65        30
          8       0.57      0.86      0.68        78
          9       0.75      0.86      0.80        80
         10       0.69      0.59      0.63       100

avg / total       0.65      0.65      0.64       806

============================================
Running  2  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:21:17
forest model fit end:  2018-04-14 02:22:07
forest model predict start:  2018-04-14 02:22:07
forest model predict end:  2018-04-14 02:22:07
accuracy:  0.642679900744   518 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.55      0.35      0.43       100
          2       1.00      0.93      0.97        30
          3       0.53      0.64      0.58       100
          4       0.57      0.56      0.57       100
          5       0.79      0.74      0.76       100
          6       0.60      0.52      0.56        88
          7       0.77      0.57      0.65        30
          8       0.59      0.87      0.70        78
          9       0.74      0.86      0.80        80
         10       0.64      0.61      0.63       100

avg / total       0.64      0.64      0.64       806

============================================
Running  3  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:22:07
forest model fit end:  2018-04-14 02:22:56
forest model predict start:  2018-04-14 02:22:56
forest model predict end:  2018-04-14 02:22:57
accuracy:  0.660049627792   532 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.57      0.35      0.43       100
          2       1.00      0.90      0.95        30
          3       0.52      0.59      0.55       100
          4       0.60      0.57      0.58       100
          5       0.80      0.76      0.78       100
          6       0.67      0.68      0.67        88
          7       0.77      0.57      0.65        30
          8       0.59      0.87      0.70        78
          9       0.74      0.88      0.80        80
         10       0.68      0.63      0.65       100

avg / total       0.66      0.66      0.65       806

============================================
Running  4  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:22:57
forest model fit end:  2018-04-14 02:23:46
forest model predict start:  2018-04-14 02:23:46
forest model predict end:  2018-04-14 02:23:46
accuracy:  0.600496277916   484 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.11      0.04      0.06       100
          2       1.00      0.90      0.95        30
          3       0.55      0.64      0.59       100
          4       0.59      0.55      0.57       100
          5       0.76      0.74      0.75       100
          6       0.45      0.58      0.50        88
          7       0.77      0.57      0.65        30
          8       0.57      0.85      0.68        78
          9       0.76      0.85      0.80        80
         10       0.62      0.58      0.60       100

avg / total       0.57      0.60      0.58       806

============================================
Running  5  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:23:46
forest model fit end:  2018-04-14 02:24:36
forest model predict start:  2018-04-14 02:24:36
forest model predict end:  2018-04-14 02:24:37
accuracy:  0.63523573201   512 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.44      0.31      0.36       100
          2       1.00      0.93      0.97        30
          3       0.55      0.66      0.60       100
          4       0.64      0.58      0.61       100
          5       0.79      0.74      0.76       100
          6       0.59      0.49      0.53        88
          7       0.78      0.60      0.68        30
          8       0.56      0.87      0.68        78
          9       0.72      0.88      0.79        80
         10       0.62      0.56      0.59       100

avg / total       0.63      0.64      0.63       806

============================================
Running  6  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:24:37
forest model fit end:  2018-04-14 02:25:25
forest model predict start:  2018-04-14 02:25:25
forest model predict end:  2018-04-14 02:25:25
accuracy:  0.650124069479   524 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.52      0.33      0.40       100
          2       1.00      0.97      0.98        30
          3       0.53      0.67      0.59       100
          4       0.64      0.56      0.60       100
          5       0.79      0.76      0.78       100
          6       0.65      0.60      0.62        88
          7       0.77      0.57      0.65        30
          8       0.59      0.86      0.70        78
          9       0.71      0.85      0.77        80
         10       0.65      0.58      0.61       100

avg / total       0.65      0.65      0.64       806

============================================
Running  7  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:25:26
forest model fit end:  2018-04-14 02:26:14
forest model predict start:  2018-04-14 02:26:14
forest model predict end:  2018-04-14 02:26:14
accuracy:  0.638957816377   515 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.51      0.25      0.34       100
          2       1.00      0.93      0.97        30
          3       0.50      0.63      0.56       100
          4       0.58      0.58      0.58       100
          5       0.80      0.71      0.75       100
          6       0.64      0.65      0.64        88
          7       0.74      0.57      0.64        30
          8       0.58      0.90      0.70        78
          9       0.74      0.86      0.80        80
         10       0.65      0.57      0.61       100

avg / total       0.64      0.64      0.63       806

============================================
Running  8  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:26:14
forest model fit end:  2018-04-14 02:27:03
forest model predict start:  2018-04-14 02:27:03
forest model predict end:  2018-04-14 02:27:03
accuracy:  0.60794044665   490 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.07      0.03      0.04       100
          2       1.00      0.87      0.93        30
          3       0.54      0.65      0.59       100
          4       0.62      0.56      0.59       100
          5       0.80      0.78      0.79       100
          6       0.47      0.52      0.49        88
          7       0.74      0.57      0.64        30
          8       0.56      0.86      0.68        78
          9       0.77      0.88      0.82        80
         10       0.61      0.62      0.62       100

avg / total       0.58      0.61      0.59       806

============================================
Running  9  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:27:03
forest model fit end:  2018-04-14 02:27:52
forest model predict start:  2018-04-14 02:27:52
forest model predict end:  2018-04-14 02:27:52
accuracy:  0.617866004963   498 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.35      0.15      0.21       100
          2       1.00      0.90      0.95        30
          3       0.51      0.62      0.56       100
          4       0.60      0.53      0.56       100
          5       0.76      0.74      0.75       100
          6       0.49      0.58      0.53        88
          7       0.77      0.57      0.65        30
          8       0.60      0.87      0.71        78
          9       0.75      0.88      0.81        80
         10       0.65      0.61      0.63       100

avg / total       0.61      0.62      0.60       806

============================================
Running  10  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:27:52
forest model fit end:  2018-04-14 02:28:40
forest model predict start:  2018-04-14 02:28:40
forest model predict end:  2018-04-14 02:28:41
accuracy:  0.633995037221   511 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.50      0.32      0.39       100
          2       0.96      0.90      0.93        30
          3       0.51      0.62      0.56       100
          4       0.57      0.56      0.57       100
          5       0.78      0.73      0.76       100
          6       0.64      0.57      0.60        88
          7       0.77      0.57      0.65        30
          8       0.57      0.87      0.69        78
          9       0.75      0.86      0.80        80
         10       0.64      0.57      0.60       100

avg / total       0.64      0.63      0.63       806

============================================
Running  11  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:28:41
forest model fit end:  2018-04-14 02:29:29
forest model predict start:  2018-04-14 02:29:29
forest model predict end:  2018-04-14 02:29:29
accuracy:  0.647642679901   522 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.48      0.32      0.38       100
          2       1.00      0.90      0.95        30
          3       0.52      0.65      0.58       100
          4       0.60      0.58      0.59       100
          5       0.80      0.74      0.77       100
          6       0.71      0.58      0.64        88
          7       0.74      0.57      0.64        30
          8       0.58      0.87      0.70        78
          9       0.74      0.88      0.80        80
         10       0.67      0.60      0.63       100

avg / total       0.65      0.65      0.64       806

============================================
Running  12  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:29:29
forest model fit end:  2018-04-14 02:30:20
forest model predict start:  2018-04-14 02:30:20
forest model predict end:  2018-04-14 02:30:20
accuracy:  0.633995037221   511 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.50      0.31      0.38       100
          2       1.00      0.90      0.95        30
          3       0.52      0.63      0.57       100
          4       0.58      0.56      0.57       100
          5       0.79      0.74      0.76       100
          6       0.61      0.52      0.56        88
          7       0.77      0.57      0.65        30
          8       0.55      0.87      0.67        78
          9       0.74      0.88      0.80        80
         10       0.66      0.59      0.62       100

avg / total       0.64      0.63      0.63       806

============================================
Running  13  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:30:20
forest model fit end:  2018-04-14 02:31:09
forest model predict start:  2018-04-14 02:31:09
forest model predict end:  2018-04-14 02:31:09
accuracy:  0.612903225806   494 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.09      0.03      0.05       100
          2       1.00      0.87      0.93        30
          3       0.52      0.64      0.57       100
          4       0.58      0.54      0.56       100
          5       0.77      0.75      0.76       100
          6       0.49      0.64      0.55        88
          7       0.77      0.57      0.65        30
          8       0.60      0.87      0.71        78
          9       0.77      0.90      0.83        80
         10       0.64      0.59      0.61       100

avg / total       0.58      0.61      0.59       806

============================================
Running  14  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:31:09
forest model fit end:  2018-04-14 02:31:58
forest model predict start:  2018-04-14 02:31:58
forest model predict end:  2018-04-14 02:31:58
accuracy:  0.616625310174   497 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.11      0.05      0.07       100
          2       1.00      0.90      0.95        30
          3       0.55      0.66      0.60       100
          4       0.61      0.56      0.58       100
          5       0.80      0.76      0.78       100
          6       0.49      0.59      0.53        88
          7       0.81      0.57      0.67        30
          8       0.59      0.87      0.70        78
          9       0.76      0.89      0.82        80
         10       0.65      0.59      0.62       100

avg / total       0.59      0.62      0.60       806

============================================
Running  15  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:31:58
forest model fit end:  2018-04-14 02:32:47
forest model predict start:  2018-04-14 02:32:47
forest model predict end:  2018-04-14 02:32:47
accuracy:  0.631513647643   509 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.49      0.35      0.41       100
          2       1.00      0.90      0.95        30
          3       0.54      0.66      0.59       100
          4       0.59      0.57      0.58       100
          5       0.76      0.70      0.73       100
          6       0.63      0.51      0.57        88
          7       0.77      0.57      0.65        30
          8       0.56      0.85      0.67        78
          9       0.71      0.86      0.78        80
         10       0.63      0.57      0.60       100

avg / total       0.63      0.63      0.63       806

============================================
Running  16  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:32:47
forest model fit end:  2018-04-14 02:33:36
forest model predict start:  2018-04-14 02:33:36
forest model predict end:  2018-04-14 02:33:36
accuracy:  0.643920595533   519 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.56      0.37      0.45       100
          2       1.00      0.97      0.98        30
          3       0.51      0.62      0.56       100
          4       0.61      0.54      0.57       100
          5       0.78      0.72      0.75       100
          6       0.62      0.60      0.61        88
          7       0.77      0.57      0.65        30
          8       0.58      0.86      0.69        78
          9       0.73      0.89      0.80        80
         10       0.63      0.57      0.60       100

avg / total       0.65      0.64      0.64       806

============================================
Running  17  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:33:36
forest model fit end:  2018-04-14 02:34:25
forest model predict start:  2018-04-14 02:34:25
forest model predict end:  2018-04-14 02:34:25
accuracy:  0.620347394541   500 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.41      0.29      0.34       100
          2       1.00      0.87      0.93        30
          3       0.51      0.63      0.56       100
          4       0.62      0.60      0.61       100
          5       0.77      0.75      0.76       100
          6       0.61      0.49      0.54        88
          7       0.77      0.57      0.65        30
          8       0.54      0.81      0.65        78
          9       0.73      0.86      0.79        80
         10       0.63      0.55      0.59       100

avg / total       0.62      0.62      0.61       806

============================================
Running  18  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:34:25
forest model fit end:  2018-04-14 02:35:13
forest model predict start:  2018-04-14 02:35:13
forest model predict end:  2018-04-14 02:35:14
accuracy:  0.647642679901   522 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.48      0.32      0.38       100
          2       1.00      0.90      0.95        30
          3       0.52      0.64      0.57       100
          4       0.67      0.58      0.62       100
          5       0.82      0.75      0.79       100
          6       0.63      0.56      0.59        88
          7       0.74      0.57      0.64        30
          8       0.57      0.88      0.70        78
          9       0.74      0.89      0.81        80
         10       0.65      0.60      0.62       100

avg / total       0.65      0.65      0.64       806

============================================
Running  19  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:35:14
forest model fit end:  2018-04-14 02:36:04
forest model predict start:  2018-04-14 02:36:04
forest model predict end:  2018-04-14 02:36:05
accuracy:  0.619106699752   499 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.25      0.10      0.14       100
          2       0.96      0.90      0.93        30
          3       0.51      0.61      0.55       100
          4       0.59      0.54      0.57       100
          5       0.84      0.76      0.80       100
          6       0.50      0.61      0.55        88
          7       0.74      0.57      0.64        30
          8       0.59      0.90      0.71        78
          9       0.75      0.88      0.81        80
         10       0.65      0.60      0.62       100

avg / total       0.60      0.62      0.60       806

============================================
Running  20  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:36:05
forest model fit end:  2018-04-14 02:36:53
forest model predict start:  2018-04-14 02:36:53
forest model predict end:  2018-04-14 02:36:53
accuracy:  0.671215880893   541 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.57      0.37      0.45       100
          2       1.00      0.97      0.98        30
          3       0.56      0.64      0.60       100
          4       0.62      0.58      0.60       100
          5       0.82      0.78      0.80       100
          6       0.66      0.66      0.66        88
          7       0.77      0.57      0.65        30
          8       0.58      0.86      0.69        78
          9       0.76      0.89      0.82        80
         10       0.70      0.62      0.66       100

avg / total       0.67      0.67      0.67       806

============================================
Running  21  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:36:54
forest model fit end:  2018-04-14 02:37:42
forest model predict start:  2018-04-14 02:37:42
forest model predict end:  2018-04-14 02:37:42
accuracy:  0.637717121588   514 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.44      0.28      0.34       100
          2       1.00      0.90      0.95        30
          3       0.56      0.65      0.60       100
          4       0.61      0.57      0.59       100
          5       0.81      0.79      0.80       100
          6       0.60      0.55      0.57        88
          7       0.74      0.57      0.64        30
          8       0.56      0.87      0.68        78
          9       0.75      0.86      0.80        80
         10       0.62      0.56      0.59       100

avg / total       0.63      0.64      0.63       806

============================================
Running  22  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:37:42
forest model fit end:  2018-04-14 02:38:32
forest model predict start:  2018-04-14 02:38:32
forest model predict end:  2018-04-14 02:38:32
accuracy:  0.630272952854   508 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.43      0.23      0.30       100
          2       1.00      0.90      0.95        30
          3       0.54      0.61      0.57       100
          4       0.57      0.55      0.56       100
          5       0.79      0.74      0.76       100
          6       0.56      0.58      0.57        88
          7       0.78      0.60      0.68        30
          8       0.56      0.87      0.68        78
          9       0.75      0.86      0.80        80
         10       0.66      0.62      0.64       100

avg / total       0.63      0.63      0.62       806

============================================
Running  23  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:38:32
forest model fit end:  2018-04-14 02:39:20
forest model predict start:  2018-04-14 02:39:20
forest model predict end:  2018-04-14 02:39:21
accuracy:  0.646401985112   521 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.49      0.35      0.41       100
          2       1.00      0.90      0.95        30
          3       0.53      0.63      0.58       100
          4       0.61      0.58      0.59       100
          5       0.81      0.76      0.78       100
          6       0.61      0.52      0.56        88
          7       0.77      0.57      0.65        30
          8       0.59      0.87      0.70        78
          9       0.75      0.88      0.81        80
         10       0.66      0.61      0.63       100

avg / total       0.65      0.65      0.64       806

============================================
Running  24  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:39:21
forest model fit end:  2018-04-14 02:40:09
forest model predict start:  2018-04-14 02:40:09
forest model predict end:  2018-04-14 02:40:10
accuracy:  0.612903225806   494 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.12      0.04      0.06       100
          2       0.90      0.93      0.92        30
          3       0.53      0.63      0.58       100
          4       0.61      0.58      0.59       100
          5       0.83      0.72      0.77       100
          6       0.45      0.56      0.49        88
          7       0.68      0.57      0.62        30
          8       0.57      0.88      0.69        78
          9       0.76      0.89      0.82        80
         10       0.69      0.63      0.66       100

avg / total       0.58      0.61      0.59       806

============================================
Running  25  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:40:10
forest model fit end:  2018-04-14 02:40:58
forest model predict start:  2018-04-14 02:40:58
forest model predict end:  2018-04-14 02:40:58
accuracy:  0.645161290323   520 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.56      0.35      0.43       100
          2       0.96      0.90      0.93        30
          3       0.52      0.65      0.58       100
          4       0.60      0.57      0.58       100
          5       0.79      0.72      0.75       100
          6       0.65      0.62      0.64        88
          7       0.77      0.57      0.65        30
          8       0.59      0.87      0.70        78
          9       0.74      0.88      0.80        80
         10       0.62      0.54      0.58       100

avg / total       0.65      0.65      0.64       806

============================================
Running  26  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:40:59
forest model fit end:  2018-04-14 02:41:47
forest model predict start:  2018-04-14 02:41:47
forest model predict end:  2018-04-14 02:41:47
accuracy:  0.619106699752   499 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.17      0.06      0.09       100
          2       0.96      0.87      0.91        30
          3       0.55      0.66      0.60       100
          4       0.63      0.57      0.60       100
          5       0.76      0.78      0.77       100
          6       0.50      0.61      0.55        88
          7       0.77      0.57      0.65        30
          8       0.58      0.85      0.69        78
          9       0.77      0.88      0.82        80
         10       0.61      0.59      0.60       100

avg / total       0.59      0.62      0.60       806

============================================
Running  27  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:41:47
forest model fit end:  2018-04-14 02:42:36
forest model predict start:  2018-04-14 02:42:36
forest model predict end:  2018-04-14 02:42:37
accuracy:  0.638957816377   515 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.49      0.34      0.40       100
          2       0.96      0.87      0.91        30
          3       0.53      0.62      0.57       100
          4       0.57      0.57      0.57       100
          5       0.78      0.71      0.74       100
          6       0.67      0.57      0.61        88
          7       0.74      0.57      0.64        30
          8       0.55      0.87      0.67        78
          9       0.76      0.88      0.81        80
         10       0.67      0.60      0.63       100

avg / total       0.64      0.64      0.63       806

============================================
Running  28  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:42:37
forest model fit end:  2018-04-14 02:43:25
forest model predict start:  2018-04-14 02:43:25
forest model predict end:  2018-04-14 02:43:26
accuracy:  0.657568238213   530 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.56      0.36      0.44       100
          2       1.00      0.90      0.95        30
          3       0.52      0.63      0.57       100
          4       0.63      0.58      0.60       100
          5       0.81      0.78      0.80       100
          6       0.62      0.64      0.63        88
          7       0.77      0.57      0.65        30
          8       0.60      0.86      0.71        78
          9       0.74      0.86      0.80        80
         10       0.66      0.59      0.62       100

avg / total       0.66      0.66      0.65       806

============================================
Running  29  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:43:26
forest model fit end:  2018-04-14 02:44:14
forest model predict start:  2018-04-14 02:44:14
forest model predict end:  2018-04-14 02:44:14
accuracy:  0.646401985112   521 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.39      0.19      0.26       100
          2       1.00      0.93      0.97        30
          3       0.54      0.63      0.58       100
          4       0.65      0.58      0.61       100
          5       0.80      0.78      0.79       100
          6       0.60      0.69      0.64        88
          7       0.77      0.57      0.65        30
          8       0.57      0.86      0.68        78
          9       0.77      0.88      0.82        80
         10       0.65      0.60      0.63       100

avg / total       0.64      0.65      0.63       806

============================================
Running  30  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:44:14
forest model fit end:  2018-04-14 02:45:02
forest model predict start:  2018-04-14 02:45:02
forest model predict end:  2018-04-14 02:45:03
accuracy:  0.650124069479   524 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.51      0.36      0.42       100
          2       1.00      0.93      0.97        30
          3       0.55      0.64      0.59       100
          4       0.61      0.58      0.59       100
          5       0.78      0.74      0.76       100
          6       0.65      0.62      0.64        88
          7       0.77      0.57      0.65        30
          8       0.59      0.86      0.70        78
          9       0.76      0.85      0.80        80
         10       0.63      0.57      0.60       100

avg / total       0.65      0.65      0.64       806

============================================
Running  31  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:45:03
forest model fit end:  2018-04-14 02:45:51
forest model predict start:  2018-04-14 02:45:51
forest model predict end:  2018-04-14 02:45:51
accuracy:  0.630272952854   508 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.44      0.16      0.24       100
          2       1.00      0.93      0.97        30
          3       0.53      0.66      0.59       100
          4       0.58      0.55      0.56       100
          5       0.80      0.75      0.77       100
          6       0.50      0.59      0.54        88
          7       0.79      0.63      0.70        30
          8       0.58      0.87      0.70        78
          9       0.76      0.88      0.81        80
         10       0.64      0.59      0.61       100

avg / total       0.62      0.63      0.61       806

============================================
Running  32  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:45:51
forest model fit end:  2018-04-14 02:46:39
forest model predict start:  2018-04-14 02:46:39
forest model predict end:  2018-04-14 02:46:39
accuracy:  0.633995037221   511 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.36      0.17      0.23       100
          2       1.00      0.93      0.97        30
          3       0.56      0.64      0.60       100
          4       0.61      0.59      0.60       100
          5       0.78      0.71      0.74       100
          6       0.55      0.66      0.60        88
          7       0.74      0.57      0.64        30
          8       0.59      0.86      0.70        78
          9       0.74      0.88      0.80        80
         10       0.65      0.60      0.63       100

avg / total       0.62      0.63      0.62       806

============================================
Running  33  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:46:40
forest model fit end:  2018-04-14 02:47:28
forest model predict start:  2018-04-14 02:47:28
forest model predict end:  2018-04-14 02:47:28
accuracy:  0.643920595533   519 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.54      0.35      0.42       100
          2       1.00      0.90      0.95        30
          3       0.53      0.62      0.57       100
          4       0.61      0.56      0.58       100
          5       0.80      0.76      0.78       100
          6       0.59      0.53      0.56        88
          7       0.77      0.57      0.65        30
          8       0.55      0.88      0.68        78
          9       0.73      0.88      0.80        80
         10       0.68      0.60      0.64       100

avg / total       0.65      0.64      0.64       806

============================================
Running  34  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:47:28
forest model fit end:  2018-04-14 02:48:16
forest model predict start:  2018-04-14 02:48:16
forest model predict end:  2018-04-14 02:48:17
accuracy:  0.645161290323   520 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.51      0.32      0.39       100
          2       1.00      0.90      0.95        30
          3       0.55      0.63      0.59       100
          4       0.57      0.55      0.56       100
          5       0.80      0.74      0.77       100
          6       0.60      0.62      0.61        88
          7       0.77      0.57      0.65        30
          8       0.61      0.88      0.72        78
          9       0.76      0.88      0.81        80
         10       0.63      0.58      0.60       100

avg / total       0.64      0.65      0.64       806

============================================
Running  35  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:48:17
forest model fit end:  2018-04-14 02:49:05
forest model predict start:  2018-04-14 02:49:05
forest model predict end:  2018-04-14 02:49:05
accuracy:  0.622828784119   502 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.33      0.15      0.21       100
          2       1.00      0.90      0.95        30
          3       0.54      0.65      0.59       100
          4       0.62      0.58      0.60       100
          5       0.81      0.75      0.78       100
          6       0.51      0.58      0.54        88
          7       0.77      0.57      0.65        30
          8       0.55      0.88      0.68        78
          9       0.76      0.86      0.81        80
         10       0.64      0.56      0.60       100

avg / total       0.61      0.62      0.61       806

============================================
Running  36  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:49:05
forest model fit end:  2018-04-14 02:49:53
forest model predict start:  2018-04-14 02:49:53
forest model predict end:  2018-04-14 02:49:54
accuracy:  0.643920595533   519 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.45      0.24      0.31       100
          2       1.00      0.93      0.97        30
          3       0.54      0.64      0.58       100
          4       0.62      0.57      0.59       100
          5       0.81      0.78      0.80       100
          6       0.58      0.65      0.61        88
          7       0.77      0.57      0.65        30
          8       0.59      0.87      0.70        78
          9       0.76      0.85      0.80        80
         10       0.64      0.58      0.61       100

avg / total       0.64      0.64      0.63       806

============================================
Running  37  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:49:54
forest model fit end:  2018-04-14 02:50:42
forest model predict start:  2018-04-14 02:50:42
forest model predict end:  2018-04-14 02:50:42
accuracy:  0.637717121588   514 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.53      0.33      0.41       100
          2       1.00      0.90      0.95        30
          3       0.52      0.63      0.57       100
          4       0.61      0.57      0.59       100
          5       0.80      0.74      0.77       100
          6       0.59      0.53      0.56        88
          7       0.77      0.57      0.65        30
          8       0.55      0.86      0.67        78
          9       0.75      0.88      0.81        80
         10       0.63      0.59      0.61       100

avg / total       0.64      0.64      0.63       806

============================================
Running  38  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:50:42
forest model fit end:  2018-04-14 02:51:31
forest model predict start:  2018-04-14 02:51:31
forest model predict end:  2018-04-14 02:51:31
accuracy:  0.645161290323   520 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.58      0.34      0.43       100
          2       1.00      0.93      0.97        30
          3       0.54      0.64      0.58       100
          4       0.59      0.58      0.59       100
          5       0.77      0.71      0.74       100
          6       0.65      0.60      0.63        88
          7       0.77      0.57      0.65        30
          8       0.53      0.83      0.65        78
          9       0.74      0.88      0.80        80
         10       0.66      0.60      0.63       100

avg / total       0.65      0.65      0.64       806

============================================
Running  39  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:51:31
forest model fit end:  2018-04-14 02:52:20
forest model predict start:  2018-04-14 02:52:20
forest model predict end:  2018-04-14 02:52:20
accuracy:  0.627791563275   506 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.42      0.18      0.25       100
          2       1.00      0.90      0.95        30
          3       0.55      0.65      0.59       100
          4       0.63      0.56      0.59       100
          5       0.78      0.75      0.77       100
          6       0.51      0.60      0.55        88
          7       0.77      0.57      0.65        30
          8       0.56      0.87      0.68        78
          9       0.74      0.88      0.80        80
         10       0.63      0.57      0.60       100

avg / total       0.62      0.63      0.61       806

============================================
Running  40  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:52:20
forest model fit end:  2018-04-14 02:53:09
forest model predict start:  2018-04-14 02:53:09
forest model predict end:  2018-04-14 02:53:09
accuracy:  0.642679900744   518 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.58      0.33      0.42       100
          2       0.96      0.87      0.91        30
          3       0.53      0.64      0.58       100
          4       0.57      0.54      0.55       100
          5       0.78      0.73      0.76       100
          6       0.63      0.61      0.62        88
          7       0.77      0.57      0.65        30
          8       0.56      0.87      0.68        78
          9       0.75      0.86      0.80        80
         10       0.66      0.60      0.63       100

avg / total       0.65      0.64      0.64       806

============================================
Running  41  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:53:09
forest model fit end:  2018-04-14 02:53:57
forest model predict start:  2018-04-14 02:53:57
forest model predict end:  2018-04-14 02:53:58
accuracy:  0.651364764268   525 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.52      0.32      0.40       100
          2       1.00      0.90      0.95        30
          3       0.51      0.63      0.57       100
          4       0.63      0.57      0.60       100
          5       0.81      0.75      0.78       100
          6       0.61      0.61      0.61        88
          7       0.75      0.60      0.67        30
          8       0.63      0.88      0.73        78
          9       0.73      0.89      0.80        80
         10       0.64      0.59      0.61       100

avg / total       0.65      0.65      0.64       806

============================================
Running  42  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:53:58
forest model fit end:  2018-04-14 02:54:47
forest model predict start:  2018-04-14 02:54:47
forest model predict end:  2018-04-14 02:54:47
accuracy:  0.601736972705   485 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.15      0.05      0.07       100
          2       1.00      0.93      0.97        30
          3       0.52      0.66      0.58       100
          4       0.60      0.55      0.57       100
          5       0.77      0.72      0.75       100
          6       0.42      0.55      0.48        88
          7       0.77      0.57      0.65        30
          8       0.58      0.85      0.69        78
          9       0.74      0.86      0.80        80
         10       0.66      0.59      0.62       100

avg / total       0.58      0.60      0.58       806

============================================
Running  43  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:54:47
forest model fit end:  2018-04-14 02:55:36
forest model predict start:  2018-04-14 02:55:36
forest model predict end:  2018-04-14 02:55:36
accuracy:  0.646401985112   521 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.52      0.32      0.40       100
          2       1.00      0.90      0.95        30
          3       0.50      0.62      0.55       100
          4       0.63      0.59      0.61       100
          5       0.80      0.75      0.77       100
          6       0.64      0.61      0.63        88
          7       0.74      0.57      0.64        30
          8       0.61      0.87      0.72        78
          9       0.71      0.89      0.79        80
         10       0.65      0.56      0.60       100

avg / total       0.65      0.65      0.64       806

============================================
Running  44  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:55:36
forest model fit end:  2018-04-14 02:56:24
forest model predict start:  2018-04-14 02:56:24
forest model predict end:  2018-04-14 02:56:25
accuracy:  0.651364764268   525 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.49      0.32      0.39       100
          2       1.00      0.90      0.95        30
          3       0.54      0.65      0.59       100
          4       0.59      0.54      0.57       100
          5       0.77      0.77      0.77       100
          6       0.68      0.68      0.68        88
          7       0.77      0.57      0.65        30
          8       0.61      0.86      0.72        78
          9       0.75      0.86      0.80        80
         10       0.63      0.57      0.60       100

avg / total       0.65      0.65      0.64       806

============================================
Running  45  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:56:25
forest model fit end:  2018-04-14 02:57:13
forest model predict start:  2018-04-14 02:57:13
forest model predict end:  2018-04-14 02:57:14
accuracy:  0.647642679901   522 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.49      0.32      0.39       100
          2       1.00      0.90      0.95        30
          3       0.53      0.63      0.58       100
          4       0.60      0.59      0.60       100
          5       0.76      0.74      0.75       100
          6       0.63      0.60      0.62        88
          7       0.77      0.57      0.65        30
          8       0.59      0.83      0.69        78
          9       0.74      0.88      0.80        80
         10       0.69      0.62      0.65       100

avg / total       0.65      0.65      0.64       806

============================================
Running  46  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:57:14
forest model fit end:  2018-04-14 02:58:03
forest model predict start:  2018-04-14 02:58:03
forest model predict end:  2018-04-14 02:58:03
accuracy:  0.629032258065   507 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.26      0.11      0.15       100
          2       1.00      0.87      0.93        30
          3       0.54      0.64      0.59       100
          4       0.62      0.58      0.60       100
          5       0.80      0.75      0.77       100
          6       0.55      0.65      0.59        88
          7       0.77      0.57      0.65        30
          8       0.58      0.87      0.69        78
          9       0.72      0.88      0.79        80
         10       0.67      0.61      0.64       100

avg / total       0.61      0.63      0.61       806

============================================
Running  47  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:58:03
forest model fit end:  2018-04-14 02:58:52
forest model predict start:  2018-04-14 02:58:52
forest model predict end:  2018-04-14 02:58:52
accuracy:  0.599255583127   483 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.12      0.04      0.06       100
          2       1.00      0.87      0.93        30
          3       0.52      0.64      0.58       100
          4       0.60      0.57      0.58       100
          5       0.77      0.72      0.74       100
          6       0.43      0.52      0.47        88
          7       0.77      0.57      0.65        30
          8       0.57      0.87      0.69        78
          9       0.78      0.88      0.82        80
         10       0.61      0.59      0.60       100

avg / total       0.57      0.60      0.58       806

============================================
Running  48  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:58:52
forest model fit end:  2018-04-14 02:59:40
forest model predict start:  2018-04-14 02:59:40
forest model predict end:  2018-04-14 02:59:40
accuracy:  0.637717121588   514 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.47      0.31      0.37       100
          2       0.97      0.93      0.95        30
          3       0.55      0.65      0.59       100
          4       0.61      0.56      0.58       100
          5       0.78      0.75      0.77       100
          6       0.61      0.55      0.57        88
          7       0.77      0.57      0.65        30
          8       0.56      0.86      0.68        78
          9       0.73      0.88      0.80        80
         10       0.65      0.57      0.61       100

avg / total       0.64      0.64      0.63       806

============================================
Running  49  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:59:40
forest model fit end:  2018-04-14 03:00:28
forest model predict start:  2018-04-14 03:00:28
forest model predict end:  2018-04-14 03:00:29
accuracy:  0.657568238213   530 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.51      0.32      0.39       100
          2       1.00      0.90      0.95        30
          3       0.55      0.66      0.60       100
          4       0.62      0.57      0.59       100
          5       0.79      0.77      0.78       100
          6       0.65      0.66      0.66        88
          7       0.77      0.57      0.65        30
          8       0.61      0.85      0.71        78
          9       0.74      0.86      0.80        80
         10       0.65      0.61      0.63       100

avg / total       0.66      0.66      0.65       806

============================================
Running  50  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 03:00:29
forest model fit end:  2018-04-14 03:01:16
forest model predict start:  2018-04-14 03:01:16
forest model predict end:  2018-04-14 03:01:17
accuracy:  0.63523573201   512 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.42      0.23      0.30       100
          2       0.93      0.90      0.92        30
          3       0.54      0.63      0.58       100
          4       0.61      0.56      0.58       100
          5       0.79      0.73      0.76       100
          6       0.58      0.60      0.59        88
          7       0.78      0.60      0.68        30
          8       0.58      0.86      0.69        78
          9       0.75      0.88      0.81        80
         10       0.63      0.62      0.62       100

avg / total       0.63      0.64      0.62       806

============================================
[0.64764267990074442, 0.64267990074441683, 0.66004962779156329, 0.60049627791563276, 0.63523573200992556, 0.65012406947890822, 0.63895781637717119, 0.60794044665012403, 0.6178660049627791, 0.63399503722084372, 0.64764267990074442, 0.63399503722084372, 0.61290322580645162, 0.61662531017369726, 0.63151364764267992, 0.64392059553349879, 0.6203473945409429, 0.64764267990074442, 0.61910669975186106, 0.6712158808933002, 0.63771712158808935, 0.63027295285359797, 0.64640198511166258, 0.61290322580645162, 0.64516129032258063, 0.61910669975186106, 0.63895781637717119, 0.65756823821339949, 0.64640198511166258, 0.65012406947890822, 0.63027295285359797, 0.63399503722084372, 0.64392059553349879, 0.64516129032258063, 0.62282878411910669, 0.64392059553349879, 0.63771712158808935, 0.64516129032258063, 0.62779156327543428, 0.64267990074441683, 0.65136476426799006, 0.6017369727047146, 0.64640198511166258, 0.65136476426799006, 0.64764267990074442, 0.62903225806451613, 0.59925558312655092, 0.63771712158808935, 0.65756823821339949, 0.63523573200992556]
Avg accuracy:  0.635905707196
