Running  1  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:20:57
forest model fit end:  2018-04-14 02:21:43
forest model predict start:  2018-04-14 02:21:43
forest model predict end:  2018-04-14 02:21:43
accuracy:  0.555555555556   465 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.59      0.64      0.61       100
          2       0.81      0.67      0.73        33
          3       0.47      0.79      0.59       100
          4       0.70      0.54      0.61       100
          5       0.38      0.42      0.40       100
          6       0.67      0.34      0.45        93
          7       1.00      0.56      0.72        32
          8       0.61      0.61      0.61        96
          9       0.63      0.37      0.47        83
         10       0.48      0.64      0.55       100

avg / total       0.59      0.56      0.55       837

============================================
Running  2  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:21:43
forest model fit end:  2018-04-14 02:22:28
forest model predict start:  2018-04-14 02:22:28
forest model predict end:  2018-04-14 02:22:29
accuracy:  0.620071684588   519 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.78      0.82      0.80       100
          2       0.85      0.67      0.75        33
          3       0.48      0.81      0.60       100
          4       0.79      0.55      0.65       100
          5       0.42      0.43      0.42       100
          6       0.84      0.70      0.76        93
          7       1.00      0.56      0.72        32
          8       0.62      0.56      0.59        96
          9       0.64      0.39      0.48        83
         10       0.51      0.67      0.58       100

avg / total       0.66      0.62      0.62       837

============================================
Running  3  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:22:29
forest model fit end:  2018-04-14 02:23:14
forest model predict start:  2018-04-14 02:23:14
forest model predict end:  2018-04-14 02:23:14
accuracy:  0.615292712067   515 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.72      0.76      0.74       100
          2       0.81      0.67      0.73        33
          3       0.44      0.77      0.56       100
          4       0.74      0.54      0.62       100
          5       0.46      0.44      0.45       100
          6       0.85      0.71      0.77        93
          7       1.00      0.59      0.75        32
          8       0.67      0.60      0.64        96
          9       0.63      0.39      0.48        83
         10       0.52      0.67      0.59       100

avg / total       0.65      0.62      0.62       837

============================================
Running  4  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:23:15
forest model fit end:  2018-04-14 02:24:00
forest model predict start:  2018-04-14 02:24:00
forest model predict end:  2018-04-14 02:24:00
accuracy:  0.592592592593   496 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.65      0.81      0.72       100
          2       0.79      0.67      0.72        33
          3       0.45      0.79      0.58       100
          4       0.74      0.56      0.64       100
          5       0.40      0.36      0.38       100
          6       0.84      0.51      0.63        93
          7       1.00      0.59      0.75        32
          8       0.64      0.60      0.62        96
          9       0.62      0.37      0.47        83
         10       0.52      0.67      0.58       100

avg / total       0.63      0.59      0.59       837

============================================
Running  5  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:24:00
forest model fit end:  2018-04-14 02:24:46
forest model predict start:  2018-04-14 02:24:46
forest model predict end:  2018-04-14 02:24:46
accuracy:  0.583034647551   488 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.72      0.72      0.72       100
          2       0.81      0.67      0.73        33
          3       0.45      0.78      0.57       100
          4       0.69      0.54      0.61       100
          5       0.38      0.38      0.38       100
          6       0.75      0.57      0.65        93
          7       1.00      0.62      0.77        32
          8       0.60      0.55      0.58        96
          9       0.62      0.36      0.46        83
         10       0.51      0.68      0.58       100

avg / total       0.61      0.58      0.58       837

============================================
Running  6  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:24:46
forest model fit end:  2018-04-14 02:25:31
forest model predict start:  2018-04-14 02:25:31
forest model predict end:  2018-04-14 02:25:32
accuracy:  0.57825567503   484 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.67      0.82      0.74       100
          2       0.79      0.67      0.72        33
          3       0.46      0.82      0.59       100
          4       0.74      0.53      0.62       100
          5       0.39      0.35      0.37       100
          6       0.65      0.34      0.45        93
          7       1.00      0.56      0.72        32
          8       0.58      0.64      0.60        96
          9       0.63      0.37      0.47        83
         10       0.54      0.68      0.60       100

avg / total       0.60      0.58      0.57       837

============================================
Running  7  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:25:32
forest model fit end:  2018-04-14 02:26:17
forest model predict start:  2018-04-14 02:26:17
forest model predict end:  2018-04-14 02:26:17
accuracy:  0.605734767025   507 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.77      0.80      0.78       100
          2       0.79      0.70      0.74        33
          3       0.48      0.76      0.59       100
          4       0.69      0.53      0.60       100
          5       0.35      0.30      0.32       100
          6       0.80      0.69      0.74        93
          7       1.00      0.62      0.77        32
          8       0.58      0.64      0.61        96
          9       0.63      0.37      0.47        83
         10       0.53      0.69      0.60       100

avg / total       0.62      0.61      0.60       837

============================================
Running  8  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:26:18
forest model fit end:  2018-04-14 02:27:03
forest model predict start:  2018-04-14 02:27:03
forest model predict end:  2018-04-14 02:27:03
accuracy:  0.591397849462   495 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.61      0.78      0.68       100
          2       0.79      0.67      0.72        33
          3       0.49      0.81      0.61       100
          4       0.75      0.55      0.64       100
          5       0.43      0.44      0.43       100
          6       0.81      0.51      0.62        93
          7       1.00      0.50      0.67        32
          8       0.58      0.56      0.57        96
          9       0.61      0.37      0.46        83
         10       0.56      0.67      0.61       100

avg / total       0.62      0.59      0.59       837

============================================
Running  9  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:27:03
forest model fit end:  2018-04-14 02:27:49
forest model predict start:  2018-04-14 02:27:49
forest model predict end:  2018-04-14 02:27:49
accuracy:  0.596176821983   499 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.68      0.81      0.74       100
          2       0.85      0.70      0.77        33
          3       0.44      0.80      0.57       100
          4       0.75      0.54      0.63       100
          5       0.44      0.42      0.43       100
          6       0.79      0.48      0.60        93
          7       1.00      0.44      0.61        32
          8       0.66      0.62      0.64        96
          9       0.62      0.37      0.47        83
         10       0.53      0.69      0.60       100

avg / total       0.64      0.60      0.59       837

============================================
Running  10  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:27:49
forest model fit end:  2018-04-14 02:28:34
forest model predict start:  2018-04-14 02:28:34
forest model predict end:  2018-04-14 02:28:35
accuracy:  0.596176821983   499 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.71      0.82      0.76       100
          2       0.79      0.67      0.72        33
          3       0.49      0.82      0.61       100
          4       0.73      0.54      0.62       100
          5       0.35      0.34      0.35       100
          6       0.84      0.58      0.69        93
          7       1.00      0.59      0.75        32
          8       0.60      0.56      0.58        96
          9       0.61      0.37      0.46        83
         10       0.51      0.67      0.58       100

avg / total       0.63      0.60      0.59       837

============================================
Running  11  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:28:35
forest model fit end:  2018-04-14 02:29:20
forest model predict start:  2018-04-14 02:29:20
forest model predict end:  2018-04-14 02:29:20
accuracy:  0.589008363202   493 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.68      0.80      0.74       100
          2       0.76      0.67      0.71        33
          3       0.49      0.79      0.60       100
          4       0.74      0.55      0.63       100
          5       0.37      0.36      0.36       100
          6       0.73      0.51      0.60        93
          7       1.00      0.59      0.75        32
          8       0.59      0.57      0.58        96
          9       0.65      0.37      0.47        83
         10       0.52      0.69      0.59       100

avg / total       0.62      0.59      0.59       837

============================================
Running  12  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:29:20
forest model fit end:  2018-04-14 02:30:06
forest model predict start:  2018-04-14 02:30:06
forest model predict end:  2018-04-14 02:30:06
accuracy:  0.592592592593   496 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.72      0.84      0.77       100
          2       0.79      0.67      0.72        33
          3       0.46      0.79      0.58       100
          4       0.72      0.55      0.63       100
          5       0.39      0.41      0.40       100
          6       0.80      0.52      0.63        93
          7       1.00      0.62      0.77        32
          8       0.63      0.49      0.55        96
          9       0.63      0.39      0.48        83
         10       0.52      0.68      0.59       100

avg / total       0.63      0.59      0.59       837

============================================
Running  13  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:30:06
forest model fit end:  2018-04-14 02:30:52
forest model predict start:  2018-04-14 02:30:52
forest model predict end:  2018-04-14 02:30:52
accuracy:  0.606929510155   508 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.68      0.78      0.73       100
          2       0.85      0.70      0.77        33
          3       0.49      0.82      0.61       100
          4       0.77      0.55      0.64       100
          5       0.46      0.36      0.40       100
          6       0.74      0.53      0.62        93
          7       1.00      0.53      0.69        32
          8       0.63      0.72      0.67        96
          9       0.61      0.36      0.45        83
         10       0.51      0.69      0.58       100

avg / total       0.63      0.61      0.60       837

============================================
Running  14  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:30:52
forest model fit end:  2018-04-14 02:31:37
forest model predict start:  2018-04-14 02:31:37
forest model predict end:  2018-04-14 02:31:37
accuracy:  0.598566308244   501 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.73      0.80      0.76       100
          2       0.79      0.67      0.72        33
          3       0.49      0.81      0.61       100
          4       0.75      0.54      0.63       100
          5       0.36      0.30      0.33       100
          6       0.81      0.67      0.73        93
          7       1.00      0.44      0.61        32
          8       0.61      0.64      0.62        96
          9       0.61      0.36      0.45        83
         10       0.49      0.67      0.56       100

avg / total       0.63      0.60      0.59       837

============================================
Running  15  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:31:38
forest model fit end:  2018-04-14 02:32:23
forest model predict start:  2018-04-14 02:32:23
forest model predict end:  2018-04-14 02:32:23
accuracy:  0.590203106332   494 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.76      0.77      0.77       100
          2       0.81      0.67      0.73        33
          3       0.48      0.79      0.59       100
          4       0.74      0.54      0.62       100
          5       0.35      0.35      0.35       100
          6       0.76      0.63      0.69        93
          7       1.00      0.62      0.77        32
          8       0.55      0.50      0.52        96
          9       0.58      0.37      0.46        83
         10       0.53      0.69      0.60       100

avg / total       0.62      0.59      0.59       837

============================================
Running  16  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:32:23
forest model fit end:  2018-04-14 02:33:09
forest model predict start:  2018-04-14 02:33:09
forest model predict end:  2018-04-14 02:33:09
accuracy:  0.584229390681   489 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.60      0.75      0.67       100
          2       0.88      0.70      0.78        33
          3       0.49      0.81      0.61       100
          4       0.75      0.53      0.62       100
          5       0.40      0.40      0.40       100
          6       0.75      0.49      0.60        93
          7       1.00      0.59      0.75        32
          8       0.58      0.54      0.56        96
          9       0.62      0.39      0.47        83
         10       0.53      0.68      0.59       100

avg / total       0.62      0.58      0.58       837

============================================
Running  17  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:33:09
forest model fit end:  2018-04-14 02:33:55
forest model predict start:  2018-04-14 02:33:55
forest model predict end:  2018-04-14 02:33:55
accuracy:  0.563918757467   472 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.62      0.78      0.69       100
          2       0.81      0.67      0.73        33
          3       0.45      0.76      0.57       100
          4       0.70      0.54      0.61       100
          5       0.37      0.41      0.39       100
          6       0.72      0.39      0.50        93
          7       1.00      0.59      0.75        32
          8       0.57      0.49      0.53        96
          9       0.60      0.37      0.46        83
         10       0.54      0.68      0.60       100

avg / total       0.60      0.56      0.56       837

============================================
Running  18  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:33:55
forest model fit end:  2018-04-14 02:34:40
forest model predict start:  2018-04-14 02:34:40
forest model predict end:  2018-04-14 02:34:41
accuracy:  0.612903225806   513 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.77      0.85      0.81       100
          2       0.88      0.67      0.76        33
          3       0.48      0.82      0.61       100
          4       0.76      0.54      0.63       100
          5       0.41      0.43      0.42       100
          6       0.76      0.66      0.71        93
          7       1.00      0.59      0.75        32
          8       0.61      0.51      0.56        96
          9       0.60      0.37      0.46        83
         10       0.54      0.67      0.60       100

avg / total       0.64      0.61      0.61       837

============================================
Running  19  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:34:41
forest model fit end:  2018-04-14 02:35:26
forest model predict start:  2018-04-14 02:35:26
forest model predict end:  2018-04-14 02:35:26
accuracy:  0.5770609319   483 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.69      0.72      0.71       100
          2       0.88      0.67      0.76        33
          3       0.45      0.80      0.58       100
          4       0.74      0.54      0.62       100
          5       0.38      0.41      0.40       100
          6       0.75      0.56      0.64        93
          7       1.00      0.50      0.67        32
          8       0.56      0.51      0.54        96
          9       0.62      0.37      0.47        83
         10       0.52      0.66      0.58       100

avg / total       0.61      0.58      0.58       837

============================================
Running  20  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:35:26
forest model fit end:  2018-04-14 02:36:12
forest model predict start:  2018-04-14 02:36:12
forest model predict end:  2018-04-14 02:36:12
accuracy:  0.556750298686   466 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.62      0.69      0.65       100
          2       0.80      0.73      0.76        33
          3       0.44      0.79      0.56       100
          4       0.72      0.56      0.63       100
          5       0.40      0.39      0.40       100
          6       0.72      0.33      0.46        93
          7       1.00      0.53      0.69        32
          8       0.53      0.56      0.55        96
          9       0.64      0.36      0.46        83
         10       0.51      0.67      0.58       100

avg / total       0.59      0.56      0.55       837

============================================
Running  21  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:36:12
forest model fit end:  2018-04-14 02:36:57
forest model predict start:  2018-04-14 02:36:57
forest model predict end:  2018-04-14 02:36:58
accuracy:  0.5770609319   483 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.65      0.74      0.69       100
          2       0.88      0.67      0.76        33
          3       0.48      0.78      0.59       100
          4       0.73      0.55      0.63       100
          5       0.37      0.38      0.37       100
          6       0.68      0.52      0.59        93
          7       1.00      0.62      0.77        32
          8       0.60      0.51      0.55        96
          9       0.60      0.36      0.45        83
         10       0.51      0.69      0.59       100

avg / total       0.60      0.58      0.58       837

============================================
Running  22  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:36:58
forest model fit end:  2018-04-14 02:37:43
forest model predict start:  2018-04-14 02:37:43
forest model predict end:  2018-04-14 02:37:43
accuracy:  0.592592592593   496 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.75      0.83      0.79       100
          2       0.82      0.70      0.75        33
          3       0.48      0.82      0.60       100
          4       0.77      0.54      0.64       100
          5       0.34      0.36      0.35       100
          6       0.81      0.59      0.68        93
          7       1.00      0.47      0.64        32
          8       0.57      0.48      0.52        96
          9       0.60      0.37      0.46        83
         10       0.53      0.71      0.61       100

avg / total       0.63      0.59      0.59       837

============================================
Running  23  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:37:44
forest model fit end:  2018-04-14 02:38:29
forest model predict start:  2018-04-14 02:38:29
forest model predict end:  2018-04-14 02:38:29
accuracy:  0.609318996416   510 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.75      0.76      0.75       100
          2       0.85      0.70      0.77        33
          3       0.48      0.79      0.59       100
          4       0.74      0.55      0.63       100
          5       0.45      0.46      0.46       100
          6       0.84      0.71      0.77        93
          7       1.00      0.44      0.61        32
          8       0.59      0.56      0.57        96
          9       0.61      0.37      0.46        83
         10       0.51      0.66      0.57       100

avg / total       0.64      0.61      0.61       837

============================================
Running  24  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:38:29
forest model fit end:  2018-04-14 02:39:14
forest model predict start:  2018-04-14 02:39:14
forest model predict end:  2018-04-14 02:39:15
accuracy:  0.603345280765   505 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.76      0.78      0.77       100
          2       0.73      0.67      0.70        33
          3       0.44      0.81      0.57       100
          4       0.76      0.54      0.63       100
          5       0.44      0.44      0.44       100
          6       0.83      0.59      0.69        93
          7       1.00      0.47      0.64        32
          8       0.63      0.58      0.61        96
          9       0.67      0.39      0.49        83
         10       0.52      0.68      0.59       100

avg / total       0.65      0.60      0.61       837

============================================
Running  25  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:39:15
forest model fit end:  2018-04-14 02:40:00
forest model predict start:  2018-04-14 02:40:00
forest model predict end:  2018-04-14 02:40:01
accuracy:  0.611708482676   512 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.78      0.83      0.81       100
          2       0.80      0.73      0.76        33
          3       0.46      0.81      0.59       100
          4       0.73      0.55      0.63       100
          5       0.42      0.37      0.39       100
          6       0.82      0.60      0.70        93
          7       1.00      0.59      0.75        32
          8       0.62      0.62      0.62        96
          9       0.61      0.36      0.45        83
         10       0.52      0.67      0.59       100

avg / total       0.64      0.61      0.61       837

============================================
Running  26  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:40:01
forest model fit end:  2018-04-14 02:40:46
forest model predict start:  2018-04-14 02:40:46
forest model predict end:  2018-04-14 02:40:47
accuracy:  0.567502986858   475 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.63      0.79      0.70       100
          2       0.85      0.67      0.75        33
          3       0.48      0.80      0.60       100
          4       0.68      0.54      0.60       100
          5       0.36      0.35      0.36       100
          6       0.69      0.45      0.55        93
          7       1.00      0.50      0.67        32
          8       0.56      0.55      0.56        96
          9       0.60      0.36      0.45        83
         10       0.52      0.64      0.57       100

avg / total       0.59      0.57      0.56       837

============================================
Running  27  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:40:47
forest model fit end:  2018-04-14 02:41:32
forest model predict start:  2018-04-14 02:41:32
forest model predict end:  2018-04-14 02:41:33
accuracy:  0.602150537634   504 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.76      0.82      0.79       100
          2       0.92      0.67      0.77        33
          3       0.44      0.78      0.56       100
          4       0.73      0.55      0.63       100
          5       0.41      0.40      0.41       100
          6       0.83      0.56      0.67        93
          7       1.00      0.59      0.75        32
          8       0.62      0.57      0.60        96
          9       0.62      0.39      0.47        83
         10       0.52      0.69      0.59       100

avg / total       0.64      0.60      0.60       837

============================================
Running  28  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:41:33
forest model fit end:  2018-04-14 02:42:18
forest model predict start:  2018-04-14 02:42:18
forest model predict end:  2018-04-14 02:42:19
accuracy:  0.572281959379   479 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.65      0.83      0.73       100
          2       0.88      0.67      0.76        33
          3       0.47      0.81      0.59       100
          4       0.76      0.54      0.63       100
          5       0.36      0.39      0.37       100
          6       0.71      0.38      0.49        93
          7       1.00      0.59      0.75        32
          8       0.58      0.50      0.54        96
          9       0.59      0.36      0.45        83
         10       0.53      0.68      0.59       100

avg / total       0.61      0.57      0.57       837

============================================
Running  29  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:42:19
forest model fit end:  2018-04-14 02:43:04
forest model predict start:  2018-04-14 02:43:04
forest model predict end:  2018-04-14 02:43:05
accuracy:  0.581839904421   487 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.70      0.78      0.74       100
          2       0.86      0.73      0.79        33
          3       0.45      0.76      0.56       100
          4       0.70      0.54      0.61       100
          5       0.36      0.35      0.36       100
          6       0.79      0.53      0.63        93
          7       1.00      0.56      0.72        32
          8       0.59      0.55      0.57        96
          9       0.63      0.40      0.49        83
         10       0.51      0.67      0.58       100

avg / total       0.61      0.58      0.58       837

============================================
Running  30  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:43:05
forest model fit end:  2018-04-14 02:43:51
forest model predict start:  2018-04-14 02:43:51
forest model predict end:  2018-04-14 02:43:51
accuracy:  0.586618876941   491 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.72      0.79      0.76       100
          2       0.88      0.70      0.78        33
          3       0.47      0.81      0.59       100
          4       0.69      0.53      0.60       100
          5       0.37      0.37      0.37       100
          6       0.78      0.56      0.65        93
          7       1.00      0.62      0.77        32
          8       0.60      0.52      0.56        96
          9       0.61      0.37      0.46        83
         10       0.50      0.65      0.57       100

avg / total       0.62      0.59      0.59       837

============================================
Running  31  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:43:51
forest model fit end:  2018-04-14 02:44:37
forest model predict start:  2018-04-14 02:44:37
forest model predict end:  2018-04-14 02:44:37
accuracy:  0.587813620072   492 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.69      0.81      0.74       100
          2       0.80      0.73      0.76        33
          3       0.46      0.81      0.59       100
          4       0.75      0.55      0.64       100
          5       0.42      0.40      0.41       100
          6       0.75      0.44      0.55        93
          7       1.00      0.44      0.61        32
          8       0.60      0.57      0.59        96
          9       0.62      0.37      0.47        83
         10       0.53      0.70      0.60       100

avg / total       0.62      0.59      0.58       837

============================================
Running  32  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:44:37
forest model fit end:  2018-04-14 02:45:23
forest model predict start:  2018-04-14 02:45:23
forest model predict end:  2018-04-14 02:45:23
accuracy:  0.584229390681   489 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.63      0.81      0.71       100
          2       0.79      0.67      0.72        33
          3       0.47      0.80      0.59       100
          4       0.74      0.54      0.62       100
          5       0.40      0.35      0.37       100
          6       0.71      0.40      0.51        93
          7       1.00      0.59      0.75        32
          8       0.65      0.66      0.65        96
          9       0.62      0.36      0.46        83
         10       0.51      0.68      0.58       100

avg / total       0.61      0.58      0.58       837

============================================
Running  33  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:45:23
forest model fit end:  2018-04-14 02:46:09
forest model predict start:  2018-04-14 02:46:09
forest model predict end:  2018-04-14 02:46:09
accuracy:  0.561529271207   470 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.62      0.76      0.68       100
          2       0.88      0.67      0.76        33
          3       0.48      0.79      0.60       100
          4       0.73      0.52      0.61       100
          5       0.37      0.42      0.39       100
          6       0.66      0.38      0.48        93
          7       1.00      0.59      0.75        32
          8       0.53      0.46      0.49        96
          9       0.61      0.37      0.46        83
         10       0.53      0.70      0.60       100

avg / total       0.59      0.56      0.56       837

============================================
Running  34  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:46:09
forest model fit end:  2018-04-14 02:46:54
forest model predict start:  2018-04-14 02:46:54
forest model predict end:  2018-04-14 02:46:55
accuracy:  0.581839904421   487 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.65      0.81      0.72       100
          2       0.79      0.67      0.72        33
          3       0.46      0.79      0.58       100
          4       0.72      0.52      0.60       100
          5       0.38      0.41      0.39       100
          6       0.80      0.48      0.60        93
          7       0.95      0.62      0.75        32
          8       0.61      0.49      0.54        96
          9       0.63      0.37      0.47        83
         10       0.53      0.69      0.60       100

avg / total       0.62      0.58      0.58       837

============================================
Running  35  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:46:55
forest model fit end:  2018-04-14 02:47:40
forest model predict start:  2018-04-14 02:47:40
forest model predict end:  2018-04-14 02:47:41
accuracy:  0.599761051374   502 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.73      0.81      0.77       100
          2       0.92      0.67      0.77        33
          3       0.44      0.77      0.56       100
          4       0.72      0.55      0.63       100
          5       0.38      0.41      0.40       100
          6       0.84      0.58      0.69        93
          7       1.00      0.59      0.75        32
          8       0.66      0.54      0.59        96
          9       0.64      0.39      0.48        83
         10       0.52      0.69      0.59       100

avg / total       0.64      0.60      0.60       837

============================================
Running  36  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:47:41
forest model fit end:  2018-04-14 02:48:26
forest model predict start:  2018-04-14 02:48:26
forest model predict end:  2018-04-14 02:48:27
accuracy:  0.57825567503   484 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.69      0.81      0.74       100
          2       0.92      0.70      0.79        33
          3       0.47      0.81      0.59       100
          4       0.76      0.55      0.64       100
          5       0.34      0.36      0.35       100
          6       0.72      0.51      0.59        93
          7       1.00      0.53      0.69        32
          8       0.56      0.46      0.50        96
          9       0.61      0.37      0.46        83
         10       0.52      0.69      0.59       100

avg / total       0.61      0.58      0.58       837

============================================
Running  37  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:48:27
forest model fit end:  2018-04-14 02:49:12
forest model predict start:  2018-04-14 02:49:12
forest model predict end:  2018-04-14 02:49:13
accuracy:  0.602150537634   504 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.69      0.70      0.69       100
          2       0.85      0.70      0.77        33
          3       0.46      0.78      0.58       100
          4       0.74      0.54      0.62       100
          5       0.44      0.40      0.42       100
          6       0.81      0.62      0.70        93
          7       1.00      0.59      0.75        32
          8       0.60      0.64      0.62        96
          9       0.62      0.37      0.47        83
         10       0.53      0.70      0.60       100

avg / total       0.63      0.60      0.60       837

============================================
Running  38  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:49:13
forest model fit end:  2018-04-14 02:49:58
forest model predict start:  2018-04-14 02:49:58
forest model predict end:  2018-04-14 02:49:59
accuracy:  0.606929510155   508 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.80      0.75      0.77       100
          2       0.76      0.67      0.71        33
          3       0.46      0.77      0.57       100
          4       0.71      0.54      0.61       100
          5       0.38      0.35      0.37       100
          6       0.84      0.75      0.80        93
          7       1.00      0.53      0.69        32
          8       0.59      0.60      0.59        96
          9       0.63      0.37      0.47        83
         10       0.53      0.69      0.60       100

avg / total       0.64      0.61      0.61       837

============================================
Running  39  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:49:59
forest model fit end:  2018-04-14 02:50:44
forest model predict start:  2018-04-14 02:50:44
forest model predict end:  2018-04-14 02:50:44
accuracy:  0.618876941458   518 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.77      0.76      0.76       100
          2       0.79      0.67      0.72        33
          3       0.50      0.78      0.61       100
          4       0.68      0.54      0.60       100
          5       0.43      0.41      0.42       100
          6       0.81      0.71      0.76        93
          7       1.00      0.56      0.72        32
          8       0.65      0.67      0.66        96
          9       0.62      0.39      0.47        83
         10       0.52      0.67      0.59       100

avg / total       0.64      0.62      0.62       837

============================================
Running  40  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:50:45
forest model fit end:  2018-04-14 02:51:30
forest model predict start:  2018-04-14 02:51:30
forest model predict end:  2018-04-14 02:51:31
accuracy:  0.573476702509   480 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.64      0.81      0.71       100
          2       0.81      0.67      0.73        33
          3       0.47      0.82      0.59       100
          4       0.79      0.55      0.65       100
          5       0.37      0.40      0.38       100
          6       0.77      0.39      0.51        93
          7       1.00      0.44      0.61        32
          8       0.59      0.52      0.55        96
          9       0.61      0.37      0.46        83
         10       0.53      0.69      0.60       100

avg / total       0.62      0.57      0.57       837

============================================
Running  41  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:51:31
forest model fit end:  2018-04-14 02:52:16
forest model predict start:  2018-04-14 02:52:16
forest model predict end:  2018-04-14 02:52:16
accuracy:  0.590203106332   494 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.75      0.80      0.77       100
          2       0.92      0.67      0.77        33
          3       0.44      0.79      0.56       100
          4       0.77      0.54      0.64       100
          5       0.37      0.40      0.39       100
          6       0.80      0.56      0.66        93
          7       1.00      0.47      0.64        32
          8       0.59      0.53      0.56        96
          9       0.62      0.37      0.47        83
         10       0.53      0.70      0.61       100

avg / total       0.63      0.59      0.59       837

============================================
Running  42  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:52:17
forest model fit end:  2018-04-14 02:53:02
forest model predict start:  2018-04-14 02:53:02
forest model predict end:  2018-04-14 02:53:02
accuracy:  0.563918757467   472 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.65      0.75      0.70       100
          2       0.88      0.67      0.76        33
          3       0.42      0.82      0.55       100
          4       0.74      0.55      0.63       100
          5       0.39      0.37      0.38       100
          6       0.63      0.28      0.39        93
          7       1.00      0.56      0.72        32
          8       0.57      0.56      0.57        96
          9       0.67      0.39      0.49        83
         10       0.55      0.71      0.62       100

avg / total       0.60      0.56      0.56       837

============================================
Running  43  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:53:03
forest model fit end:  2018-04-14 02:53:48
forest model predict start:  2018-04-14 02:53:48
forest model predict end:  2018-04-14 02:53:48
accuracy:  0.565113500597   473 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.63      0.79      0.70       100
          2       0.80      0.73      0.76        33
          3       0.46      0.81      0.59       100
          4       0.73      0.55      0.63       100
          5       0.33      0.30      0.31       100
          6       0.72      0.37      0.49        93
          7       1.00      0.59      0.75        32
          8       0.56      0.56      0.56        96
          9       0.60      0.36      0.45        83
         10       0.53      0.67      0.59       100

avg / total       0.59      0.57      0.56       837

============================================
Running  44  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:53:49
forest model fit end:  2018-04-14 02:54:34
forest model predict start:  2018-04-14 02:54:34
forest model predict end:  2018-04-14 02:54:34
accuracy:  0.620071684588   519 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.70      0.82      0.76       100
          2       0.79      0.67      0.72        33
          3       0.47      0.78      0.59       100
          4       0.76      0.56      0.64       100
          5       0.46      0.41      0.43       100
          6       0.81      0.66      0.73        93
          7       1.00      0.62      0.77        32
          8       0.68      0.66      0.67        96
          9       0.64      0.36      0.46        83
         10       0.52      0.66      0.58       100

avg / total       0.65      0.62      0.62       837

============================================
Running  45  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:54:34
forest model fit end:  2018-04-14 02:55:20
forest model predict start:  2018-04-14 02:55:20
forest model predict end:  2018-04-14 02:55:20
accuracy:  0.554360812425   464 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.64      0.76      0.69       100
          2       0.79      0.67      0.72        33
          3       0.44      0.81      0.57       100
          4       0.75      0.53      0.62       100
          5       0.35      0.40      0.38       100
          6       0.83      0.37      0.51        93
          7       1.00      0.59      0.75        32
          8       0.53      0.44      0.48        96
          9       0.62      0.37      0.47        83
         10       0.50      0.66      0.57       100

avg / total       0.60      0.55      0.55       837

============================================
Running  46  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:55:20
forest model fit end:  2018-04-14 02:56:06
forest model predict start:  2018-04-14 02:56:06
forest model predict end:  2018-04-14 02:56:06
accuracy:  0.58064516129   486 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.76      0.78      0.77       100
          2       0.85      0.67      0.75        33
          3       0.45      0.78      0.57       100
          4       0.72      0.54      0.62       100
          5       0.36      0.36      0.36       100
          6       0.78      0.61      0.69        93
          7       1.00      0.53      0.69        32
          8       0.53      0.52      0.53        96
          9       0.60      0.36      0.45        83
         10       0.52      0.64      0.57       100

avg / total       0.61      0.58      0.58       837

============================================
Running  47  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:56:06
forest model fit end:  2018-04-14 02:56:52
forest model predict start:  2018-04-14 02:56:52
forest model predict end:  2018-04-14 02:56:52
accuracy:  0.572281959379   479 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.67      0.77      0.72       100
          2       0.79      0.67      0.72        33
          3       0.45      0.80      0.57       100
          4       0.75      0.53      0.62       100
          5       0.36      0.37      0.37       100
          6       0.76      0.48      0.59        93
          7       0.95      0.62      0.75        32
          8       0.58      0.50      0.54        96
          9       0.63      0.37      0.47        83
         10       0.51      0.66      0.57       100

avg / total       0.61      0.57      0.57       837

============================================
Running  48  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:56:52
forest model fit end:  2018-04-14 02:57:37
forest model predict start:  2018-04-14 02:57:37
forest model predict end:  2018-04-14 02:57:38
accuracy:  0.583034647551   488 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.66      0.83      0.74       100
          2       0.92      0.73      0.81        33
          3       0.46      0.79      0.59       100
          4       0.71      0.54      0.61       100
          5       0.37      0.39      0.38       100
          6       0.85      0.51      0.64        93
          7       1.00      0.47      0.64        32
          8       0.53      0.49      0.51        96
          9       0.62      0.37      0.47        83
         10       0.54      0.69      0.61       100

avg / total       0.62      0.58      0.58       837

============================================
Running  49  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:57:38
forest model fit end:  2018-04-14 02:58:23
forest model predict start:  2018-04-14 02:58:23
forest model predict end:  2018-04-14 02:58:23
accuracy:  0.599761051374   502 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.73      0.85      0.79       100
          2       0.79      0.67      0.72        33
          3       0.46      0.81      0.58       100
          4       0.73      0.55      0.63       100
          5       0.39      0.36      0.37       100
          6       0.85      0.60      0.70        93
          7       0.94      0.47      0.62        32
          8       0.58      0.58      0.58        96
          9       0.65      0.37      0.47        83
         10       0.53      0.65      0.59       100

avg / total       0.63      0.60      0.60       837

============================================
Running  50  iteration.
============================================
Parameters: n_estimator =  100 , max_depth =  6 , min_samples_leaf =  30
forest model fit start:  2018-04-14 02:58:23
forest model fit end:  2018-04-14 02:59:08
forest model predict start:  2018-04-14 02:59:08
forest model predict end:  2018-04-14 02:59:09
accuracy:  0.597371565114   500 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.72      0.84      0.77       100
          2       0.92      0.70      0.79        33
          3       0.45      0.80      0.58       100
          4       0.77      0.55      0.64       100
          5       0.38      0.41      0.40       100
          6       0.84      0.55      0.66        93
          7       1.00      0.62      0.77        32
          8       0.55      0.46      0.50        96
          9       0.64      0.39      0.48        83
         10       0.54      0.70      0.61       100

avg / total       0.64      0.60      0.60       837

============================================
[0.55555555555555558, 0.62007168458781359, 0.61529271206690561, 0.59259259259259256, 0.58303464755077661, 0.57825567502986863, 0.60573476702508966, 0.59139784946236562, 0.5961768219832736, 0.5961768219832736, 0.58900836320191163, 0.59259259259259256, 0.6069295101553166, 0.59856630824372759, 0.59020310633213857, 0.58422939068100355, 0.56391875746714459, 0.61290322580645162, 0.57706093189964158, 0.55675029868578252, 0.57706093189964158, 0.59259259259259256, 0.60931899641577059, 0.60334528076463556, 0.61170848267622457, 0.56750298685782552, 0.60215053763440862, 0.57228195937873361, 0.58183990442054956, 0.58661887694145753, 0.58781362007168458, 0.58422939068100355, 0.56152927120669061, 0.58183990442054956, 0.59976105137395463, 0.57825567502986863, 0.60215053763440862, 0.6069295101553166, 0.61887694145758665, 0.57347670250896055, 0.59020310633213857, 0.56391875746714459, 0.56511350059737153, 0.62007168458781359, 0.55436081242532853, 0.58064516129032262, 0.57228195937873361, 0.58303464755077661, 0.59976105137395463, 0.59737156511350065]
Avg accuracy:  0.588649940263
