Running  1  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 03:33:14
forest model fit end:  2018-04-14 03:38:41
forest model predict start:  2018-04-14 03:38:41
forest model predict end:  2018-04-14 03:38:43
accuracy:  0.674937965261   544 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.63      0.31      0.42       100
          2       1.00      0.97      0.98        30
          3       0.54      0.64      0.59       100
          4       0.66      0.61      0.64       100
          5       0.79      0.85      0.82       100
          6       0.62      0.68      0.65        88
          7       0.77      0.57      0.65        30
          8       0.67      0.85      0.75        78
          9       0.71      0.88      0.79        80
         10       0.64      0.61      0.63       100

avg / total       0.67      0.67      0.66       806

============================================
Running  2  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 03:38:43
forest model fit end:  2018-04-14 03:44:15
forest model predict start:  2018-04-14 03:44:15
forest model predict end:  2018-04-14 03:44:17
accuracy:  0.674937965261   544 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.67      0.32      0.43       100
          2       1.00      0.97      0.98        30
          3       0.54      0.65      0.59       100
          4       0.65      0.62      0.64       100
          5       0.77      0.81      0.79       100
          6       0.63      0.67      0.65        88
          7       0.78      0.60      0.68        30
          8       0.67      0.83      0.74        78
          9       0.72      0.89      0.79        80
         10       0.65      0.62      0.63       100

avg / total       0.68      0.67      0.67       806

============================================
Running  3  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 03:44:17
forest model fit end:  2018-04-14 03:49:54
forest model predict start:  2018-04-14 03:49:54
forest model predict end:  2018-04-14 03:49:56
accuracy:  0.652605459057   526 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.47      0.15      0.23       100
          2       1.00      0.97      0.98        30
          3       0.53      0.65      0.59       100
          4       0.66      0.62      0.64       100
          5       0.80      0.85      0.83       100
          6       0.52      0.62      0.57        88
          7       0.77      0.57      0.65        30
          8       0.63      0.86      0.72        78
          9       0.72      0.88      0.79        80
         10       0.66      0.61      0.64       100

avg / total       0.64      0.65      0.63       806

============================================
Running  4  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 03:49:56
forest model fit end:  2018-04-14 03:55:28
forest model predict start:  2018-04-14 03:55:28
forest model predict end:  2018-04-14 03:55:29
accuracy:  0.678660049628   547 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.67      0.32      0.43       100
          2       1.00      0.97      0.98        30
          3       0.55      0.65      0.60       100
          4       0.67      0.64      0.65       100
          5       0.79      0.84      0.82       100
          6       0.64      0.65      0.64        88
          7       0.77      0.57      0.65        30
          8       0.66      0.86      0.74        78
          9       0.71      0.88      0.78        80
         10       0.64      0.62      0.63       100

avg / total       0.68      0.68      0.67       806

============================================
Running  5  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 03:55:29
forest model fit end:  2018-04-14 04:01:03
forest model predict start:  2018-04-14 04:01:03
forest model predict end:  2018-04-14 04:01:05
accuracy:  0.673697270471   543 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.70      0.32      0.44       100
          2       1.00      0.97      0.98        30
          3       0.55      0.65      0.59       100
          4       0.65      0.62      0.64       100
          5       0.80      0.81      0.81       100
          6       0.64      0.66      0.65        88
          7       0.74      0.57      0.64        30
          8       0.64      0.86      0.74        78
          9       0.71      0.88      0.78        80
         10       0.63      0.62      0.62       100

avg / total       0.68      0.67      0.66       806

============================================
Running  6  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 04:01:05
forest model fit end:  2018-04-14 04:06:39
forest model predict start:  2018-04-14 04:06:39
forest model predict end:  2018-04-14 04:06:40
accuracy:  0.641439205955   517 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.10      0.02      0.03       100
          2       1.00      0.97      0.98        30
          3       0.54      0.65      0.59       100
          4       0.67      0.62      0.64       100
          5       0.79      0.85      0.82       100
          6       0.47      0.66      0.55        88
          7       0.78      0.60      0.68        30
          8       0.66      0.86      0.75        78
          9       0.73      0.86      0.79        80
         10       0.66      0.62      0.64       100

avg / total       0.60      0.64      0.61       806

============================================
Running  7  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 04:06:41
forest model fit end:  2018-04-14 04:12:12
forest model predict start:  2018-04-14 04:12:12
forest model predict end:  2018-04-14 04:12:14
accuracy:  0.681141439206   549 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.62      0.32      0.42       100
          2       1.00      0.97      0.98        30
          3       0.58      0.65      0.61       100
          4       0.67      0.62      0.65       100
          5       0.81      0.84      0.82       100
          6       0.64      0.69      0.66        88
          7       0.77      0.57      0.65        30
          8       0.67      0.87      0.76        78
          9       0.72      0.88      0.79        80
         10       0.61      0.61      0.61       100

avg / total       0.68      0.68      0.67       806

============================================
Running  8  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 04:12:14
forest model fit end:  2018-04-14 04:17:52
forest model predict start:  2018-04-14 04:17:52
forest model predict end:  2018-04-14 04:17:54
accuracy:  0.686104218362   553 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.67      0.31      0.42       100
          2       0.97      0.97      0.97        30
          3       0.58      0.65      0.61       100
          4       0.67      0.63      0.65       100
          5       0.79      0.83      0.81       100
          6       0.64      0.72      0.67        88
          7       0.77      0.57      0.65        30
          8       0.67      0.86      0.75        78
          9       0.72      0.89      0.79        80
         10       0.65      0.64      0.65       100

avg / total       0.69      0.69      0.68       806

============================================
Running  9  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 04:17:54
forest model fit end:  2018-04-14 04:23:23
forest model predict start:  2018-04-14 04:23:23
forest model predict end:  2018-04-14 04:23:25
accuracy:  0.677419354839   546 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.64      0.32      0.43       100
          2       0.97      0.97      0.97        30
          3       0.56      0.64      0.60       100
          4       0.67      0.62      0.64       100
          5       0.79      0.82      0.80       100
          6       0.65      0.68      0.66        88
          7       0.77      0.57      0.65        30
          8       0.65      0.85      0.74        78
          9       0.72      0.89      0.80        80
         10       0.62      0.63      0.63       100

avg / total       0.68      0.68      0.67       806

============================================
Running  10  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 04:23:25
forest model fit end:  2018-04-14 04:28:54
forest model predict start:  2018-04-14 04:28:54
forest model predict end:  2018-04-14 04:28:55
accuracy:  0.67617866005   545 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.60      0.32      0.42       100
          2       1.00      0.97      0.98        30
          3       0.56      0.65      0.60       100
          4       0.68      0.65      0.66       100
          5       0.79      0.84      0.81       100
          6       0.64      0.65      0.64        88
          7       0.77      0.57      0.65        30
          8       0.65      0.85      0.73        78
          9       0.74      0.89      0.81        80
         10       0.62      0.59      0.61       100

avg / total       0.67      0.68      0.67       806

============================================
Running  11  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 04:28:55
forest model fit end:  2018-04-14 04:34:27
forest model predict start:  2018-04-14 04:34:27
forest model predict end:  2018-04-14 04:34:29
accuracy:  0.643920595533   519 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.20      0.04      0.07       100
          2       1.00      0.97      0.98        30
          3       0.54      0.65      0.59       100
          4       0.65      0.62      0.64       100
          5       0.79      0.84      0.81       100
          6       0.50      0.69      0.58        88
          7       0.77      0.57      0.65        30
          8       0.67      0.85      0.75        78
          9       0.72      0.88      0.79        80
         10       0.64      0.61      0.63       100

avg / total       0.61      0.64      0.61       806

============================================
Running  12  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 04:34:29
forest model fit end:  2018-04-14 04:40:07
forest model predict start:  2018-04-14 04:40:07
forest model predict end:  2018-04-14 04:40:08
accuracy:  0.64888337469   523 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.33      0.08      0.13       100
          2       1.00      0.97      0.98        30
          3       0.55      0.65      0.59       100
          4       0.66      0.63      0.65       100
          5       0.79      0.84      0.82       100
          6       0.50      0.67      0.58        88
          7       0.77      0.57      0.65        30
          8       0.66      0.86      0.74        78
          9       0.74      0.88      0.80        80
         10       0.63      0.61      0.62       100

avg / total       0.63      0.65      0.62       806

============================================
Running  13  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 04:40:09
forest model fit end:  2018-04-14 04:45:58
forest model predict start:  2018-04-14 04:45:58
forest model predict end:  2018-04-14 04:46:00
accuracy:  0.674937965261   544 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.63      0.29      0.40       100
          2       1.00      0.97      0.98        30
          3       0.54      0.64      0.59       100
          4       0.67      0.62      0.65       100
          5       0.80      0.83      0.81       100
          6       0.62      0.68      0.65        88
          7       0.78      0.60      0.68        30
          8       0.66      0.86      0.74        78
          9       0.71      0.88      0.79        80
         10       0.64      0.62      0.63       100

avg / total       0.68      0.67      0.66       806

============================================
Running  14  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 04:46:00
forest model fit end:  2018-04-14 04:51:33
forest model predict start:  2018-04-14 04:51:33
forest model predict end:  2018-04-14 04:51:35
accuracy:  0.677419354839   546 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.63      0.32      0.42       100
          2       1.00      0.97      0.98        30
          3       0.57      0.66      0.61       100
          4       0.65      0.64      0.65       100
          5       0.79      0.84      0.82       100
          6       0.63      0.65      0.64        88
          7       0.77      0.57      0.65        30
          8       0.66      0.85      0.74        78
          9       0.72      0.88      0.79        80
         10       0.63      0.61      0.62       100

avg / total       0.68      0.68      0.67       806

============================================
Running  15  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 04:51:35
forest model fit end:  2018-04-14 04:57:12
forest model predict start:  2018-04-14 04:57:12
forest model predict end:  2018-04-14 04:57:14
accuracy:  0.674937965261   544 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.63      0.31      0.42       100
          2       1.00      0.97      0.98        30
          3       0.56      0.65      0.60       100
          4       0.68      0.63      0.65       100
          5       0.80      0.84      0.82       100
          6       0.60      0.66      0.63        88
          7       0.77      0.57      0.65        30
          8       0.68      0.86      0.76        78
          9       0.70      0.88      0.78        80
         10       0.62      0.60      0.61       100

avg / total       0.68      0.67      0.66       806

============================================
Running  16  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 04:57:14
forest model fit end:  2018-04-14 05:02:41
forest model predict start:  2018-04-14 05:02:41
forest model predict end:  2018-04-14 05:02:43
accuracy:  0.673697270471   543 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.62      0.32      0.42       100
          2       1.00      0.97      0.98        30
          3       0.55      0.64      0.59       100
          4       0.67      0.62      0.64       100
          5       0.80      0.83      0.81       100
          6       0.65      0.67      0.66        88
          7       0.77      0.57      0.65        30
          8       0.65      0.86      0.74        78
          9       0.72      0.89      0.79        80
         10       0.61      0.59      0.60       100

avg / total       0.67      0.67      0.66       806

============================================
Running  17  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 05:02:43
forest model fit end:  2018-04-14 05:08:17
forest model predict start:  2018-04-14 05:08:17
forest model predict end:  2018-04-14 05:08:18
accuracy:  0.677419354839   546 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.64      0.30      0.41       100
          2       1.00      0.97      0.98        30
          3       0.55      0.66      0.60       100
          4       0.66      0.64      0.65       100
          5       0.80      0.84      0.82       100
          6       0.62      0.65      0.63        88
          7       0.78      0.60      0.68        30
          8       0.66      0.86      0.74        78
          9       0.73      0.88      0.80        80
         10       0.64      0.61      0.62       100

avg / total       0.68      0.68      0.67       806

============================================
Running  18  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 05:08:19
forest model fit end:  2018-04-14 05:13:51
forest model predict start:  2018-04-14 05:13:51
forest model predict end:  2018-04-14 05:13:52
accuracy:  0.668734491315   539 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.61      0.30      0.40       100
          2       1.00      0.97      0.98        30
          3       0.56      0.65      0.60       100
          4       0.67      0.62      0.64       100
          5       0.78      0.83      0.80       100
          6       0.58      0.65      0.61        88
          7       0.77      0.57      0.65        30
          8       0.66      0.83      0.73        78
          9       0.72      0.88      0.79        80
         10       0.64      0.61      0.62       100

avg / total       0.67      0.67      0.66       806

============================================
Running  19  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 05:13:53
forest model fit end:  2018-04-14 05:19:24
forest model predict start:  2018-04-14 05:19:24
forest model predict end:  2018-04-14 05:19:25
accuracy:  0.672456575682   542 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.60      0.27      0.37       100
          2       1.00      0.97      0.98        30
          3       0.53      0.65      0.59       100
          4       0.71      0.63      0.67       100
          5       0.79      0.85      0.82       100
          6       0.58      0.66      0.62        88
          7       0.77      0.57      0.65        30
          8       0.67      0.85      0.75        78
          9       0.72      0.89      0.79        80
         10       0.65      0.61      0.63       100

avg / total       0.67      0.67      0.66       806

============================================
Running  20  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 05:19:25
forest model fit end:  2018-04-14 05:25:04
forest model predict start:  2018-04-14 05:25:04
forest model predict end:  2018-04-14 05:25:06
accuracy:  0.667493796526   538 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.58      0.22      0.32       100
          2       1.00      0.97      0.98        30
          3       0.55      0.66      0.60       100
          4       0.67      0.62      0.65       100
          5       0.80      0.85      0.83       100
          6       0.55      0.66      0.60        88
          7       0.78      0.60      0.68        30
          8       0.67      0.86      0.75        78
          9       0.72      0.88      0.79        80
         10       0.64      0.61      0.63       100

avg / total       0.67      0.67      0.65       806

============================================
Running  21  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 05:25:06
forest model fit end:  2018-04-14 05:31:04
forest model predict start:  2018-04-14 05:31:04
forest model predict end:  2018-04-14 05:31:06
accuracy:  0.643920595533   519 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.08      0.02      0.03       100
          2       1.00      0.97      0.98        30
          3       0.58      0.66      0.62       100
          4       0.65      0.62      0.64       100
          5       0.81      0.84      0.82       100
          6       0.50      0.68      0.57        88
          7       0.77      0.57      0.65        30
          8       0.65      0.86      0.74        78
          9       0.72      0.88      0.79        80
         10       0.63      0.62      0.63       100

avg / total       0.60      0.64      0.61       806

============================================
Running  22  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 05:31:06
forest model fit end:  2018-04-14 05:36:51
forest model predict start:  2018-04-14 05:36:51
forest model predict end:  2018-04-14 05:36:53
accuracy:  0.679900744417   548 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.71      0.32      0.44       100
          2       0.97      0.97      0.97        30
          3       0.57      0.64      0.60       100
          4       0.67      0.64      0.65       100
          5       0.78      0.83      0.81       100
          6       0.65      0.68      0.66        88
          7       0.77      0.57      0.65        30
          8       0.63      0.83      0.72        78
          9       0.71      0.88      0.79        80
         10       0.63      0.64      0.64       100

avg / total       0.68      0.68      0.67       806

============================================
Running  23  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 05:36:53
forest model fit end:  2018-04-14 05:42:23
forest model predict start:  2018-04-14 05:42:23
forest model predict end:  2018-04-14 05:42:25
accuracy:  0.677419354839   546 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.62      0.31      0.41       100
          2       1.00      0.97      0.98        30
          3       0.55      0.65      0.60       100
          4       0.67      0.64      0.65       100
          5       0.79      0.83      0.81       100
          6       0.64      0.66      0.65        88
          7       0.77      0.57      0.65        30
          8       0.65      0.86      0.74        78
          9       0.73      0.89      0.80        80
         10       0.64      0.61      0.63       100

avg / total       0.68      0.68      0.67       806

============================================
Running  24  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 05:42:25
forest model fit end:  2018-04-14 05:48:07
forest model predict start:  2018-04-14 05:48:07
forest model predict end:  2018-04-14 05:48:09
accuracy:  0.643920595533   519 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.16      0.04      0.06       100
          2       1.00      0.93      0.97        30
          3       0.55      0.65      0.60       100
          4       0.69      0.64      0.66       100
          5       0.79      0.84      0.82       100
          6       0.49      0.65      0.56        88
          7       0.77      0.57      0.65        30
          8       0.65      0.86      0.74        78
          9       0.72      0.88      0.79        80
         10       0.65      0.63      0.64       100

avg / total       0.61      0.64      0.62       806

============================================
Running  25  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 05:48:09
forest model fit end:  2018-04-14 05:53:35
forest model predict start:  2018-04-14 05:53:35
forest model predict end:  2018-04-14 05:53:36
accuracy:  0.657568238213   530 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.57      0.23      0.33       100
          2       1.00      0.97      0.98        30
          3       0.56      0.65      0.60       100
          4       0.66      0.61      0.63       100
          5       0.79      0.83      0.81       100
          6       0.56      0.62      0.59        88
          7       0.78      0.60      0.68        30
          8       0.62      0.85      0.72        78
          9       0.71      0.88      0.78        80
         10       0.62      0.60      0.61       100

avg / total       0.66      0.66      0.64       806

============================================
Running  26  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 05:53:37
forest model fit end:  2018-04-14 05:59:04
forest model predict start:  2018-04-14 05:59:04
forest model predict end:  2018-04-14 05:59:06
accuracy:  0.673697270471   543 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.64      0.32      0.43       100
          2       1.00      0.97      0.98        30
          3       0.56      0.65      0.60       100
          4       0.67      0.62      0.64       100
          5       0.79      0.82      0.80       100
          6       0.64      0.65      0.64        88
          7       0.77      0.57      0.65        30
          8       0.65      0.85      0.73        78
          9       0.71      0.89      0.79        80
         10       0.62      0.62      0.62       100

avg / total       0.67      0.67      0.66       806

============================================
Running  27  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 05:59:06
forest model fit end:  2018-04-14 06:04:34
forest model predict start:  2018-04-14 06:04:34
forest model predict end:  2018-04-14 06:04:36
accuracy:  0.671215880893   541 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.67      0.30      0.41       100
          2       1.00      0.97      0.98        30
          3       0.56      0.65      0.60       100
          4       0.66      0.63      0.64       100
          5       0.79      0.83      0.81       100
          6       0.61      0.61      0.61        88
          7       0.78      0.60      0.68        30
          8       0.64      0.87      0.74        78
          9       0.70      0.88      0.78        80
         10       0.64      0.61      0.62       100

avg / total       0.67      0.67      0.66       806

============================================
Running  28  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 06:04:36
forest model fit end:  2018-04-14 06:10:15
forest model predict start:  2018-04-14 06:10:15
forest model predict end:  2018-04-14 06:10:16
accuracy:  0.655086848635   528 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.53      0.20      0.29       100
          2       1.00      0.97      0.98        30
          3       0.55      0.64      0.59       100
          4       0.66      0.64      0.65       100
          5       0.81      0.83      0.82       100
          6       0.55      0.61      0.58        88
          7       0.77      0.57      0.65        30
          8       0.61      0.86      0.72        78
          9       0.73      0.88      0.80        80
         10       0.62      0.60      0.61       100

avg / total       0.65      0.66      0.64       806

============================================
Running  29  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 06:10:16
forest model fit end:  2018-04-14 06:15:54
forest model predict start:  2018-04-14 06:15:54
forest model predict end:  2018-04-14 06:15:56
accuracy:  0.646401985112   521 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.29      0.07      0.11       100
          2       0.97      0.97      0.97        30
          3       0.56      0.65      0.60       100
          4       0.67      0.62      0.64       100
          5       0.79      0.84      0.81       100
          6       0.51      0.69      0.59        88
          7       0.77      0.57      0.65        30
          8       0.66      0.83      0.74        78
          9       0.71      0.88      0.79        80
         10       0.62      0.61      0.62       100

avg / total       0.62      0.65      0.62       806

============================================
Running  30  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 06:15:56
forest model fit end:  2018-04-14 06:21:30
forest model predict start:  2018-04-14 06:21:30
forest model predict end:  2018-04-14 06:21:32
accuracy:  0.684863523573   552 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.64      0.32      0.43       100
          2       1.00      0.93      0.97        30
          3       0.57      0.65      0.61       100
          4       0.67      0.64      0.66       100
          5       0.80      0.85      0.83       100
          6       0.66      0.70      0.68        88
          7       0.77      0.57      0.65        30
          8       0.67      0.86      0.75        78
          9       0.69      0.88      0.77        80
         10       0.65      0.62      0.63       100

avg / total       0.68      0.68      0.67       806

============================================
Running  31  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 06:21:32
forest model fit end:  2018-04-14 06:27:14
forest model predict start:  2018-04-14 06:27:14
forest model predict end:  2018-04-14 06:27:16
accuracy:  0.672456575682   542 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.59      0.30      0.40       100
          2       0.97      0.97      0.97        30
          3       0.54      0.65      0.59       100
          4       0.67      0.63      0.65       100
          5       0.79      0.83      0.81       100
          6       0.63      0.65      0.64        88
          7       0.78      0.60      0.68        30
          8       0.66      0.85      0.74        78
          9       0.71      0.88      0.79        80
         10       0.64      0.61      0.63       100

avg / total       0.67      0.67      0.66       806

============================================
Running  32  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 06:27:16
forest model fit end:  2018-04-14 06:32:59
forest model predict start:  2018-04-14 06:32:59
forest model predict end:  2018-04-14 06:33:01
accuracy:  0.674937965261   544 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.68      0.32      0.44       100
          2       1.00      0.97      0.98        30
          3       0.55      0.65      0.60       100
          4       0.64      0.62      0.63       100
          5       0.78      0.83      0.80       100
          6       0.63      0.67      0.65        88
          7       0.78      0.60      0.68        30
          8       0.66      0.83      0.73        78
          9       0.74      0.88      0.80        80
         10       0.62      0.61      0.62       100

avg / total       0.68      0.67      0.67       806

============================================
Running  33  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 06:33:01
forest model fit end:  2018-04-14 06:38:31
forest model predict start:  2018-04-14 06:38:31
forest model predict end:  2018-04-14 06:38:32
accuracy:  0.653846153846   527 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.42      0.14      0.21       100
          2       1.00      0.97      0.98        30
          3       0.55      0.66      0.60       100
          4       0.65      0.62      0.63       100
          5       0.80      0.82      0.81       100
          6       0.53      0.66      0.59        88
          7       0.77      0.57      0.65        30
          8       0.66      0.86      0.75        78
          9       0.73      0.88      0.80        80
         10       0.63      0.62      0.63       100

avg / total       0.64      0.65      0.63       806

============================================
Running  34  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 06:38:33
forest model fit end:  2018-04-14 06:44:07
forest model predict start:  2018-04-14 06:44:07
forest model predict end:  2018-04-14 06:44:08
accuracy:  0.660049627792   532 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.49      0.18      0.26       100
          2       1.00      0.97      0.98        30
          3       0.55      0.65      0.59       100
          4       0.68      0.63      0.65       100
          5       0.79      0.84      0.81       100
          6       0.54      0.65      0.59        88
          7       0.77      0.57      0.65        30
          8       0.65      0.85      0.73        78
          9       0.72      0.88      0.79        80
         10       0.67      0.63      0.65       100

avg / total       0.65      0.66      0.64       806

============================================
Running  35  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 06:44:09
forest model fit end:  2018-04-14 06:49:40
forest model predict start:  2018-04-14 06:49:40
forest model predict end:  2018-04-14 06:49:42
accuracy:  0.647642679901   522 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.14      0.03      0.05       100
          2       1.00      0.97      0.98        30
          3       0.55      0.65      0.59       100
          4       0.69      0.65      0.67       100
          5       0.81      0.84      0.82       100
          6       0.48      0.65      0.55        88
          7       0.77      0.57      0.65        30
          8       0.68      0.88      0.77        78
          9       0.71      0.88      0.78        80
         10       0.64      0.63      0.64       100

avg / total       0.61      0.65      0.62       806

============================================
Running  36  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 06:49:42
forest model fit end:  2018-04-14 06:55:40
forest model predict start:  2018-04-14 06:55:40
forest model predict end:  2018-04-14 06:55:42
accuracy:  0.637717121588   514 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.06      0.01      0.02       100
          2       0.97      0.97      0.97        30
          3       0.54      0.65      0.59       100
          4       0.66      0.63      0.64       100
          5       0.78      0.83      0.81       100
          6       0.47      0.66      0.55        88
          7       0.79      0.63      0.70        30
          8       0.66      0.83      0.74        78
          9       0.73      0.88      0.80        80
         10       0.64      0.61      0.63       100

avg / total       0.59      0.64      0.61       806

============================================
Running  37  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 06:55:42
forest model fit end:  2018-04-14 07:01:21
forest model predict start:  2018-04-14 07:01:21
forest model predict end:  2018-04-14 07:01:23
accuracy:  0.667493796526   538 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.57      0.21      0.31       100
          2       1.00      0.97      0.98        30
          3       0.54      0.65      0.59       100
          4       0.66      0.63      0.64       100
          5       0.80      0.83      0.81       100
          6       0.59      0.69      0.64        88
          7       0.77      0.57      0.65        30
          8       0.67      0.86      0.75        78
          9       0.71      0.88      0.79        80
         10       0.65      0.62      0.63       100

avg / total       0.66      0.67      0.65       806

============================================
Running  38  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 07:01:23
forest model fit end:  2018-04-14 07:07:01
forest model predict start:  2018-04-14 07:07:01
forest model predict end:  2018-04-14 07:07:02
accuracy:  0.657568238213   530 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.52      0.17      0.26       100
          2       1.00      0.97      0.98        30
          3       0.55      0.65      0.60       100
          4       0.64      0.63      0.64       100
          5       0.79      0.84      0.82       100
          6       0.54      0.66      0.59        88
          7       0.77      0.57      0.65        30
          8       0.63      0.85      0.73        78
          9       0.74      0.88      0.80        80
         10       0.64      0.61      0.63       100

avg / total       0.65      0.66      0.64       806

============================================
Running  39  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 07:07:02
forest model fit end:  2018-04-14 07:12:29
forest model predict start:  2018-04-14 07:12:29
forest model predict end:  2018-04-14 07:12:31
accuracy:  0.679900744417   548 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.64      0.32      0.43       100
          2       1.00      0.97      0.98        30
          3       0.55      0.65      0.60       100
          4       0.66      0.65      0.66       100
          5       0.80      0.83      0.81       100
          6       0.64      0.67      0.66        88
          7       0.77      0.57      0.65        30
          8       0.66      0.86      0.74        78
          9       0.73      0.88      0.80        80
         10       0.64      0.61      0.63       100

avg / total       0.68      0.68      0.67       806

============================================
Running  40  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 07:12:31
forest model fit end:  2018-04-14 07:17:55
forest model predict start:  2018-04-14 07:17:55
forest model predict end:  2018-04-14 07:17:57
accuracy:  0.674937965261   544 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.65      0.32      0.43       100
          2       0.97      0.97      0.97        30
          3       0.55      0.64      0.59       100
          4       0.68      0.62      0.65       100
          5       0.79      0.85      0.82       100
          6       0.63      0.65      0.64        88
          7       0.78      0.60      0.68        30
          8       0.65      0.83      0.73        78
          9       0.71      0.88      0.78        80
         10       0.63      0.62      0.63       100

avg / total       0.68      0.67      0.67       806

============================================
Running  41  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 07:17:57
forest model fit end:  2018-04-14 07:23:25
forest model predict start:  2018-04-14 07:23:25
forest model predict end:  2018-04-14 07:23:27
accuracy:  0.679900744417   548 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.67      0.32      0.43       100
          2       1.00      0.97      0.98        30
          3       0.54      0.65      0.59       100
          4       0.66      0.63      0.65       100
          5       0.80      0.84      0.82       100
          6       0.65      0.68      0.66        88
          7       0.77      0.57      0.65        30
          8       0.65      0.86      0.74        78
          9       0.73      0.88      0.80        80
         10       0.65      0.61      0.63       100

avg / total       0.68      0.68      0.67       806

============================================
Running  42  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 07:23:27
forest model fit end:  2018-04-14 07:29:00
forest model predict start:  2018-04-14 07:29:00
forest model predict end:  2018-04-14 07:29:02
accuracy:  0.678660049628   547 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.65      0.31      0.42       100
          2       1.00      0.97      0.98        30
          3       0.55      0.65      0.59       100
          4       0.65      0.64      0.65       100
          5       0.79      0.83      0.81       100
          6       0.62      0.67      0.64        88
          7       0.79      0.63      0.70        30
          8       0.67      0.86      0.75        78
          9       0.74      0.88      0.80        80
         10       0.64      0.60      0.62       100

avg / total       0.68      0.68      0.67       806

============================================
Running  43  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 07:29:02
forest model fit end:  2018-04-14 07:34:36
forest model predict start:  2018-04-14 07:34:36
forest model predict end:  2018-04-14 07:34:38
accuracy:  0.68982630273   556 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.68      0.32      0.44       100
          2       0.97      0.97      0.97        30
          3       0.61      0.65      0.63       100
          4       0.67      0.62      0.64       100
          5       0.80      0.85      0.83       100
          6       0.67      0.75      0.71        88
          7       0.78      0.60      0.68        30
          8       0.66      0.86      0.74        78
          9       0.71      0.88      0.79        80
         10       0.61      0.62      0.61       100

avg / total       0.69      0.69      0.68       806

============================================
Running  44  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 07:34:38
forest model fit end:  2018-04-14 07:40:06
forest model predict start:  2018-04-14 07:40:06
forest model predict end:  2018-04-14 07:40:08
accuracy:  0.683622828784   551 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.70      0.32      0.44       100
          2       1.00      0.97      0.98        30
          3       0.57      0.64      0.60       100
          4       0.69      0.65      0.67       100
          5       0.79      0.85      0.82       100
          6       0.64      0.69      0.66        88
          7       0.77      0.57      0.65        30
          8       0.66      0.86      0.74        78
          9       0.71      0.88      0.78        80
         10       0.63      0.61      0.62       100

avg / total       0.69      0.68      0.67       806

============================================
Running  45  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 07:40:08
forest model fit end:  2018-04-14 07:45:40
forest model predict start:  2018-04-14 07:45:40
forest model predict end:  2018-04-14 07:45:41
accuracy:  0.643920595533   519 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.24      0.06      0.10       100
          2       1.00      0.97      0.98        30
          3       0.56      0.64      0.60       100
          4       0.66      0.63      0.65       100
          5       0.81      0.83      0.82       100
          6       0.50      0.67      0.58        88
          7       0.77      0.57      0.65        30
          8       0.64      0.86      0.73        78
          9       0.72      0.88      0.79        80
         10       0.62      0.61      0.61       100

avg / total       0.61      0.64      0.62       806

============================================
Running  46  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 07:45:42
forest model fit end:  2018-04-14 07:51:14
forest model predict start:  2018-04-14 07:51:14
forest model predict end:  2018-04-14 07:51:16
accuracy:  0.657568238213   530 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.47      0.16      0.24       100
          2       1.00      0.97      0.98        30
          3       0.58      0.66      0.62       100
          4       0.68      0.65      0.66       100
          5       0.78      0.83      0.81       100
          6       0.54      0.64      0.58        88
          7       0.77      0.57      0.65        30
          8       0.61      0.83      0.71        78
          9       0.71      0.88      0.78        80
         10       0.66      0.63      0.64       100

avg / total       0.65      0.66      0.64       806

============================================
Running  47  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 07:51:16
forest model fit end:  2018-04-14 07:56:54
forest model predict start:  2018-04-14 07:56:54
forest model predict end:  2018-04-14 07:56:56
accuracy:  0.656327543424   529 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.53      0.18      0.27       100
          2       1.00      0.97      0.98        30
          3       0.54      0.64      0.59       100
          4       0.67      0.64      0.66       100
          5       0.80      0.83      0.81       100
          6       0.54      0.62      0.58        88
          7       0.77      0.57      0.65        30
          8       0.62      0.86      0.72        78
          9       0.71      0.88      0.79        80
         10       0.64      0.62      0.63       100

avg / total       0.65      0.66      0.64       806

============================================
Running  48  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 07:56:56
forest model fit end:  2018-04-14 08:02:23
forest model predict start:  2018-04-14 08:02:23
forest model predict end:  2018-04-14 08:02:25
accuracy:  0.67617866005   545 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.59      0.27      0.37       100
          2       1.00      0.97      0.98        30
          3       0.56      0.65      0.60       100
          4       0.67      0.64      0.66       100
          5       0.79      0.84      0.82       100
          6       0.62      0.69      0.66        88
          7       0.77      0.57      0.65        30
          8       0.66      0.85      0.74        78
          9       0.72      0.88      0.79        80
         10       0.65      0.62      0.63       100

avg / total       0.67      0.68      0.66       806

============================================
Running  49  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 08:02:25
forest model fit end:  2018-04-14 08:07:50
forest model predict start:  2018-04-14 08:07:50
forest model predict end:  2018-04-14 08:07:52
accuracy:  0.67617866005   545 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.61      0.30      0.40       100
          2       1.00      0.97      0.98        30
          3       0.57      0.66      0.61       100
          4       0.66      0.63      0.65       100
          5       0.79      0.84      0.82       100
          6       0.62      0.66      0.64        88
          7       0.77      0.57      0.65        30
          8       0.66      0.87      0.75        78
          9       0.71      0.88      0.79        80
         10       0.64      0.60      0.62       100

avg / total       0.67      0.68      0.67       806

============================================
Running  50  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 08:07:52
forest model fit end:  2018-04-14 08:13:29
forest model predict start:  2018-04-14 08:13:29
forest model predict end:  2018-04-14 08:13:31
accuracy:  0.679900744417   548 / 806
Testing folds:  [ 8.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 9, 10]
             precision    recall  f1-score   support

          1       0.64      0.32      0.43       100
          2       1.00      0.97      0.98        30
          3       0.54      0.64      0.59       100
          4       0.67      0.63      0.65       100
          5       0.81      0.84      0.82       100
          6       0.64      0.66      0.65        88
          7       0.78      0.60      0.68        30
          8       0.67      0.86      0.75        78
          9       0.72      0.88      0.79        80
         10       0.62      0.63      0.63       100

avg / total       0.68      0.68      0.67       806

============================================
[0.67493796526054595, 0.67493796526054595, 0.65260545905707201, 0.67866004962779158, 0.67369727047146399, 0.64143920595533499, 0.68114143920595538, 0.68610421836228286, 0.67741935483870963, 0.67617866004962779, 0.64392059553349879, 0.64888337468982626, 0.67493796526054595, 0.67741935483870963, 0.67493796526054595, 0.67369727047146399, 0.67741935483870963, 0.66873449131513651, 0.67245657568238215, 0.66749379652605456, 0.64392059553349879, 0.67990074441687343, 0.67741935483870963, 0.64392059553349879, 0.65756823821339949, 0.67369727047146399, 0.6712158808933002, 0.6550868486352357, 0.64640198511166258, 0.68486352357320102, 0.67245657568238215, 0.67493796526054595, 0.65384615384615385, 0.66004962779156329, 0.64764267990074442, 0.63771712158808935, 0.66749379652605456, 0.65756823821339949, 0.67990074441687343, 0.67493796526054595, 0.67990074441687343, 0.67866004962779158, 0.6898263027295285, 0.68362282878411906, 0.64392059553349879, 0.65756823821339949, 0.65632754342431765, 0.67617866004962779, 0.67617866004962779, 0.67990074441687343]
Avg accuracy:  0.667593052109
