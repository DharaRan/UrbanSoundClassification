Running  1  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 03:33:43
forest model fit end:  2018-04-14 03:39:14
forest model predict start:  2018-04-14 03:39:14
forest model predict end:  2018-04-14 03:39:15
accuracy:  0.613970588235   501 / 816
Testing folds:  [ 9.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 10]
             precision    recall  f1-score   support

          1       0.54      0.21      0.30       100
          2       1.00      0.78      0.88        32
          3       0.44      0.66      0.53       100
          4       0.83      0.60      0.70       100
          5       0.37      0.42      0.39       100
          6       0.88      0.82      0.85        89
          7       0.89      0.52      0.65        31
          8       0.52      0.61      0.56        82
          9       0.76      0.95      0.84        82
         10       0.61      0.70      0.65       100

avg / total       0.64      0.61      0.61       816

============================================
Running  2  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 03:39:16
forest model fit end:  2018-04-14 03:45:13
forest model predict start:  2018-04-14 03:45:13
forest model predict end:  2018-04-14 03:45:15
accuracy:  0.611519607843   499 / 816
Testing folds:  [ 9.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 10]
             precision    recall  f1-score   support

          1       0.53      0.20      0.29       100
          2       1.00      0.75      0.86        32
          3       0.44      0.67      0.53       100
          4       0.81      0.59      0.68       100
          5       0.37      0.43      0.40       100
          6       0.86      0.84      0.85        89
          7       0.89      0.52      0.65        31
          8       0.53      0.61      0.57        82
          9       0.76      0.93      0.84        82
         10       0.62      0.69      0.65       100

avg / total       0.63      0.61      0.60       816

============================================
Running  3  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 03:45:15
forest model fit end:  2018-04-14 03:50:53
forest model predict start:  2018-04-14 03:50:53
forest model predict end:  2018-04-14 03:50:55
accuracy:  0.612745098039   500 / 816
Testing folds:  [ 9.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 10]
             precision    recall  f1-score   support

          1       0.43      0.20      0.27       100
          2       1.00      0.78      0.88        32
          3       0.46      0.70      0.56       100
          4       0.82      0.60      0.69       100
          5       0.37      0.43      0.40       100
          6       0.86      0.78      0.82        89
          7       0.94      0.48      0.64        31
          8       0.53      0.61      0.56        82
          9       0.77      0.94      0.85        82
         10       0.62      0.71      0.66       100

avg / total       0.63      0.61      0.61       816

============================================
Running  4  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 03:50:55
forest model fit end:  2018-04-14 03:56:51
forest model predict start:  2018-04-14 03:56:51
forest model predict end:  2018-04-14 03:56:53
accuracy:  0.610294117647   498 / 816
Testing folds:  [ 9.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 10]
             precision    recall  f1-score   support

          1       0.49      0.21      0.29       100
          2       1.00      0.78      0.88        32
          3       0.43      0.68      0.53       100
          4       0.83      0.57      0.67       100
          5       0.37      0.43      0.40       100
          6       0.88      0.83      0.86        89
          7       0.88      0.45      0.60        31
          8       0.53      0.61      0.56        82
          9       0.77      0.94      0.85        82
         10       0.62      0.69      0.65       100

avg / total       0.63      0.61      0.60       816

============================================
Running  5  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 03:56:53
forest model fit end:  2018-04-14 04:02:44
forest model predict start:  2018-04-14 04:02:44
forest model predict end:  2018-04-14 04:02:46
accuracy:  0.609068627451   497 / 816
Testing folds:  [ 9.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 10]
             precision    recall  f1-score   support

          1       0.44      0.21      0.28       100
          2       1.00      0.81      0.90        32
          3       0.44      0.67      0.53       100
          4       0.81      0.59      0.68       100
          5       0.38      0.43      0.40       100
          6       0.88      0.80      0.84        89
          7       0.93      0.42      0.58        31
          8       0.53      0.61      0.56        82
          9       0.76      0.93      0.84        82
         10       0.62      0.71      0.66       100

avg / total       0.63      0.61      0.60       816

============================================
Running  6  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 04:02:46
forest model fit end:  2018-04-14 04:08:24
forest model predict start:  2018-04-14 04:08:24
forest model predict end:  2018-04-14 04:08:26
accuracy:  0.609068627451   497 / 816
Testing folds:  [ 9.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 10]
             precision    recall  f1-score   support

          1       0.45      0.18      0.26       100
          2       0.96      0.75      0.84        32
          3       0.44      0.67      0.53       100
          4       0.83      0.60      0.70       100
          5       0.37      0.43      0.40       100
          6       0.84      0.82      0.83        89
          7       0.88      0.48      0.62        31
          8       0.53      0.61      0.56        82
          9       0.77      0.95      0.85        82
         10       0.62      0.69      0.65       100

avg / total       0.63      0.61      0.60       816

============================================
Running  7  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 04:08:26
forest model fit end:  2018-04-14 04:14:06
forest model predict start:  2018-04-14 04:14:06
forest model predict end:  2018-04-14 04:14:08
accuracy:  0.611519607843   499 / 816
Testing folds:  [ 9.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 10]
             precision    recall  f1-score   support

          1       0.53      0.21      0.30       100
          2       1.00      0.75      0.86        32
          3       0.44      0.67      0.53       100
          4       0.81      0.59      0.68       100
          5       0.37      0.43      0.40       100
          6       0.84      0.82      0.83        89
          7       0.88      0.48      0.62        31
          8       0.53      0.61      0.56        82
          9       0.76      0.93      0.84        82
         10       0.63      0.71      0.67       100

avg / total       0.63      0.61      0.60       816

============================================
Running  8  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 04:14:08
forest model fit end:  2018-04-14 04:19:46
forest model predict start:  2018-04-14 04:19:46
forest model predict end:  2018-04-14 04:19:48
accuracy:  0.610294117647   498 / 816
Testing folds:  [ 9.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 10]
             precision    recall  f1-score   support

          1       0.50      0.17      0.25       100
          2       1.00      0.72      0.84        32
          3       0.44      0.67      0.53       100
          4       0.81      0.59      0.68       100
          5       0.37      0.43      0.40       100
          6       0.82      0.88      0.85        89
          7       0.94      0.48      0.64        31
          8       0.52      0.61      0.56        82
          9       0.76      0.93      0.84        82
         10       0.64      0.70      0.67       100

avg / total       0.63      0.61      0.60       816

============================================
Running  9  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 04:19:48
forest model fit end:  2018-04-14 04:25:22
forest model predict start:  2018-04-14 04:25:22
forest model predict end:  2018-04-14 04:25:24
accuracy:  0.610294117647   498 / 816
Testing folds:  [ 9.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 10]
             precision    recall  f1-score   support

          1       0.49      0.21      0.29       100
          2       1.00      0.75      0.86        32
          3       0.43      0.67      0.53       100
          4       0.81      0.60      0.69       100
          5       0.37      0.43      0.40       100
          6       0.88      0.81      0.84        89
          7       0.94      0.52      0.67        31
          8       0.53      0.61      0.57        82
          9       0.76      0.93      0.84        82
         10       0.62      0.69      0.65       100

avg / total       0.63      0.61      0.61       816

============================================
Running  10  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 04:25:24
forest model fit end:  2018-04-14 04:30:56
forest model predict start:  2018-04-14 04:30:56
forest model predict end:  2018-04-14 04:30:58
accuracy:  0.610294117647   498 / 816
Testing folds:  [ 9.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 10]
             precision    recall  f1-score   support

          1       0.51      0.21      0.30       100
          2       1.00      0.78      0.88        32
          3       0.44      0.67      0.53       100
          4       0.81      0.58      0.67       100
          5       0.37      0.43      0.40       100
          6       0.84      0.80      0.82        89
          7       0.89      0.55      0.68        31
          8       0.54      0.61      0.57        82
          9       0.76      0.93      0.84        82
         10       0.62      0.70      0.66       100

avg / total       0.63      0.61      0.60       816

============================================
Running  11  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 04:30:58
forest model fit end:  2018-04-14 04:36:35
forest model predict start:  2018-04-14 04:36:35
forest model predict end:  2018-04-14 04:36:37
accuracy:  0.609068627451   497 / 816
Testing folds:  [ 9.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 10]
             precision    recall  f1-score   support

          1       0.45      0.19      0.27       100
          2       1.00      0.78      0.88        32
          3       0.43      0.65      0.52       100
          4       0.81      0.61      0.70       100
          5       0.37      0.43      0.40       100
          6       0.88      0.80      0.84        89
          7       0.89      0.52      0.65        31
          8       0.53      0.61      0.57        82
          9       0.75      0.94      0.83        82
         10       0.63      0.70      0.66       100

avg / total       0.63      0.61      0.60       816

============================================
Running  12  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 04:36:37
forest model fit end:  2018-04-14 04:42:14
forest model predict start:  2018-04-14 04:42:14
forest model predict end:  2018-04-14 04:42:16
accuracy:  0.616421568627   503 / 816
Testing folds:  [ 9.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 10]
             precision    recall  f1-score   support

          1       0.50      0.21      0.30       100
          2       1.00      0.75      0.86        32
          3       0.44      0.67      0.53       100
          4       0.82      0.60      0.69       100
          5       0.38      0.43      0.41       100
          6       0.89      0.82      0.85        89
          7       0.89      0.55      0.68        31
          8       0.52      0.61      0.56        82
          9       0.76      0.94      0.84        82
         10       0.63      0.71      0.67       100

avg / total       0.64      0.62      0.61       816

============================================
Running  13  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 04:42:16
forest model fit end:  2018-04-14 04:47:53
forest model predict start:  2018-04-14 04:47:53
forest model predict end:  2018-04-14 04:47:54
accuracy:  0.609068627451   497 / 816
Testing folds:  [ 9.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 10]
             precision    recall  f1-score   support

          1       0.46      0.19      0.27       100
          2       1.00      0.75      0.86        32
          3       0.44      0.67      0.53       100
          4       0.82      0.59      0.69       100
          5       0.38      0.43      0.40       100
          6       0.86      0.82      0.84        89
          7       0.94      0.48      0.64        31
          8       0.52      0.61      0.56        82
          9       0.75      0.93      0.83        82
         10       0.63      0.71      0.67       100

avg / total       0.63      0.61      0.60       816

============================================
Running  14  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 04:47:55
forest model fit end:  2018-04-14 04:53:31
forest model predict start:  2018-04-14 04:53:31
forest model predict end:  2018-04-14 04:53:33
accuracy:  0.606617647059   495 / 816
Testing folds:  [ 9.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 10]
             precision    recall  f1-score   support

          1       0.49      0.21      0.29       100
          2       1.00      0.75      0.86        32
          3       0.44      0.68      0.53       100
          4       0.81      0.58      0.67       100
          5       0.37      0.43      0.40       100
          6       0.83      0.78      0.80        89
          7       0.89      0.52      0.65        31
          8       0.53      0.61      0.57        82
          9       0.77      0.93      0.84        82
         10       0.62      0.70      0.66       100

avg / total       0.63      0.61      0.60       816

============================================
Running  15  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 04:53:33
forest model fit end:  2018-04-14 04:59:10
forest model predict start:  2018-04-14 04:59:10
forest model predict end:  2018-04-14 04:59:11
accuracy:  0.615196078431   502 / 816
Testing folds:  [ 9.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 10]
             precision    recall  f1-score   support

          1       0.50      0.20      0.29       100
          2       1.00      0.78      0.88        32
          3       0.44      0.67      0.53       100
          4       0.82      0.60      0.69       100
          5       0.37      0.43      0.40       100
          6       0.87      0.84      0.86        89
          7       0.84      0.52      0.64        31
          8       0.54      0.61      0.57        82
          9       0.76      0.93      0.84        82
         10       0.62      0.70      0.66       100

avg / total       0.63      0.62      0.61       816

============================================
Running  16  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 04:59:12
forest model fit end:  2018-04-14 05:04:53
forest model predict start:  2018-04-14 05:04:53
forest model predict end:  2018-04-14 05:04:55
accuracy:  0.610294117647   498 / 816
Testing folds:  [ 9.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 10]
             precision    recall  f1-score   support

          1       0.48      0.21      0.29       100
          2       1.00      0.75      0.86        32
          3       0.44      0.67      0.53       100
          4       0.82      0.58      0.68       100
          5       0.37      0.43      0.40       100
          6       0.89      0.81      0.85        89
          7       0.94      0.52      0.67        31
          8       0.53      0.61      0.56        82
          9       0.76      0.95      0.84        82
         10       0.61      0.69      0.65       100

avg / total       0.63      0.61      0.61       816

============================================
Running  17  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 05:04:55
forest model fit end:  2018-04-14 05:10:36
forest model predict start:  2018-04-14 05:10:36
forest model predict end:  2018-04-14 05:10:38
accuracy:  0.615196078431   502 / 816
Testing folds:  [ 9.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 10]
             precision    recall  f1-score   support

          1       0.50      0.21      0.30       100
          2       0.96      0.78      0.86        32
          3       0.44      0.67      0.53       100
          4       0.82      0.60      0.69       100
          5       0.38      0.43      0.40       100
          6       0.91      0.82      0.86        89
          7       0.83      0.48      0.61        31
          8       0.53      0.61      0.56        82
          9       0.76      0.94      0.84        82
         10       0.62      0.71      0.66       100

avg / total       0.64      0.62      0.61       816

============================================
Running  18  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 05:10:39
forest model fit end:  2018-04-14 05:16:16
forest model predict start:  2018-04-14 05:16:16
forest model predict end:  2018-04-14 05:16:17
accuracy:  0.616421568627   503 / 816
Testing folds:  [ 9.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 10]
             precision    recall  f1-score   support

          1       0.50      0.21      0.30       100
          2       1.00      0.78      0.88        32
          3       0.45      0.68      0.54       100
          4       0.82      0.58      0.68       100
          5       0.37      0.43      0.40       100
          6       0.86      0.84      0.85        89
          7       0.83      0.48      0.61        31
          8       0.54      0.61      0.57        82
          9       0.77      0.94      0.85        82
         10       0.62      0.71      0.66       100

avg / total       0.64      0.62      0.61       816

============================================
Running  19  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 05:16:17
forest model fit end:  2018-04-14 05:21:58
forest model predict start:  2018-04-14 05:21:58
forest model predict end:  2018-04-14 05:22:00
accuracy:  0.611519607843   499 / 816
Testing folds:  [ 9.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 10]
             precision    recall  f1-score   support

          1       0.50      0.21      0.30       100
          2       1.00      0.78      0.88        32
          3       0.44      0.67      0.53       100
          4       0.82      0.60      0.69       100
          5       0.38      0.43      0.40       100
          6       0.84      0.79      0.81        89
          7       0.89      0.55      0.68        31
          8       0.53      0.61      0.57        82
          9       0.76      0.91      0.83        82
         10       0.62      0.71      0.66       100

avg / total       0.63      0.61      0.61       816

============================================
Running  20  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 05:22:00
forest model fit end:  2018-04-14 05:27:40
forest model predict start:  2018-04-14 05:27:40
forest model predict end:  2018-04-14 05:27:42
accuracy:  0.610294117647   498 / 816
Testing folds:  [ 9.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 10]
             precision    recall  f1-score   support

          1       0.48      0.21      0.29       100
          2       1.00      0.75      0.86        32
          3       0.44      0.66      0.53       100
          4       0.82      0.59      0.69       100
          5       0.37      0.43      0.40       100
          6       0.87      0.80      0.83        89
          7       0.89      0.55      0.68        31
          8       0.54      0.61      0.57        82
          9       0.75      0.93      0.83        82
         10       0.62      0.71      0.66       100

avg / total       0.63      0.61      0.61       816

============================================
Running  21  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 05:27:42
forest model fit end:  2018-04-14 05:33:16
forest model predict start:  2018-04-14 05:33:16
forest model predict end:  2018-04-14 05:33:18
accuracy:  0.605392156863   494 / 816
Testing folds:  [ 9.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 10]
             precision    recall  f1-score   support

          1       0.39      0.16      0.23       100
          2       1.00      0.75      0.86        32
          3       0.44      0.68      0.54       100
          4       0.82      0.59      0.69       100
          5       0.37      0.43      0.40       100
          6       0.86      0.79      0.82        89
          7       0.89      0.55      0.68        31
          8       0.54      0.61      0.57        82
          9       0.75      0.94      0.84        82
         10       0.61      0.70      0.65       100

avg / total       0.62      0.61      0.60       816

============================================
Running  22  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 05:33:18
forest model fit end:  2018-04-14 05:38:57
forest model predict start:  2018-04-14 05:38:57
forest model predict end:  2018-04-14 05:38:59
accuracy:  0.607843137255   496 / 816
Testing folds:  [ 9.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 10]
             precision    recall  f1-score   support

          1       0.47      0.19      0.27       100
          2       0.96      0.75      0.84        32
          3       0.44      0.68      0.53       100
          4       0.82      0.59      0.69       100
          5       0.37      0.43      0.40       100
          6       0.83      0.81      0.82        89
          7       0.85      0.55      0.67        31
          8       0.54      0.61      0.57        82
          9       0.77      0.93      0.84        82
         10       0.61      0.68      0.64       100

avg / total       0.63      0.61      0.60       816

============================================
Running  23  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 05:38:59
forest model fit end:  2018-04-14 05:44:31
forest model predict start:  2018-04-14 05:44:31
forest model predict end:  2018-04-14 05:44:32
accuracy:  0.607843137255   496 / 816
Testing folds:  [ 9.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 10]
             precision    recall  f1-score   support

          1       0.49      0.21      0.29       100
          2       1.00      0.78      0.88        32
          3       0.43      0.66      0.52       100
          4       0.81      0.59      0.68       100
          5       0.36      0.43      0.39       100
          6       0.88      0.79      0.83        89
          7       0.89      0.52      0.65        31
          8       0.54      0.61      0.57        82
          9       0.75      0.93      0.83        82
         10       0.63      0.70      0.66       100

avg / total       0.63      0.61      0.60       816

============================================
Running  24  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 05:44:32
forest model fit end:  2018-04-14 05:50:08
forest model predict start:  2018-04-14 05:50:08
forest model predict end:  2018-04-14 05:50:10
accuracy:  0.617647058824   504 / 816
Testing folds:  [ 9.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 10]
             precision    recall  f1-score   support

          1       0.53      0.21      0.30       100
          2       1.00      0.78      0.88        32
          3       0.44      0.66      0.53       100
          4       0.84      0.59      0.69       100
          5       0.38      0.43      0.40       100
          6       0.85      0.83      0.84        89
          7       0.89      0.55      0.68        31
          8       0.54      0.61      0.57        82
          9       0.76      0.94      0.84        82
         10       0.62      0.72      0.67       100

avg / total       0.64      0.62      0.61       816

============================================
Running  25  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 05:50:10
forest model fit end:  2018-04-14 05:55:38
forest model predict start:  2018-04-14 05:55:38
forest model predict end:  2018-04-14 05:55:40
accuracy:  0.612745098039   500 / 816
Testing folds:  [ 9.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 10]
             precision    recall  f1-score   support

          1       0.53      0.19      0.28       100
          2       1.00      0.75      0.86        32
          3       0.43      0.67      0.53       100
          4       0.83      0.59      0.69       100
          5       0.37      0.43      0.40       100
          6       0.84      0.85      0.84        89
          7       0.89      0.55      0.68        31
          8       0.53      0.61      0.57        82
          9       0.76      0.91      0.83        82
         10       0.62      0.70      0.66       100

avg / total       0.64      0.61      0.61       816

============================================
Running  26  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 05:55:40
forest model fit end:  2018-04-14 06:01:16
forest model predict start:  2018-04-14 06:01:16
forest model predict end:  2018-04-14 06:01:18
accuracy:  0.610294117647   498 / 816
Testing folds:  [ 9.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 10]
             precision    recall  f1-score   support

          1       0.51      0.20      0.29       100
          2       1.00      0.78      0.88        32
          3       0.43      0.67      0.52       100
          4       0.81      0.58      0.67       100
          5       0.37      0.43      0.40       100
          6       0.86      0.82      0.84        89
          7       0.85      0.55      0.67        31
          8       0.54      0.61      0.57        82
          9       0.76      0.93      0.84        82
         10       0.62      0.69      0.65       100

avg / total       0.63      0.61      0.60       816

============================================
Running  27  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 06:01:18
forest model fit end:  2018-04-14 06:06:53
forest model predict start:  2018-04-14 06:06:53
forest model predict end:  2018-04-14 06:06:54
accuracy:  0.611519607843   499 / 816
Testing folds:  [ 9.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 10]
             precision    recall  f1-score   support

          1       0.51      0.21      0.30       100
          2       1.00      0.78      0.88        32
          3       0.43      0.67      0.53       100
          4       0.81      0.59      0.68       100
          5       0.38      0.43      0.40       100
          6       0.88      0.83      0.86        89
          7       0.94      0.48      0.64        31
          8       0.51      0.61      0.56        82
          9       0.76      0.91      0.83        82
         10       0.62      0.70      0.66       100

avg / total       0.64      0.61      0.61       816

============================================
Running  28  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 06:06:55
forest model fit end:  2018-04-14 06:12:39
forest model predict start:  2018-04-14 06:12:39
forest model predict end:  2018-04-14 06:12:40
accuracy:  0.605392156863   494 / 816
Testing folds:  [ 9.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 10]
             precision    recall  f1-score   support

          1       0.46      0.21      0.29       100
          2       1.00      0.75      0.86        32
          3       0.43      0.66      0.52       100
          4       0.81      0.58      0.67       100
          5       0.37      0.43      0.40       100
          6       0.90      0.79      0.84        89
          7       0.84      0.52      0.64        31
          8       0.54      0.61      0.57        82
          9       0.75      0.93      0.83        82
         10       0.61      0.70      0.65       100

avg / total       0.63      0.61      0.60       816

============================================
Running  29  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 06:12:41
forest model fit end:  2018-04-14 06:18:39
forest model predict start:  2018-04-14 06:18:39
forest model predict end:  2018-04-14 06:18:40
accuracy:  0.609068627451   497 / 816
Testing folds:  [ 9.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 10]
             precision    recall  f1-score   support

          1       0.48      0.21      0.29       100
          2       1.00      0.78      0.88        32
          3       0.43      0.66      0.52       100
          4       0.82      0.58      0.68       100
          5       0.38      0.42      0.40       100
          6       0.88      0.83      0.86        89
          7       0.94      0.52      0.67        31
          8       0.53      0.61      0.56        82
          9       0.75      0.93      0.83        82
         10       0.61      0.69      0.64       100

avg / total       0.63      0.61      0.60       816

============================================
Running  30  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 06:18:41
forest model fit end:  2018-04-14 06:24:30
forest model predict start:  2018-04-14 06:24:30
forest model predict end:  2018-04-14 06:24:32
accuracy:  0.599264705882   489 / 816
Testing folds:  [ 9.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 10]
             precision    recall  f1-score   support

          1       0.44      0.21      0.28       100
          2       1.00      0.75      0.86        32
          3       0.43      0.66      0.52       100
          4       0.81      0.58      0.67       100
          5       0.37      0.43      0.40       100
          6       0.84      0.74      0.79        89
          7       0.89      0.52      0.65        31
          8       0.53      0.61      0.56        82
          9       0.76      0.93      0.84        82
         10       0.62      0.69      0.65       100

avg / total       0.62      0.60      0.60       816

============================================
Running  31  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 06:24:32
forest model fit end:  2018-04-14 06:30:22
forest model predict start:  2018-04-14 06:30:22
forest model predict end:  2018-04-14 06:30:24
accuracy:  0.607843137255   496 / 816
Testing folds:  [ 9.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 10]
             precision    recall  f1-score   support

          1       0.47      0.20      0.28       100
          2       1.00      0.78      0.88        32
          3       0.44      0.67      0.53       100
          4       0.82      0.59      0.69       100
          5       0.37      0.43      0.40       100
          6       0.86      0.80      0.83        89
          7       0.94      0.48      0.64        31
          8       0.52      0.61      0.56        82
          9       0.76      0.93      0.84        82
         10       0.63      0.70      0.66       100

avg / total       0.63      0.61      0.60       816

============================================
Running  32  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 06:30:24
forest model fit end:  2018-04-14 06:36:16
forest model predict start:  2018-04-14 06:36:16
forest model predict end:  2018-04-14 06:36:17
accuracy:  0.611519607843   499 / 816
Testing folds:  [ 9.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 10]
             precision    recall  f1-score   support

          1       0.47      0.19      0.27       100
          2       1.00      0.78      0.88        32
          3       0.44      0.67      0.53       100
          4       0.81      0.58      0.67       100
          5       0.37      0.43      0.40       100
          6       0.87      0.82      0.84        89
          7       0.84      0.52      0.64        31
          8       0.54      0.61      0.57        82
          9       0.76      0.94      0.84        82
         10       0.62      0.71      0.66       100

avg / total       0.63      0.61      0.60       816

============================================
Running  33  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 06:36:18
forest model fit end:  2018-04-14 06:42:18
forest model predict start:  2018-04-14 06:42:18
forest model predict end:  2018-04-14 06:42:20
accuracy:  0.611519607843   499 / 816
Testing folds:  [ 9.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 10]
             precision    recall  f1-score   support

          1       0.45      0.20      0.28       100
          2       1.00      0.75      0.86        32
          3       0.44      0.67      0.53       100
          4       0.82      0.58      0.68       100
          5       0.37      0.43      0.40       100
          6       0.87      0.83      0.85        89
          7       0.88      0.48      0.62        31
          8       0.53      0.61      0.57        82
          9       0.76      0.94      0.84        82
         10       0.63      0.71      0.67       100

avg / total       0.63      0.61      0.60       816

============================================
Running  34  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 06:42:20
forest model fit end:  2018-04-14 06:47:56
forest model predict start:  2018-04-14 06:47:56
forest model predict end:  2018-04-14 06:47:58
accuracy:  0.609068627451   497 / 816
Testing folds:  [ 9.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 10]
             precision    recall  f1-score   support

          1       0.50      0.21      0.30       100
          2       1.00      0.78      0.88        32
          3       0.43      0.66      0.52       100
          4       0.83      0.59      0.69       100
          5       0.37      0.43      0.40       100
          6       0.86      0.80      0.83        89
          7       0.88      0.48      0.62        31
          8       0.52      0.61      0.56        82
          9       0.76      0.94      0.84        82
         10       0.62      0.70      0.66       100

avg / total       0.63      0.61      0.60       816

============================================
Running  35  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 06:47:58
forest model fit end:  2018-04-14 06:53:36
forest model predict start:  2018-04-14 06:53:36
forest model predict end:  2018-04-14 06:53:38
accuracy:  0.610294117647   498 / 816
Testing folds:  [ 9.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 10]
             precision    recall  f1-score   support

          1       0.46      0.21      0.29       100
          2       1.00      0.75      0.86        32
          3       0.44      0.67      0.53       100
          4       0.82      0.58      0.68       100
          5       0.37      0.43      0.40       100
          6       0.90      0.80      0.85        89
          7       0.94      0.55      0.69        31
          8       0.52      0.61      0.56        82
          9       0.76      0.94      0.84        82
         10       0.61      0.70      0.65       100

avg / total       0.63      0.61      0.61       816

============================================
Running  36  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 06:53:38
forest model fit end:  2018-04-14 06:59:11
forest model predict start:  2018-04-14 06:59:11
forest model predict end:  2018-04-14 06:59:13
accuracy:  0.615196078431   502 / 816
Testing folds:  [ 9.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 10]
             precision    recall  f1-score   support

          1       0.50      0.21      0.30       100
          2       1.00      0.75      0.86        32
          3       0.45      0.68      0.54       100
          4       0.83      0.58      0.68       100
          5       0.37      0.42      0.39       100
          6       0.90      0.82      0.86        89
          7       0.94      0.55      0.69        31
          8       0.53      0.61      0.56        82
          9       0.78      0.95      0.86        82
         10       0.59      0.71      0.65       100

avg / total       0.64      0.62      0.61       816

============================================
Running  37  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 06:59:13
forest model fit end:  2018-04-14 07:04:49
forest model predict start:  2018-04-14 07:04:49
forest model predict end:  2018-04-14 07:04:51
accuracy:  0.612745098039   500 / 816
Testing folds:  [ 9.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 10]
             precision    recall  f1-score   support

          1       0.48      0.21      0.29       100
          2       1.00      0.75      0.86        32
          3       0.44      0.66      0.53       100
          4       0.82      0.60      0.69       100
          5       0.37      0.43      0.40       100
          6       0.91      0.82      0.86        89
          7       0.83      0.48      0.61        31
          8       0.53      0.61      0.57        82
          9       0.75      0.94      0.84        82
         10       0.62      0.71      0.66       100

avg / total       0.63      0.61      0.61       816

============================================
Running  38  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 07:04:51
forest model fit end:  2018-04-14 07:10:34
forest model predict start:  2018-04-14 07:10:34
forest model predict end:  2018-04-14 07:10:35
accuracy:  0.612745098039   500 / 816
Testing folds:  [ 9.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 10]
             precision    recall  f1-score   support

          1       0.48      0.21      0.29       100
          2       1.00      0.78      0.88        32
          3       0.44      0.67      0.53       100
          4       0.82      0.58      0.68       100
          5       0.37      0.43      0.40       100
          6       0.90      0.82      0.86        89
          7       0.94      0.52      0.67        31
          8       0.53      0.61      0.57        82
          9       0.76      0.94      0.84        82
         10       0.61      0.70      0.65       100

avg / total       0.64      0.61      0.61       816

============================================
Running  39  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 07:10:36
forest model fit end:  2018-04-14 07:16:07
forest model predict start:  2018-04-14 07:16:07
forest model predict end:  2018-04-14 07:16:09
accuracy:  0.602941176471   492 / 816
Testing folds:  [ 9.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 10]
             precision    recall  f1-score   support

          1       0.45      0.18      0.26       100
          2       1.00      0.75      0.86        32
          3       0.43      0.67      0.53       100
          4       0.81      0.58      0.67       100
          5       0.37      0.43      0.40       100
          6       0.83      0.80      0.81        89
          7       0.94      0.52      0.67        31
          8       0.53      0.61      0.57        82
          9       0.76      0.93      0.84        82
         10       0.62      0.69      0.65       100

avg / total       0.62      0.60      0.60       816

============================================
Running  40  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 07:16:09
forest model fit end:  2018-04-14 07:21:40
forest model predict start:  2018-04-14 07:21:40
forest model predict end:  2018-04-14 07:21:42
accuracy:  0.609068627451   497 / 816
Testing folds:  [ 9.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 10]
             precision    recall  f1-score   support

          1       0.50      0.21      0.30       100
          2       0.96      0.75      0.84        32
          3       0.43      0.66      0.52       100
          4       0.83      0.59      0.69       100
          5       0.37      0.42      0.39       100
          6       0.84      0.82      0.83        89
          7       0.88      0.48      0.62        31
          8       0.53      0.61      0.57        82
          9       0.77      0.94      0.85        82
         10       0.62      0.70      0.66       100

avg / total       0.63      0.61      0.60       816

============================================
Running  41  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 07:21:42
forest model fit end:  2018-04-14 07:27:22
forest model predict start:  2018-04-14 07:27:22
forest model predict end:  2018-04-14 07:27:24
accuracy:  0.611519607843   499 / 816
Testing folds:  [ 9.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 10]
             precision    recall  f1-score   support

          1       0.51      0.20      0.29       100
          2       1.00      0.78      0.88        32
          3       0.43      0.67      0.53       100
          4       0.82      0.59      0.69       100
          5       0.37      0.43      0.40       100
          6       0.88      0.84      0.86        89
          7       0.94      0.52      0.67        31
          8       0.52      0.61      0.56        82
          9       0.75      0.91      0.82        82
         10       0.62      0.69      0.65       100

avg / total       0.64      0.61      0.61       816

============================================
Running  42  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 07:27:24
forest model fit end:  2018-04-14 07:33:23
forest model predict start:  2018-04-14 07:33:23
forest model predict end:  2018-04-14 07:33:25
accuracy:  0.607843137255   496 / 816
Testing folds:  [ 9.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 10]
             precision    recall  f1-score   support

          1       0.43      0.21      0.28       100
          2       1.00      0.78      0.88        32
          3       0.44      0.67      0.53       100
          4       0.82      0.59      0.69       100
          5       0.37      0.42      0.39       100
          6       0.88      0.75      0.81        89
          7       0.89      0.55      0.68        31
          8       0.54      0.61      0.57        82
          9       0.76      0.94      0.84        82
         10       0.62      0.71      0.66       100

avg / total       0.63      0.61      0.60       816

============================================
Running  43  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 07:33:25
forest model fit end:  2018-04-14 07:39:06
forest model predict start:  2018-04-14 07:39:06
forest model predict end:  2018-04-14 07:39:08
accuracy:  0.617647058824   504 / 816
Testing folds:  [ 9.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 10]
             precision    recall  f1-score   support

          1       0.53      0.21      0.30       100
          2       1.00      0.78      0.88        32
          3       0.44      0.68      0.54       100
          4       0.81      0.59      0.68       100
          5       0.37      0.43      0.40       100
          6       0.90      0.85      0.88        89
          7       0.94      0.52      0.67        31
          8       0.53      0.61      0.57        82
          9       0.75      0.93      0.83        82
         10       0.62      0.70      0.66       100

avg / total       0.64      0.62      0.61       816

============================================
Running  44  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 07:39:08
forest model fit end:  2018-04-14 07:44:47
forest model predict start:  2018-04-14 07:44:47
forest model predict end:  2018-04-14 07:44:49
accuracy:  0.61887254902   505 / 816
Testing folds:  [ 9.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 10]
             precision    recall  f1-score   support

          1       0.51      0.21      0.30       100
          2       0.96      0.78      0.86        32
          3       0.44      0.67      0.53       100
          4       0.85      0.60      0.70       100
          5       0.37      0.43      0.40       100
          6       0.93      0.84      0.88        89
          7       0.89      0.52      0.65        31
          8       0.54      0.61      0.57        82
          9       0.75      0.94      0.84        82
         10       0.62      0.71      0.66       100

avg / total       0.64      0.62      0.61       816

============================================
Running  45  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 07:44:49
forest model fit end:  2018-04-14 07:50:28
forest model predict start:  2018-04-14 07:50:28
forest model predict end:  2018-04-14 07:50:30
accuracy:  0.609068627451   497 / 816
Testing folds:  [ 9.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 10]
             precision    recall  f1-score   support

          1       0.45      0.21      0.29       100
          2       1.00      0.78      0.88        32
          3       0.44      0.66      0.53       100
          4       0.82      0.58      0.68       100
          5       0.38      0.43      0.40       100
          6       0.88      0.79      0.83        89
          7       0.89      0.52      0.65        31
          8       0.53      0.61      0.56        82
          9       0.75      0.94      0.84        82
         10       0.62      0.71      0.66       100

avg / total       0.63      0.61      0.60       816

============================================
Running  46  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 07:50:30
forest model fit end:  2018-04-14 07:56:12
forest model predict start:  2018-04-14 07:56:12
forest model predict end:  2018-04-14 07:56:13
accuracy:  0.615196078431   502 / 816
Testing folds:  [ 9.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 10]
             precision    recall  f1-score   support

          1       0.57      0.21      0.31       100
          2       1.00      0.78      0.88        32
          3       0.44      0.68      0.53       100
          4       0.81      0.58      0.67       100
          5       0.37      0.43      0.40       100
          6       0.86      0.83      0.85        89
          7       0.94      0.55      0.69        31
          8       0.53      0.61      0.57        82
          9       0.76      0.93      0.84        82
         10       0.62      0.70      0.66       100

avg / total       0.64      0.62      0.61       816

============================================
Running  47  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 07:56:14
forest model fit end:  2018-04-14 08:01:47
forest model predict start:  2018-04-14 08:01:47
forest model predict end:  2018-04-14 08:01:49
accuracy:  0.609068627451   497 / 816
Testing folds:  [ 9.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 10]
             precision    recall  f1-score   support

          1       0.45      0.20      0.28       100
          2       1.00      0.75      0.86        32
          3       0.43      0.67      0.53       100
          4       0.82      0.59      0.69       100
          5       0.37      0.43      0.40       100
          6       0.88      0.80      0.84        89
          7       0.94      0.55      0.69        31
          8       0.52      0.61      0.56        82
          9       0.76      0.93      0.84        82
         10       0.64      0.70      0.67       100

avg / total       0.63      0.61      0.60       816

============================================
Running  48  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 08:01:49
forest model fit end:  2018-04-14 08:07:20
forest model predict start:  2018-04-14 08:07:20
forest model predict end:  2018-04-14 08:07:22
accuracy:  0.611519607843   499 / 816
Testing folds:  [ 9.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 10]
             precision    recall  f1-score   support

          1       0.49      0.21      0.29       100
          2       1.00      0.75      0.86        32
          3       0.44      0.67      0.53       100
          4       0.82      0.59      0.69       100
          5       0.37      0.43      0.40       100
          6       0.88      0.81      0.84        89
          7       0.89      0.52      0.65        31
          8       0.53      0.61      0.57        82
          9       0.76      0.94      0.84        82
         10       0.62      0.70      0.66       100

avg / total       0.63      0.61      0.61       816

============================================
Running  49  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 08:07:22
forest model fit end:  2018-04-14 08:12:55
forest model predict start:  2018-04-14 08:12:55
forest model predict end:  2018-04-14 08:12:57
accuracy:  0.607843137255   496 / 816
Testing folds:  [ 9.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 10]
             precision    recall  f1-score   support

          1       0.47      0.21      0.29       100
          2       1.00      0.75      0.86        32
          3       0.43      0.67      0.53       100
          4       0.82      0.58      0.68       100
          5       0.37      0.43      0.40       100
          6       0.86      0.80      0.83        89
          7       0.89      0.52      0.65        31
          8       0.54      0.61      0.57        82
          9       0.77      0.94      0.85        82
         10       0.62      0.69      0.65       100

avg / total       0.63      0.61      0.60       816

============================================
Running  50  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 08:12:57
forest model fit end:  2018-04-14 08:18:31
forest model predict start:  2018-04-14 08:18:31
forest model predict end:  2018-04-14 08:18:33
accuracy:  0.613970588235   501 / 816
Testing folds:  [ 9.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 10]
             precision    recall  f1-score   support

          1       0.45      0.21      0.29       100
          2       1.00      0.81      0.90        32
          3       0.44      0.69      0.54       100
          4       0.82      0.61      0.70       100
          5       0.38      0.43      0.41       100
          6       0.88      0.78      0.83        89
          7       0.94      0.52      0.67        31
          8       0.53      0.61      0.57        82
          9       0.77      0.94      0.85        82
         10       0.62      0.69      0.65       100

avg / total       0.63      0.61      0.61       816

============================================
[0.61397058823529416, 0.6115196078431373, 0.61274509803921573, 0.61029411764705888, 0.60906862745098034, 0.60906862745098034, 0.6115196078431373, 0.61029411764705888, 0.61029411764705888, 0.61029411764705888, 0.60906862745098034, 0.61642156862745101, 0.60906862745098034, 0.60661764705882348, 0.61519607843137258, 0.61029411764705888, 0.61519607843137258, 0.61642156862745101, 0.6115196078431373, 0.61029411764705888, 0.60539215686274506, 0.60784313725490191, 0.60784313725490191, 0.61764705882352944, 0.61274509803921573, 0.61029411764705888, 0.6115196078431373, 0.60539215686274506, 0.60906862745098034, 0.59926470588235292, 0.60784313725490191, 0.6115196078431373, 0.6115196078431373, 0.60906862745098034, 0.61029411764705888, 0.61519607843137258, 0.61274509803921573, 0.61274509803921573, 0.6029411764705882, 0.60906862745098034, 0.6115196078431373, 0.60784313725490191, 0.61764705882352944, 0.61887254901960786, 0.60906862745098034, 0.61519607843137258, 0.60906862745098034, 0.6115196078431373, 0.60784313725490191, 0.61397058823529416]
Avg accuracy:  0.610833333333
