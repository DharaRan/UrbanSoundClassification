Running  1  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 03:33:58
forest model fit end:  2018-04-14 03:39:28
forest model predict start:  2018-04-14 03:39:28
forest model predict end:  2018-04-14 03:39:30
accuracy:  0.622461170848   521 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.85      0.80      0.82       100
          2       0.83      0.73      0.77        33
          3       0.51      0.82      0.63       100
          4       0.75      0.55      0.64       100
          5       0.40      0.47      0.43       100
          6       0.79      0.76      0.78        93
          7       1.00      0.62      0.77        32
          8       0.63      0.45      0.52        96
          9       0.60      0.39      0.47        83
         10       0.51      0.67      0.58       100

avg / total       0.65      0.62      0.62       837

============================================
Running  2  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 03:39:30
forest model fit end:  2018-04-14 03:45:14
forest model predict start:  2018-04-14 03:45:14
forest model predict end:  2018-04-14 03:45:16
accuracy:  0.605734767025   507 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.82      0.82      0.82       100
          2       0.85      0.70      0.77        33
          3       0.49      0.80      0.61       100
          4       0.72      0.55      0.63       100
          5       0.35      0.42      0.38       100
          6       0.79      0.71      0.75        93
          7       1.00      0.62      0.77        32
          8       0.60      0.41      0.48        96
          9       0.59      0.39      0.47        83
         10       0.52      0.68      0.59       100

avg / total       0.63      0.61      0.61       837

============================================
Running  3  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 03:45:16
forest model fit end:  2018-04-14 03:51:04
forest model predict start:  2018-04-14 03:51:04
forest model predict end:  2018-04-14 03:51:06
accuracy:  0.616487455197   516 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.85      0.82      0.84       100
          2       0.79      0.67      0.72        33
          3       0.49      0.81      0.61       100
          4       0.73      0.56      0.63       100
          5       0.37      0.43      0.40       100
          6       0.82      0.76      0.79        93
          7       1.00      0.62      0.77        32
          8       0.64      0.45      0.53        96
          9       0.62      0.39      0.47        83
         10       0.51      0.66      0.57       100

avg / total       0.65      0.62      0.62       837

============================================
Running  4  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 03:51:06
forest model fit end:  2018-04-14 03:56:58
forest model predict start:  2018-04-14 03:56:58
forest model predict end:  2018-04-14 03:57:00
accuracy:  0.609318996416   510 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.81      0.77      0.79       100
          2       0.80      0.73      0.76        33
          3       0.50      0.80      0.62       100
          4       0.72      0.55      0.63       100
          5       0.39      0.45      0.42       100
          6       0.78      0.73      0.76        93
          7       1.00      0.62      0.77        32
          8       0.63      0.44      0.52        96
          9       0.60      0.39      0.47        83
         10       0.50      0.67      0.57       100

avg / total       0.64      0.61      0.61       837

============================================
Running  5  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 03:57:00
forest model fit end:  2018-04-14 04:02:47
forest model predict start:  2018-04-14 04:02:47
forest model predict end:  2018-04-14 04:02:49
accuracy:  0.609318996416   510 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.84      0.81      0.82       100
          2       0.81      0.67      0.73        33
          3       0.50      0.81      0.62       100
          4       0.73      0.55      0.63       100
          5       0.37      0.42      0.39       100
          6       0.78      0.74      0.76        93
          7       1.00      0.62      0.77        32
          8       0.57      0.43      0.49        96
          9       0.59      0.39      0.47        83
         10       0.52      0.67      0.59       100

avg / total       0.64      0.61      0.61       837

============================================
Running  6  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 04:02:49
forest model fit end:  2018-04-14 04:08:29
forest model predict start:  2018-04-14 04:08:29
forest model predict end:  2018-04-14 04:08:31
accuracy:  0.611708482676   512 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.80      0.79      0.79       100
          2       0.80      0.73      0.76        33
          3       0.50      0.80      0.61       100
          4       0.73      0.54      0.62       100
          5       0.38      0.45      0.41       100
          6       0.80      0.72      0.76        93
          7       1.00      0.56      0.72        32
          8       0.63      0.46      0.53        96
          9       0.60      0.39      0.47        83
         10       0.53      0.69      0.60       100

avg / total       0.64      0.61      0.61       837

============================================
Running  7  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 04:08:31
forest model fit end:  2018-04-14 04:14:21
forest model predict start:  2018-04-14 04:14:21
forest model predict end:  2018-04-14 04:14:23
accuracy:  0.611708482676   512 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.78      0.80      0.79       100
          2       0.79      0.67      0.72        33
          3       0.50      0.82      0.62       100
          4       0.75      0.56      0.64       100
          5       0.39      0.43      0.41       100
          6       0.77      0.68      0.72        93
          7       1.00      0.62      0.77        32
          8       0.62      0.48      0.54        96
          9       0.59      0.39      0.47        83
         10       0.53      0.68      0.59       100

avg / total       0.64      0.61      0.61       837

============================================
Running  8  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 04:14:23
forest model fit end:  2018-04-14 04:20:09
forest model predict start:  2018-04-14 04:20:09
forest model predict end:  2018-04-14 04:20:10
accuracy:  0.615292712067   515 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.81      0.84      0.82       100
          2       0.83      0.73      0.77        33
          3       0.50      0.81      0.62       100
          4       0.73      0.55      0.63       100
          5       0.39      0.47      0.43       100
          6       0.80      0.71      0.75        93
          7       1.00      0.59      0.75        32
          8       0.64      0.43      0.51        96
          9       0.58      0.39      0.46        83
         10       0.52      0.66      0.58       100

avg / total       0.64      0.62      0.62       837

============================================
Running  9  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 04:20:10
forest model fit end:  2018-04-14 04:25:52
forest model predict start:  2018-04-14 04:25:52
forest model predict end:  2018-04-14 04:25:54
accuracy:  0.593787335723   497 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.71      0.78      0.74       100
          2       0.80      0.73      0.76        33
          3       0.50      0.82      0.62       100
          4       0.72      0.55      0.63       100
          5       0.39      0.45      0.42       100
          6       0.76      0.58      0.66        93
          7       1.00      0.62      0.77        32
          8       0.60      0.44      0.51        96
          9       0.60      0.39      0.47        83
         10       0.50      0.65      0.57       100

avg / total       0.62      0.59      0.59       837

============================================
Running  10  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 04:25:54
forest model fit end:  2018-04-14 04:31:37
forest model predict start:  2018-04-14 04:31:37
forest model predict end:  2018-04-14 04:31:38
accuracy:  0.609318996416   510 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.75      0.82      0.78       100
          2       0.79      0.70      0.74        33
          3       0.49      0.80      0.61       100
          4       0.73      0.54      0.62       100
          5       0.39      0.43      0.41       100
          6       0.78      0.66      0.71        93
          7       1.00      0.62      0.77        32
          8       0.66      0.49      0.56        96
          9       0.60      0.39      0.47        83
         10       0.52      0.68      0.59       100

avg / total       0.64      0.61      0.61       837

============================================
Running  11  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 04:31:39
forest model fit end:  2018-04-14 04:37:13
forest model predict start:  2018-04-14 04:37:13
forest model predict end:  2018-04-14 04:37:14
accuracy:  0.610513739546   511 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.80      0.80      0.80       100
          2       0.80      0.73      0.76        33
          3       0.50      0.81      0.62       100
          4       0.71      0.55      0.62       100
          5       0.37      0.38      0.37       100
          6       0.80      0.73      0.76        93
          7       1.00      0.62      0.77        32
          8       0.62      0.50      0.55        96
          9       0.60      0.37      0.46        83
         10       0.51      0.66      0.58       100

avg / total       0.63      0.61      0.61       837

============================================
Running  12  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 04:37:15
forest model fit end:  2018-04-14 04:43:08
forest model predict start:  2018-04-14 04:43:08
forest model predict end:  2018-04-14 04:43:10
accuracy:  0.608124253286   509 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.76      0.80      0.78       100
          2       0.83      0.73      0.77        33
          3       0.50      0.82      0.62       100
          4       0.76      0.55      0.64       100
          5       0.38      0.41      0.40       100
          6       0.78      0.66      0.71        93
          7       1.00      0.62      0.77        32
          8       0.59      0.49      0.54        96
          9       0.60      0.39      0.47        83
         10       0.52      0.67      0.58       100

avg / total       0.64      0.61      0.61       837

============================================
Running  13  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 04:43:10
forest model fit end:  2018-04-14 04:49:00
forest model predict start:  2018-04-14 04:49:00
forest model predict end:  2018-04-14 04:49:02
accuracy:  0.616487455197   516 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.77      0.83      0.80       100
          2       0.77      0.70      0.73        33
          3       0.52      0.82      0.63       100
          4       0.75      0.56      0.64       100
          5       0.40      0.45      0.42       100
          6       0.77      0.66      0.71        93
          7       1.00      0.62      0.77        32
          8       0.62      0.47      0.53        96
          9       0.62      0.39      0.47        83
         10       0.54      0.69      0.61       100

avg / total       0.64      0.62      0.62       837

============================================
Running  14  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 04:49:02
forest model fit end:  2018-04-14 04:54:45
forest model predict start:  2018-04-14 04:54:45
forest model predict end:  2018-04-14 04:54:47
accuracy:  0.611708482676   512 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.74      0.81      0.77       100
          2       0.81      0.67      0.73        33
          3       0.50      0.81      0.62       100
          4       0.76      0.55      0.64       100
          5       0.41      0.46      0.43       100
          6       0.78      0.66      0.71        93
          7       1.00      0.62      0.77        32
          8       0.64      0.49      0.56        96
          9       0.60      0.37      0.46        83
         10       0.52      0.68      0.59       100

avg / total       0.64      0.61      0.61       837

============================================
Running  15  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 04:54:47
forest model fit end:  2018-04-14 05:00:30
forest model predict start:  2018-04-14 05:00:30
forest model predict end:  2018-04-14 05:00:31
accuracy:  0.611708482676   512 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.76      0.81      0.79       100
          2       0.80      0.73      0.76        33
          3       0.51      0.82      0.63       100
          4       0.73      0.55      0.63       100
          5       0.39      0.42      0.40       100
          6       0.78      0.68      0.72        93
          7       1.00      0.62      0.77        32
          8       0.64      0.47      0.54        96
          9       0.60      0.39      0.47        83
         10       0.52      0.68      0.59       100

avg / total       0.64      0.61      0.61       837

============================================
Running  16  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 05:00:32
forest model fit end:  2018-04-14 05:06:25
forest model predict start:  2018-04-14 05:06:25
forest model predict end:  2018-04-14 05:06:27
accuracy:  0.604540023895   506 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.80      0.79      0.79       100
          2       0.79      0.67      0.72        33
          3       0.50      0.80      0.62       100
          4       0.71      0.55      0.62       100
          5       0.38      0.42      0.40       100
          6       0.79      0.69      0.74        93
          7       1.00      0.62      0.77        32
          8       0.56      0.46      0.51        96
          9       0.60      0.39      0.47        83
         10       0.52      0.68      0.59       100

avg / total       0.63      0.60      0.61       837

============================================
Running  17  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 05:06:27
forest model fit end:  2018-04-14 05:12:13
forest model predict start:  2018-04-14 05:12:13
forest model predict end:  2018-04-14 05:12:15
accuracy:  0.610513739546   511 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.79      0.81      0.80       100
          2       0.81      0.67      0.73        33
          3       0.51      0.81      0.63       100
          4       0.72      0.56      0.63       100
          5       0.38      0.44      0.41       100
          6       0.79      0.70      0.74        93
          7       1.00      0.62      0.77        32
          8       0.61      0.45      0.52        96
          9       0.60      0.39      0.47        83
         10       0.51      0.67      0.58       100

avg / total       0.64      0.61      0.61       837

============================================
Running  18  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 05:12:15
forest model fit end:  2018-04-14 05:17:56
forest model predict start:  2018-04-14 05:17:56
forest model predict end:  2018-04-14 05:17:58
accuracy:  0.598566308244   501 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.73      0.82      0.77       100
          2       0.81      0.67      0.73        33
          3       0.52      0.82      0.63       100
          4       0.73      0.54      0.62       100
          5       0.36      0.42      0.39       100
          6       0.79      0.61      0.69        93
          7       1.00      0.62      0.77        32
          8       0.56      0.42      0.48        96
          9       0.60      0.39      0.47        83
         10       0.53      0.70      0.60       100

avg / total       0.62      0.60      0.60       837

============================================
Running  19  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 05:17:58
forest model fit end:  2018-04-14 05:23:49
forest model predict start:  2018-04-14 05:23:49
forest model predict end:  2018-04-14 05:23:51
accuracy:  0.610513739546   511 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.81      0.79      0.80       100
          2       0.79      0.67      0.72        33
          3       0.51      0.82      0.63       100
          4       0.71      0.54      0.61       100
          5       0.38      0.46      0.42       100
          6       0.80      0.73      0.76        93
          7       1.00      0.62      0.77        32
          8       0.60      0.43      0.50        96
          9       0.60      0.39      0.47        83
         10       0.52      0.67      0.59       100

avg / total       0.64      0.61      0.61       837

============================================
Running  20  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 05:23:51
forest model fit end:  2018-04-14 05:29:32
forest model predict start:  2018-04-14 05:29:32
forest model predict end:  2018-04-14 05:29:34
accuracy:  0.615292712067   515 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.77      0.82      0.80       100
          2       0.80      0.73      0.76        33
          3       0.50      0.81      0.62       100
          4       0.74      0.56      0.64       100
          5       0.40      0.46      0.43       100
          6       0.78      0.66      0.71        93
          7       1.00      0.62      0.77        32
          8       0.69      0.46      0.55        96
          9       0.62      0.39      0.47        83
         10       0.52      0.69      0.59       100

avg / total       0.65      0.62      0.62       837

============================================
Running  21  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 05:29:34
forest model fit end:  2018-04-14 05:35:28
forest model predict start:  2018-04-14 05:35:28
forest model predict end:  2018-04-14 05:35:30
accuracy:  0.598566308244   501 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.77      0.80      0.78       100
          2       0.79      0.70      0.74        33
          3       0.50      0.82      0.62       100
          4       0.73      0.54      0.62       100
          5       0.37      0.45      0.40       100
          6       0.78      0.66      0.71        93
          7       1.00      0.62      0.77        32
          8       0.60      0.40      0.48        96
          9       0.60      0.37      0.46        83
         10       0.52      0.67      0.59       100

avg / total       0.63      0.60      0.60       837

============================================
Running  22  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 05:35:30
forest model fit end:  2018-04-14 05:41:18
forest model predict start:  2018-04-14 05:41:18
forest model predict end:  2018-04-14 05:41:20
accuracy:  0.612903225806   513 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.83      0.78      0.80       100
          2       0.79      0.70      0.74        33
          3       0.50      0.82      0.62       100
          4       0.76      0.54      0.63       100
          5       0.37      0.44      0.40       100
          6       0.80      0.76      0.78        93
          7       1.00      0.62      0.77        32
          8       0.61      0.43      0.50        96
          9       0.60      0.39      0.47        83
         10       0.51      0.68      0.58       100

avg / total       0.64      0.61      0.61       837

============================================
Running  23  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 05:41:20
forest model fit end:  2018-04-14 05:47:00
forest model predict start:  2018-04-14 05:47:00
forest model predict end:  2018-04-14 05:47:02
accuracy:  0.603345280765   505 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.78      0.77      0.77       100
          2       0.81      0.67      0.73        33
          3       0.50      0.82      0.62       100
          4       0.75      0.54      0.63       100
          5       0.37      0.44      0.40       100
          6       0.81      0.72      0.76        93
          7       1.00      0.62      0.77        32
          8       0.57      0.43      0.49        96
          9       0.59      0.39      0.47        83
         10       0.52      0.66      0.58       100

avg / total       0.63      0.60      0.60       837

============================================
Running  24  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 05:47:02
forest model fit end:  2018-04-14 05:52:46
forest model predict start:  2018-04-14 05:52:46
forest model predict end:  2018-04-14 05:52:48
accuracy:  0.627240143369   525 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.84      0.80      0.82       100
          2       0.83      0.73      0.77        33
          3       0.50      0.82      0.62       100
          4       0.74      0.55      0.63       100
          5       0.40      0.44      0.42       100
          6       0.81      0.76      0.78        93
          7       1.00      0.62      0.77        32
          8       0.68      0.52      0.59        96
          9       0.59      0.39      0.47        83
         10       0.51      0.67      0.58       100

avg / total       0.66      0.63      0.63       837

============================================
Running  25  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 05:52:48
forest model fit end:  2018-04-14 05:58:34
forest model predict start:  2018-04-14 05:58:34
forest model predict end:  2018-04-14 05:58:36
accuracy:  0.618876941458   518 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.80      0.82      0.81       100
          2       0.79      0.70      0.74        33
          3       0.50      0.82      0.62       100
          4       0.77      0.56      0.65       100
          5       0.39      0.46      0.42       100
          6       0.79      0.71      0.75        93
          7       1.00      0.62      0.77        32
          8       0.68      0.46      0.55        96
          9       0.62      0.39      0.47        83
         10       0.51      0.67      0.58       100

avg / total       0.65      0.62      0.62       837

============================================
Running  26  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 05:58:36
forest model fit end:  2018-04-14 06:04:28
forest model predict start:  2018-04-14 06:04:28
forest model predict end:  2018-04-14 06:04:30
accuracy:  0.620071684588   519 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.82      0.80      0.81       100
          2       0.83      0.73      0.77        33
          3       0.49      0.82      0.62       100
          4       0.77      0.54      0.64       100
          5       0.40      0.46      0.43       100
          6       0.80      0.74      0.77        93
          7       1.00      0.62      0.77        32
          8       0.64      0.48      0.55        96
          9       0.58      0.37      0.46        83
         10       0.52      0.67      0.59       100

avg / total       0.65      0.62      0.62       837

============================================
Running  27  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 06:04:30
forest model fit end:  2018-04-14 06:10:09
forest model predict start:  2018-04-14 06:10:09
forest model predict end:  2018-04-14 06:10:11
accuracy:  0.618876941458   518 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.77      0.80      0.78       100
          2       0.80      0.73      0.76        33
          3       0.51      0.82      0.63       100
          4       0.71      0.55      0.62       100
          5       0.42      0.45      0.44       100
          6       0.79      0.68      0.73        93
          7       1.00      0.62      0.77        32
          8       0.68      0.54      0.60        96
          9       0.62      0.39      0.47        83
         10       0.50      0.65      0.57       100

avg / total       0.64      0.62      0.62       837

============================================
Running  28  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 06:10:11
forest model fit end:  2018-04-14 06:16:00
forest model predict start:  2018-04-14 06:16:00
forest model predict end:  2018-04-14 06:16:01
accuracy:  0.599761051374   502 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.71      0.77      0.74       100
          2       0.83      0.73      0.77        33
          3       0.49      0.81      0.61       100
          4       0.74      0.55      0.63       100
          5       0.40      0.42      0.41       100
          6       0.74      0.59      0.66        93
          7       1.00      0.62      0.77        32
          8       0.64      0.51      0.57        96
          9       0.59      0.39      0.47        83
         10       0.51      0.67      0.58       100

avg / total       0.63      0.60      0.60       837

============================================
Running  29  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 06:16:02
forest model fit end:  2018-04-14 06:21:48
forest model predict start:  2018-04-14 06:21:48
forest model predict end:  2018-04-14 06:21:50
accuracy:  0.609318996416   510 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.76      0.78      0.77       100
          2       0.80      0.73      0.76        33
          3       0.50      0.82      0.62       100
          4       0.78      0.56      0.65       100
          5       0.39      0.42      0.40       100
          6       0.77      0.68      0.72        93
          7       1.00      0.62      0.77        32
          8       0.62      0.48      0.54        96
          9       0.60      0.39      0.47        83
         10       0.51      0.67      0.58       100

avg / total       0.64      0.61      0.61       837

============================================
Running  30  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 06:21:50
forest model fit end:  2018-04-14 06:27:40
forest model predict start:  2018-04-14 06:27:40
forest model predict end:  2018-04-14 06:27:42
accuracy:  0.597371565114   500 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.75      0.80      0.78       100
          2       0.79      0.67      0.72        33
          3       0.50      0.82      0.62       100
          4       0.75      0.54      0.63       100
          5       0.34      0.39      0.36       100
          6       0.78      0.65      0.71        93
          7       1.00      0.62      0.77        32
          8       0.60      0.45      0.51        96
          9       0.60      0.39      0.47        83
         10       0.52      0.68      0.59       100

avg / total       0.63      0.60      0.60       837

============================================
Running  31  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 06:27:42
forest model fit end:  2018-04-14 06:33:30
forest model predict start:  2018-04-14 06:33:30
forest model predict end:  2018-04-14 06:33:32
accuracy:  0.602150537634   504 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.77      0.79      0.78       100
          2       0.82      0.70      0.75        33
          3       0.50      0.81      0.62       100
          4       0.73      0.55      0.63       100
          5       0.38      0.43      0.40       100
          6       0.80      0.68      0.73        93
          7       1.00      0.62      0.77        32
          8       0.57      0.42      0.48        96
          9       0.58      0.37      0.46        83
         10       0.52      0.69      0.59       100

avg / total       0.63      0.60      0.60       837

============================================
Running  32  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 06:33:32
forest model fit end:  2018-04-14 06:39:18
forest model predict start:  2018-04-14 06:39:18
forest model predict end:  2018-04-14 06:39:19
accuracy:  0.611708482676   512 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.80      0.80      0.80       100
          2       0.83      0.73      0.77        33
          3       0.49      0.82      0.62       100
          4       0.76      0.54      0.63       100
          5       0.38      0.40      0.39       100
          6       0.80      0.73      0.76        93
          7       1.00      0.59      0.75        32
          8       0.60      0.49      0.54        96
          9       0.58      0.37      0.46        83
         10       0.51      0.67      0.58       100

avg / total       0.64      0.61      0.61       837

============================================
Running  33  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 06:39:19
forest model fit end:  2018-04-14 06:45:17
forest model predict start:  2018-04-14 06:45:17
forest model predict end:  2018-04-14 06:45:19
accuracy:  0.617682198327   517 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.80      0.80      0.80       100
          2       0.83      0.73      0.77        33
          3       0.50      0.81      0.62       100
          4       0.72      0.55      0.63       100
          5       0.40      0.46      0.43       100
          6       0.80      0.71      0.75        93
          7       1.00      0.59      0.75        32
          8       0.66      0.47      0.55        96
          9       0.60      0.39      0.47        83
         10       0.53      0.69      0.60       100

avg / total       0.65      0.62      0.62       837

============================================
Running  34  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 06:45:19
forest model fit end:  2018-04-14 06:51:06
forest model predict start:  2018-04-14 06:51:06
forest model predict end:  2018-04-14 06:51:08
accuracy:  0.610513739546   511 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.80      0.82      0.81       100
          2       0.81      0.67      0.73        33
          3       0.49      0.81      0.61       100
          4       0.74      0.55      0.63       100
          5       0.38      0.40      0.39       100
          6       0.78      0.69      0.73        93
          7       1.00      0.62      0.77        32
          8       0.61      0.49      0.54        96
          9       0.59      0.39      0.47        83
         10       0.52      0.68      0.59       100

avg / total       0.64      0.61      0.61       837

============================================
Running  35  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 06:51:08
forest model fit end:  2018-04-14 06:57:02
forest model predict start:  2018-04-14 06:57:02
forest model predict end:  2018-04-14 06:57:04
accuracy:  0.615292712067   515 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.80      0.79      0.79       100
          2       0.79      0.67      0.72        33
          3       0.51      0.82      0.63       100
          4       0.75      0.55      0.64       100
          5       0.38      0.44      0.41       100
          6       0.79      0.75      0.77        93
          7       1.00      0.62      0.77        32
          8       0.67      0.46      0.54        96
          9       0.60      0.39      0.47        83
         10       0.51      0.67      0.58       100

avg / total       0.65      0.62      0.62       837

============================================
Running  36  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 06:57:04
forest model fit end:  2018-04-14 07:02:51
forest model predict start:  2018-04-14 07:02:51
forest model predict end:  2018-04-14 07:02:54
accuracy:  0.606929510155   508 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.77      0.78      0.78       100
          2       0.79      0.70      0.74        33
          3       0.49      0.81      0.61       100
          4       0.77      0.55      0.64       100
          5       0.39      0.46      0.42       100
          6       0.76      0.69      0.72        93
          7       1.00      0.62      0.77        32
          8       0.63      0.43      0.51        96
          9       0.62      0.39      0.47        83
         10       0.52      0.68      0.59       100

avg / total       0.64      0.61      0.61       837

============================================
Running  37  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 07:02:54
forest model fit end:  2018-04-14 07:08:39
forest model predict start:  2018-04-14 07:08:39
forest model predict end:  2018-04-14 07:08:40
accuracy:  0.620071684588   519 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.81      0.83      0.82       100
          2       0.80      0.73      0.76        33
          3       0.50      0.81      0.62       100
          4       0.72      0.55      0.63       100
          5       0.39      0.43      0.41       100
          6       0.81      0.72      0.76        93
          7       1.00      0.62      0.77        32
          8       0.66      0.48      0.55        96
          9       0.62      0.39      0.47        83
         10       0.52      0.68      0.59       100

avg / total       0.65      0.62      0.62       837

============================================
Running  38  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 07:08:41
forest model fit end:  2018-04-14 07:14:26
forest model predict start:  2018-04-14 07:14:26
forest model predict end:  2018-04-14 07:14:28
accuracy:  0.609318996416   510 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.81      0.77      0.79       100
          2       0.82      0.70      0.75        33
          3       0.50      0.81      0.62       100
          4       0.73      0.55      0.63       100
          5       0.38      0.45      0.41       100
          6       0.80      0.76      0.78        93
          7       1.00      0.62      0.77        32
          8       0.59      0.42      0.49        96
          9       0.59      0.39      0.47        83
         10       0.51      0.66      0.58       100

avg / total       0.64      0.61      0.61       837

============================================
Running  39  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 07:14:28
forest model fit end:  2018-04-14 07:20:11
forest model predict start:  2018-04-14 07:20:11
forest model predict end:  2018-04-14 07:20:13
accuracy:  0.611708482676   512 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.82      0.80      0.81       100
          2       0.80      0.73      0.76        33
          3       0.50      0.82      0.62       100
          4       0.73      0.56      0.63       100
          5       0.37      0.43      0.40       100
          6       0.79      0.74      0.77        93
          7       1.00      0.62      0.77        32
          8       0.62      0.42      0.50        96
          9       0.62      0.39      0.47        83
         10       0.50      0.66      0.57       100

avg / total       0.64      0.61      0.61       837

============================================
Running  40  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 07:20:13
forest model fit end:  2018-04-14 07:25:59
forest model predict start:  2018-04-14 07:25:59
forest model predict end:  2018-04-14 07:26:01
accuracy:  0.63082437276   528 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.84      0.82      0.83       100
          2       0.81      0.67      0.73        33
          3       0.50      0.81      0.62       100
          4       0.74      0.55      0.63       100
          5       0.43      0.49      0.46       100
          6       0.80      0.75      0.78        93
          7       1.00      0.62      0.77        32
          8       0.69      0.52      0.60        96
          9       0.60      0.39      0.47        83
         10       0.52      0.67      0.59       100

avg / total       0.66      0.63      0.63       837

============================================
Running  41  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 07:26:01
forest model fit end:  2018-04-14 07:31:51
forest model predict start:  2018-04-14 07:31:51
forest model predict end:  2018-04-14 07:31:53
accuracy:  0.610513739546   511 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.75      0.80      0.77       100
          2       0.80      0.73      0.76        33
          3       0.49      0.81      0.61       100
          4       0.75      0.54      0.63       100
          5       0.41      0.48      0.44       100
          6       0.77      0.60      0.67        93
          7       1.00      0.62      0.77        32
          8       0.66      0.49      0.56        96
          9       0.60      0.39      0.47        83
         10       0.53      0.69      0.60       100

avg / total       0.64      0.61      0.61       837

============================================
Running  42  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 07:31:53
forest model fit end:  2018-04-14 07:37:41
forest model predict start:  2018-04-14 07:37:41
forest model predict end:  2018-04-14 07:37:43
accuracy:  0.604540023895   506 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.74      0.81      0.77       100
          2       0.83      0.73      0.77        33
          3       0.49      0.81      0.61       100
          4       0.73      0.54      0.62       100
          5       0.41      0.45      0.43       100
          6       0.78      0.62      0.69        93
          7       1.00      0.62      0.77        32
          8       0.66      0.49      0.56        96
          9       0.58      0.37      0.46        83
         10       0.50      0.65      0.57       100

avg / total       0.63      0.60      0.60       837

============================================
Running  43  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 07:37:43
forest model fit end:  2018-04-14 07:43:21
forest model predict start:  2018-04-14 07:43:21
forest model predict end:  2018-04-14 07:43:23
accuracy:  0.606929510155   508 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.75      0.81      0.78       100
          2       0.80      0.73      0.76        33
          3       0.49      0.81      0.61       100
          4       0.72      0.55      0.63       100
          5       0.41      0.45      0.43       100
          6       0.78      0.62      0.69        93
          7       1.00      0.62      0.77        32
          8       0.63      0.48      0.54        96
          9       0.60      0.37      0.46        83
         10       0.52      0.67      0.59       100

avg / total       0.63      0.61      0.61       837

============================================
Running  44  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 07:43:23
forest model fit end:  2018-04-14 07:48:54
forest model predict start:  2018-04-14 07:48:54
forest model predict end:  2018-04-14 07:48:56
accuracy:  0.621266427718   520 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.81      0.82      0.82       100
          2       0.86      0.73      0.79        33
          3       0.51      0.82      0.63       100
          4       0.76      0.56      0.64       100
          5       0.38      0.42      0.40       100
          6       0.80      0.75      0.78        93
          7       1.00      0.62      0.77        32
          8       0.61      0.44      0.51        96
          9       0.62      0.39      0.47        83
         10       0.52      0.70      0.60       100

avg / total       0.65      0.62      0.62       837

============================================
Running  45  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 07:48:56
forest model fit end:  2018-04-14 07:54:29
forest model predict start:  2018-04-14 07:54:29
forest model predict end:  2018-04-14 07:54:31
accuracy:  0.620071684588   519 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.81      0.82      0.82       100
          2       0.80      0.73      0.76        33
          3       0.49      0.81      0.61       100
          4       0.73      0.55      0.63       100
          5       0.41      0.43      0.42       100
          6       0.80      0.72      0.76        93
          7       1.00      0.62      0.77        32
          8       0.64      0.51      0.57        96
          9       0.61      0.37      0.46        83
         10       0.52      0.67      0.59       100

avg / total       0.65      0.62      0.62       837

============================================
Running  46  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 07:54:31
forest model fit end:  2018-04-14 08:00:16
forest model predict start:  2018-04-14 08:00:16
forest model predict end:  2018-04-14 08:00:17
accuracy:  0.621266427718   520 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.83      0.78      0.80       100
          2       0.83      0.73      0.77        33
          3       0.51      0.82      0.63       100
          4       0.73      0.56      0.63       100
          5       0.42      0.47      0.44       100
          6       0.78      0.74      0.76        93
          7       1.00      0.62      0.77        32
          8       0.64      0.48      0.55        96
          9       0.62      0.39      0.47        83
         10       0.50      0.66      0.57       100

avg / total       0.65      0.62      0.62       837

============================================
Running  47  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 08:00:18
forest model fit end:  2018-04-14 08:06:03
forest model predict start:  2018-04-14 08:06:03
forest model predict end:  2018-04-14 08:06:05
accuracy:  0.609318996416   510 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.79      0.78      0.78       100
          2       0.79      0.70      0.74        33
          3       0.50      0.82      0.62       100
          4       0.72      0.55      0.63       100
          5       0.40      0.44      0.42       100
          6       0.77      0.70      0.73        93
          7       1.00      0.62      0.77        32
          8       0.62      0.48      0.54        96
          9       0.60      0.37      0.46        83
         10       0.50      0.66      0.57       100

avg / total       0.64      0.61      0.61       837

============================================
Running  48  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 08:06:05
forest model fit end:  2018-04-14 08:11:47
forest model predict start:  2018-04-14 08:11:47
forest model predict end:  2018-04-14 08:11:49
accuracy:  0.608124253286   509 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.79      0.82      0.80       100
          2       0.81      0.67      0.73        33
          3       0.50      0.82      0.62       100
          4       0.74      0.55      0.63       100
          5       0.37      0.42      0.39       100
          6       0.79      0.71      0.75        93
          7       1.00      0.59      0.75        32
          8       0.60      0.45      0.51        96
          9       0.58      0.37      0.46        83
         10       0.52      0.67      0.59       100

avg / total       0.63      0.61      0.61       837

============================================
Running  49  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 08:11:49
forest model fit end:  2018-04-14 08:17:27
forest model predict start:  2018-04-14 08:17:27
forest model predict end:  2018-04-14 08:17:29
accuracy:  0.612903225806   513 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.78      0.79      0.79       100
          2       0.80      0.73      0.76        33
          3       0.51      0.81      0.63       100
          4       0.73      0.55      0.63       100
          5       0.40      0.45      0.42       100
          6       0.78      0.71      0.74        93
          7       1.00      0.62      0.77        32
          8       0.62      0.46      0.53        96
          9       0.62      0.39      0.47        83
         10       0.51      0.67      0.58       100

avg / total       0.64      0.61      0.61       837

============================================
Running  50  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 08:17:29
forest model fit end:  2018-04-14 08:23:00
forest model predict start:  2018-04-14 08:23:00
forest model predict end:  2018-04-14 08:23:02
accuracy:  0.616487455197   516 / 837
Testing folds:  [ 10.]
Training folds:  [1, 2, 3, 4, 5, 6, 7, 8, 9]
             precision    recall  f1-score   support

          1       0.82      0.81      0.81       100
          2       0.83      0.73      0.77        33
          3       0.50      0.82      0.62       100
          4       0.76      0.54      0.63       100
          5       0.38      0.45      0.41       100
          6       0.80      0.75      0.78        93
          7       1.00      0.62      0.77        32
          8       0.64      0.45      0.53        96
          9       0.58      0.37      0.46        83
         10       0.51      0.66      0.57       100

avg / total       0.65      0.62      0.62       837

============================================
[0.62246117084826758, 0.60573476702508966, 0.61648745519713266, 0.60931899641577059, 0.60931899641577059, 0.61170848267622457, 0.61170848267622457, 0.61529271206690561, 0.59378733572281961, 0.60931899641577059, 0.61051373954599764, 0.60812425328554365, 0.61648745519713266, 0.61170848267622457, 0.61170848267622457, 0.60454002389486261, 0.61051373954599764, 0.59856630824372759, 0.61051373954599764, 0.61529271206690561, 0.59856630824372759, 0.61290322580645162, 0.60334528076463556, 0.62724014336917566, 0.61887694145758665, 0.62007168458781359, 0.61887694145758665, 0.59976105137395463, 0.60931899641577059, 0.59737156511350065, 0.60215053763440862, 0.61170848267622457, 0.6176821983273596, 0.61051373954599764, 0.61529271206690561, 0.6069295101553166, 0.62007168458781359, 0.60931899641577059, 0.61170848267622457, 0.63082437275985659, 0.61051373954599764, 0.60454002389486261, 0.6069295101553166, 0.62126642771804064, 0.62007168458781359, 0.62126642771804064, 0.60931899641577059, 0.60812425328554365, 0.61290322580645162, 0.61648745519713266]
Avg accuracy:  0.611541218638
