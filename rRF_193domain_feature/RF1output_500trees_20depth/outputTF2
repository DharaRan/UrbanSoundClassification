Running  1  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 03:28:26
forest model fit end:  2018-04-14 03:33:27
forest model predict start:  2018-04-14 03:33:27
forest model predict end:  2018-04-14 03:33:29
accuracy:  0.55518018018   493 / 888
Testing folds:  [ 2.]
Training folds:  [1, 3, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.65      0.49      0.56       100
          2       0.67      0.38      0.48        42
          3       0.46      0.77      0.57       100
          4       0.78      0.74      0.76       100
          5       0.67      0.60      0.63       100
          6       0.35      0.60      0.44       100
          7       0.88      0.86      0.87        35
          8       0.53      0.15      0.23       120
          9       0.64      0.49      0.56        91
         10       0.50      0.64      0.56       100

avg / total       0.59      0.56      0.54       888

============================================
Running  2  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 03:33:29
forest model fit end:  2018-04-14 03:38:30
forest model predict start:  2018-04-14 03:38:30
forest model predict end:  2018-04-14 03:38:31
accuracy:  0.543918918919   483 / 888
Testing folds:  [ 2.]
Training folds:  [1, 3, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.55      0.34      0.42       100
          2       0.72      0.43      0.54        42
          3       0.48      0.81      0.60       100
          4       0.79      0.72      0.75       100
          5       0.68      0.61      0.64       100
          6       0.35      0.62      0.45       100
          7       0.91      0.83      0.87        35
          8       0.40      0.14      0.21       120
          9       0.58      0.49      0.54        91
         10       0.52      0.64      0.58       100

avg / total       0.56      0.54      0.53       888

============================================
Running  3  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 03:38:31
forest model fit end:  2018-04-14 03:43:31
forest model predict start:  2018-04-14 03:43:31
forest model predict end:  2018-04-14 03:43:33
accuracy:  0.545045045045   484 / 888
Testing folds:  [ 2.]
Training folds:  [1, 3, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.65      0.37      0.47       100
          2       0.68      0.40      0.51        42
          3       0.46      0.79      0.58       100
          4       0.79      0.74      0.76       100
          5       0.69      0.61      0.65       100
          6       0.35      0.61      0.45       100
          7       0.88      0.80      0.84        35
          8       0.43      0.16      0.23       120
          9       0.57      0.48      0.52        91
         10       0.51      0.64      0.57       100

avg / total       0.57      0.55      0.53       888

============================================
Running  4  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 03:43:33
forest model fit end:  2018-04-14 03:48:34
forest model predict start:  2018-04-14 03:48:34
forest model predict end:  2018-04-14 03:48:35
accuracy:  0.556306306306   494 / 888
Testing folds:  [ 2.]
Training folds:  [1, 3, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.59      0.47      0.52       100
          2       0.67      0.33      0.44        42
          3       0.45      0.77      0.57       100
          4       0.76      0.74      0.75       100
          5       0.67      0.61      0.64       100
          6       0.39      0.59      0.47       100
          7       0.90      0.80      0.85        35
          8       0.54      0.22      0.31       120
          9       0.59      0.48      0.53        91
         10       0.52      0.64      0.58       100

avg / total       0.58      0.56      0.55       888

============================================
Running  5  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 03:48:35
forest model fit end:  2018-04-14 03:53:36
forest model predict start:  2018-04-14 03:53:36
forest model predict end:  2018-04-14 03:53:38
accuracy:  0.548423423423   487 / 888
Testing folds:  [ 2.]
Training folds:  [1, 3, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.58      0.39      0.47       100
          2       0.65      0.31      0.42        42
          3       0.46      0.78      0.58       100
          4       0.79      0.74      0.76       100
          5       0.68      0.60      0.64       100
          6       0.39      0.60      0.47       100
          7       0.88      0.86      0.87        35
          8       0.49      0.20      0.28       120
          9       0.56      0.48      0.52        91
         10       0.50      0.65      0.56       100

avg / total       0.57      0.55      0.54       888

============================================
Running  6  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 03:53:38
forest model fit end:  2018-04-14 03:58:39
forest model predict start:  2018-04-14 03:58:39
forest model predict end:  2018-04-14 03:58:40
accuracy:  0.565315315315   502 / 888
Testing folds:  [ 2.]
Training folds:  [1, 3, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.63      0.47      0.54       100
          2       0.73      0.38      0.50        42
          3       0.46      0.80      0.59       100
          4       0.79      0.72      0.75       100
          5       0.68      0.61      0.64       100
          6       0.38      0.62      0.47       100
          7       0.91      0.83      0.87        35
          8       0.60      0.21      0.31       120
          9       0.58      0.49      0.54        91
         10       0.53      0.65      0.58       100

avg / total       0.60      0.57      0.56       888

============================================
Running  7  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 03:58:41
forest model fit end:  2018-04-14 04:03:43
forest model predict start:  2018-04-14 04:03:43
forest model predict end:  2018-04-14 04:03:45
accuracy:  0.552927927928   491 / 888
Testing folds:  [ 2.]
Training folds:  [1, 3, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.65      0.39      0.49       100
          2       0.65      0.31      0.42        42
          3       0.46      0.79      0.58       100
          4       0.78      0.74      0.76       100
          5       0.68      0.60      0.64       100
          6       0.37      0.64      0.47       100
          7       0.88      0.83      0.85        35
          8       0.48      0.20      0.28       120
          9       0.61      0.49      0.55        91
         10       0.53      0.64      0.58       100

avg / total       0.58      0.55      0.54       888

============================================
Running  8  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 04:03:45
forest model fit end:  2018-04-14 04:08:47
forest model predict start:  2018-04-14 04:08:47
forest model predict end:  2018-04-14 04:08:49
accuracy:  0.54954954955   488 / 888
Testing folds:  [ 2.]
Training folds:  [1, 3, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.61      0.42      0.50       100
          2       0.65      0.31      0.42        42
          3       0.47      0.78      0.58       100
          4       0.79      0.74      0.76       100
          5       0.68      0.61      0.64       100
          6       0.35      0.60      0.44       100
          7       0.91      0.89      0.90        35
          8       0.49      0.14      0.22       120
          9       0.60      0.49      0.54        91
         10       0.50      0.67      0.58       100

avg / total       0.58      0.55      0.54       888

============================================
Running  9  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 04:08:49
forest model fit end:  2018-04-14 04:13:51
forest model predict start:  2018-04-14 04:13:51
forest model predict end:  2018-04-14 04:13:53
accuracy:  0.558558558559   496 / 888
Testing folds:  [ 2.]
Training folds:  [1, 3, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.63      0.46      0.53       100
          2       0.71      0.40      0.52        42
          3       0.47      0.80      0.59       100
          4       0.78      0.73      0.76       100
          5       0.69      0.60      0.64       100
          6       0.38      0.62      0.47       100
          7       0.88      0.80      0.84        35
          8       0.49      0.17      0.26       120
          9       0.61      0.49      0.55        91
         10       0.50      0.64      0.56       100

avg / total       0.59      0.56      0.55       888

============================================
Running  10  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 04:13:53
forest model fit end:  2018-04-14 04:18:55
forest model predict start:  2018-04-14 04:18:55
forest model predict end:  2018-04-14 04:18:57
accuracy:  0.556306306306   494 / 888
Testing folds:  [ 2.]
Training folds:  [1, 3, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.66      0.45      0.54       100
          2       0.64      0.33      0.44        42
          3       0.47      0.82      0.60       100
          4       0.79      0.74      0.76       100
          5       0.68      0.63      0.66       100
          6       0.35      0.58      0.43       100
          7       0.91      0.86      0.88        35
          8       0.51      0.17      0.26       120
          9       0.59      0.48      0.53        91
         10       0.52      0.63      0.57       100

avg / total       0.59      0.56      0.55       888

============================================
Running  11  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 04:18:57
forest model fit end:  2018-04-14 04:24:00
forest model predict start:  2018-04-14 04:24:00
forest model predict end:  2018-04-14 04:24:02
accuracy:  0.551801801802   490 / 888
Testing folds:  [ 2.]
Training folds:  [1, 3, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.60      0.46      0.52       100
          2       0.64      0.33      0.44        42
          3       0.45      0.77      0.57       100
          4       0.78      0.74      0.76       100
          5       0.66      0.60      0.63       100
          6       0.39      0.59      0.47       100
          7       0.90      0.80      0.85        35
          8       0.53      0.19      0.28       120
          9       0.58      0.48      0.53        91
         10       0.50      0.65      0.56       100

avg / total       0.58      0.55      0.54       888

============================================
Running  12  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 04:24:02
forest model fit end:  2018-04-14 04:29:04
forest model predict start:  2018-04-14 04:29:04
forest model predict end:  2018-04-14 04:29:06
accuracy:  0.551801801802   490 / 888
Testing folds:  [ 2.]
Training folds:  [1, 3, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.59      0.45      0.51       100
          2       0.70      0.33      0.45        42
          3       0.46      0.78      0.58       100
          4       0.78      0.73      0.75       100
          5       0.69      0.61      0.65       100
          6       0.38      0.64      0.48       100
          7       0.94      0.83      0.88        35
          8       0.47      0.15      0.23       120
          9       0.56      0.49      0.52        91
         10       0.51      0.63      0.57       100

avg / total       0.58      0.55      0.54       888

============================================
Running  13  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 04:29:06
forest model fit end:  2018-04-14 04:34:09
forest model predict start:  2018-04-14 04:34:09
forest model predict end:  2018-04-14 04:34:10
accuracy:  0.554054054054   492 / 888
Testing folds:  [ 2.]
Training folds:  [1, 3, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.60      0.40      0.48       100
          2       0.70      0.38      0.49        42
          3       0.46      0.81      0.58       100
          4       0.78      0.74      0.76       100
          5       0.68      0.61      0.64       100
          6       0.36      0.59      0.45       100
          7       0.88      0.83      0.85        35
          8       0.51      0.19      0.28       120
          9       0.60      0.49      0.54        91
         10       0.55      0.64      0.59       100

avg / total       0.58      0.55      0.54       888

============================================
Running  14  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 04:34:11
forest model fit end:  2018-04-14 04:39:13
forest model predict start:  2018-04-14 04:39:13
forest model predict end:  2018-04-14 04:39:15
accuracy:  0.54954954955   488 / 888
Testing folds:  [ 2.]
Training folds:  [1, 3, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.59      0.43      0.50       100
          2       0.71      0.40      0.52        42
          3       0.46      0.78      0.58       100
          4       0.77      0.72      0.75       100
          5       0.68      0.63      0.66       100
          6       0.36      0.59      0.45       100
          7       0.88      0.83      0.85        35
          8       0.45      0.16      0.23       120
          9       0.59      0.48      0.53        91
         10       0.52      0.64      0.57       100

avg / total       0.57      0.55      0.54       888

============================================
Running  15  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 04:39:15
forest model fit end:  2018-04-14 04:44:18
forest model predict start:  2018-04-14 04:44:18
forest model predict end:  2018-04-14 04:44:20
accuracy:  0.546171171171   485 / 888
Testing folds:  [ 2.]
Training folds:  [1, 3, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.52      0.32      0.40       100
          2       0.68      0.40      0.51        42
          3       0.47      0.81      0.60       100
          4       0.78      0.73      0.76       100
          5       0.68      0.60      0.64       100
          6       0.35      0.56      0.43       100
          7       0.91      0.86      0.88        35
          8       0.48      0.23      0.31       120
          9       0.61      0.51      0.55        91
         10       0.51      0.63      0.56       100

avg / total       0.57      0.55      0.54       888

============================================
Running  16  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 04:44:20
forest model fit end:  2018-04-14 04:49:22
forest model predict start:  2018-04-14 04:49:22
forest model predict end:  2018-04-14 04:49:24
accuracy:  0.543918918919   483 / 888
Testing folds:  [ 2.]
Training folds:  [1, 3, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.60      0.41      0.49       100
          2       0.68      0.36      0.47        42
          3       0.46      0.79      0.59       100
          4       0.78      0.73      0.75       100
          5       0.67      0.59      0.63       100
          6       0.37      0.60      0.46       100
          7       0.90      0.80      0.85        35
          8       0.38      0.17      0.24       120
          9       0.62      0.49      0.55        91
         10       0.49      0.62      0.55       100

avg / total       0.56      0.54      0.53       888

============================================
Running  17  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 04:49:24
forest model fit end:  2018-04-14 04:54:27
forest model predict start:  2018-04-14 04:54:27
forest model predict end:  2018-04-14 04:54:28
accuracy:  0.541666666667   481 / 888
Testing folds:  [ 2.]
Training folds:  [1, 3, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.55      0.38      0.45       100
          2       0.68      0.36      0.47        42
          3       0.46      0.78      0.58       100
          4       0.77      0.74      0.76       100
          5       0.67      0.61      0.64       100
          6       0.35      0.62      0.45       100
          7       0.93      0.80      0.86        35
          8       0.41      0.13      0.20       120
          9       0.61      0.48      0.54        91
         10       0.54      0.65      0.59       100

avg / total       0.56      0.54      0.53       888

============================================
Running  18  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 04:54:29
forest model fit end:  2018-04-14 04:59:31
forest model predict start:  2018-04-14 04:59:31
forest model predict end:  2018-04-14 04:59:33
accuracy:  0.548423423423   487 / 888
Testing folds:  [ 2.]
Training folds:  [1, 3, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.61      0.43      0.50       100
          2       0.67      0.33      0.44        42
          3       0.45      0.79      0.58       100
          4       0.79      0.74      0.76       100
          5       0.67      0.60      0.63       100
          6       0.37      0.61      0.46       100
          7       0.90      0.80      0.85        35
          8       0.51      0.17      0.26       120
          9       0.57      0.49      0.53        91
         10       0.51      0.62      0.56       100

avg / total       0.58      0.55      0.54       888

============================================
Running  19  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 04:59:33
forest model fit end:  2018-04-14 05:04:35
forest model predict start:  2018-04-14 05:04:35
forest model predict end:  2018-04-14 05:04:36
accuracy:  0.552927927928   491 / 888
Testing folds:  [ 2.]
Training folds:  [1, 3, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.55      0.35      0.43       100
          2       0.71      0.40      0.52        42
          3       0.46      0.81      0.58       100
          4       0.80      0.73      0.76       100
          5       0.68      0.62      0.65       100
          6       0.38      0.63      0.48       100
          7       0.91      0.86      0.88        35
          8       0.48      0.19      0.27       120
          9       0.57      0.49      0.53        91
         10       0.53      0.62      0.57       100

avg / total       0.58      0.55      0.54       888

============================================
Running  20  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 05:04:37
forest model fit end:  2018-04-14 05:09:39
forest model predict start:  2018-04-14 05:09:39
forest model predict end:  2018-04-14 05:09:41
accuracy:  0.556306306306   494 / 888
Testing folds:  [ 2.]
Training folds:  [1, 3, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.63      0.42      0.50       100
          2       0.67      0.38      0.48        42
          3       0.48      0.81      0.60       100
          4       0.79      0.73      0.76       100
          5       0.67      0.61      0.64       100
          6       0.39      0.62      0.48       100
          7       0.90      0.80      0.85        35
          8       0.47      0.21      0.29       120
          9       0.59      0.48      0.53        91
         10       0.50      0.62      0.55       100

avg / total       0.58      0.56      0.55       888

============================================
Running  21  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 05:09:41
forest model fit end:  2018-04-14 05:14:43
forest model predict start:  2018-04-14 05:14:43
forest model predict end:  2018-04-14 05:14:45
accuracy:  0.551801801802   490 / 888
Testing folds:  [ 2.]
Training folds:  [1, 3, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.65      0.48      0.55       100
          2       0.68      0.36      0.47        42
          3       0.47      0.77      0.58       100
          4       0.77      0.72      0.74       100
          5       0.66      0.59      0.62       100
          6       0.39      0.62      0.48       100
          7       0.90      0.77      0.83        35
          8       0.50      0.18      0.27       120
          9       0.56      0.48      0.52        91
         10       0.49      0.64      0.55       100

avg / total       0.58      0.55      0.54       888

============================================
Running  22  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 05:14:45
forest model fit end:  2018-04-14 05:19:47
forest model predict start:  2018-04-14 05:19:47
forest model predict end:  2018-04-14 05:19:49
accuracy:  0.559684684685   497 / 888
Testing folds:  [ 2.]
Training folds:  [1, 3, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.64      0.44      0.52       100
          2       0.67      0.38      0.48        42
          3       0.47      0.80      0.59       100
          4       0.79      0.73      0.76       100
          5       0.67      0.62      0.64       100
          6       0.38      0.63      0.48       100
          7       0.91      0.83      0.87        35
          8       0.55      0.20      0.29       120
          9       0.59      0.49      0.54        91
         10       0.50      0.61      0.55       100

avg / total       0.59      0.56      0.55       888

============================================
Running  23  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 05:19:49
forest model fit end:  2018-04-14 05:24:52
forest model predict start:  2018-04-14 05:24:52
forest model predict end:  2018-04-14 05:24:54
accuracy:  0.546171171171   485 / 888
Testing folds:  [ 2.]
Training folds:  [1, 3, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.60      0.39      0.47       100
          2       0.68      0.40      0.51        42
          3       0.46      0.79      0.58       100
          4       0.78      0.73      0.75       100
          5       0.67      0.61      0.64       100
          6       0.35      0.60      0.44       100
          7       0.94      0.83      0.88        35
          8       0.48      0.17      0.25       120
          9       0.59      0.48      0.53        91
         10       0.52      0.63      0.57       100

avg / total       0.57      0.55      0.54       888

============================================
Running  24  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 05:24:54
forest model fit end:  2018-04-14 05:29:56
forest model predict start:  2018-04-14 05:29:56
forest model predict end:  2018-04-14 05:29:58
accuracy:  0.558558558559   496 / 888
Testing folds:  [ 2.]
Training folds:  [1, 3, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.65      0.45      0.53       100
          2       0.62      0.31      0.41        42
          3       0.46      0.78      0.58       100
          4       0.78      0.73      0.76       100
          5       0.69      0.61      0.65       100
          6       0.37      0.61      0.46       100
          7       0.88      0.86      0.87        35
          8       0.55      0.22      0.31       120
          9       0.59      0.49      0.54        91
         10       0.52      0.64      0.57       100

avg / total       0.59      0.56      0.55       888

============================================
Running  25  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 05:29:58
forest model fit end:  2018-04-14 05:35:01
forest model predict start:  2018-04-14 05:35:01
forest model predict end:  2018-04-14 05:35:03
accuracy:  0.554054054054   492 / 888
Testing folds:  [ 2.]
Training folds:  [1, 3, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.63      0.49      0.55       100
          2       0.68      0.36      0.47        42
          3       0.48      0.80      0.60       100
          4       0.76      0.73      0.74       100
          5       0.67      0.62      0.65       100
          6       0.35      0.60      0.44       100
          7       0.88      0.86      0.87        35
          8       0.53      0.13      0.21       120
          9       0.61      0.49      0.55        91
         10       0.50      0.62      0.56       100

avg / total       0.58      0.55      0.54       888

============================================
Running  26  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 05:35:03
forest model fit end:  2018-04-14 05:40:05
forest model predict start:  2018-04-14 05:40:05
forest model predict end:  2018-04-14 05:40:07
accuracy:  0.54954954955   488 / 888
Testing folds:  [ 2.]
Training folds:  [1, 3, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.62      0.45      0.52       100
          2       0.67      0.38      0.48        42
          3       0.46      0.79      0.58       100
          4       0.80      0.73      0.76       100
          5       0.69      0.59      0.63       100
          6       0.36      0.59      0.45       100
          7       0.89      0.89      0.89        35
          8       0.44      0.16      0.23       120
          9       0.57      0.48      0.52        91
         10       0.50      0.63      0.56       100

avg / total       0.57      0.55      0.54       888

============================================
Running  27  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 05:40:07
forest model fit end:  2018-04-14 05:45:09
forest model predict start:  2018-04-14 05:45:09
forest model predict end:  2018-04-14 05:45:11
accuracy:  0.556306306306   494 / 888
Testing folds:  [ 2.]
Training folds:  [1, 3, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.66      0.47      0.55       100
          2       0.67      0.33      0.44        42
          3       0.46      0.78      0.58       100
          4       0.77      0.73      0.75       100
          5       0.68      0.60      0.64       100
          6       0.37      0.63      0.46       100
          7       0.88      0.80      0.84        35
          8       0.50      0.17      0.26       120
          9       0.61      0.51      0.55        91
         10       0.53      0.64      0.58       100

avg / total       0.59      0.56      0.55       888

============================================
Running  28  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 05:45:11
forest model fit end:  2018-04-14 05:50:14
forest model predict start:  2018-04-14 05:50:14
forest model predict end:  2018-04-14 05:50:16
accuracy:  0.546171171171   485 / 888
Testing folds:  [ 2.]
Training folds:  [1, 3, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.62      0.39      0.48       100
          2       0.67      0.33      0.44        42
          3       0.45      0.80      0.58       100
          4       0.78      0.73      0.75       100
          5       0.67      0.60      0.63       100
          6       0.37      0.60      0.46       100
          7       0.91      0.83      0.87        35
          8       0.51      0.21      0.30       120
          9       0.56      0.48      0.52        91
         10       0.50      0.61      0.55       100

avg / total       0.58      0.55      0.54       888

============================================
Running  29  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 05:50:16
forest model fit end:  2018-04-14 05:55:19
forest model predict start:  2018-04-14 05:55:19
forest model predict end:  2018-04-14 05:55:21
accuracy:  0.547297297297   486 / 888
Testing folds:  [ 2.]
Training folds:  [1, 3, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.66      0.48      0.55       100
          2       0.62      0.36      0.45        42
          3       0.45      0.79      0.57       100
          4       0.80      0.74      0.77       100
          5       0.66      0.59      0.62       100
          6       0.36      0.59      0.45       100
          7       0.93      0.77      0.84        35
          8       0.45      0.16      0.23       120
          9       0.56      0.48      0.52        91
         10       0.51      0.62      0.56       100

avg / total       0.57      0.55      0.54       888

============================================
Running  30  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 05:55:21
forest model fit end:  2018-04-14 06:00:23
forest model predict start:  2018-04-14 06:00:23
forest model predict end:  2018-04-14 06:00:25
accuracy:  0.558558558559   496 / 888
Testing folds:  [ 2.]
Training folds:  [1, 3, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.65      0.51      0.57       100
          2       0.65      0.36      0.46        42
          3       0.47      0.80      0.59       100
          4       0.80      0.74      0.77       100
          5       0.66      0.60      0.63       100
          6       0.37      0.61      0.46       100
          7       0.91      0.86      0.88        35
          8       0.53      0.14      0.22       120
          9       0.60      0.48      0.54        91
         10       0.51      0.64      0.57       100

avg / total       0.59      0.56      0.54       888

============================================
Running  31  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 06:00:25
forest model fit end:  2018-04-14 06:05:27
forest model predict start:  2018-04-14 06:05:27
forest model predict end:  2018-04-14 06:05:28
accuracy:  0.545045045045   484 / 888
Testing folds:  [ 2.]
Training folds:  [1, 3, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.57      0.33      0.42       100
          2       0.64      0.33      0.44        42
          3       0.46      0.78      0.58       100
          4       0.77      0.75      0.76       100
          5       0.68      0.59      0.63       100
          6       0.37      0.61      0.46       100
          7       0.88      0.83      0.85        35
          8       0.48      0.21      0.29       120
          9       0.57      0.49      0.53        91
         10       0.52      0.65      0.58       100

avg / total       0.57      0.55      0.53       888

============================================
Running  32  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 06:05:29
forest model fit end:  2018-04-14 06:10:30
forest model predict start:  2018-04-14 06:10:30
forest model predict end:  2018-04-14 06:10:31
accuracy:  0.552927927928   491 / 888
Testing folds:  [ 2.]
Training folds:  [1, 3, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.67      0.48      0.56       100
          2       0.57      0.29      0.38        42
          3       0.47      0.81      0.59       100
          4       0.77      0.73      0.75       100
          5       0.67      0.61      0.64       100
          6       0.35      0.59      0.44       100
          7       0.91      0.86      0.88        35
          8       0.53      0.16      0.24       120
          9       0.61      0.49      0.55        91
         10       0.51      0.63      0.57       100

avg / total       0.58      0.55      0.54       888

============================================
Running  33  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 06:10:32
forest model fit end:  2018-04-14 06:15:33
forest model predict start:  2018-04-14 06:15:33
forest model predict end:  2018-04-14 06:15:35
accuracy:  0.558558558559   496 / 888
Testing folds:  [ 2.]
Training folds:  [1, 3, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.65      0.43      0.52       100
          2       0.70      0.38      0.49        42
          3       0.46      0.81      0.59       100
          4       0.80      0.74      0.77       100
          5       0.67      0.60      0.63       100
          6       0.37      0.61      0.46       100
          7       0.91      0.86      0.88        35
          8       0.48      0.18      0.27       120
          9       0.61      0.48      0.54        91
         10       0.53      0.65      0.58       100

avg / total       0.59      0.56      0.55       888

============================================
Running  34  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 06:15:35
forest model fit end:  2018-04-14 06:20:38
forest model predict start:  2018-04-14 06:20:38
forest model predict end:  2018-04-14 06:20:40
accuracy:  0.563063063063   500 / 888
Testing folds:  [ 2.]
Training folds:  [1, 3, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.64      0.43      0.51       100
          2       0.69      0.43      0.53        42
          3       0.46      0.80      0.59       100
          4       0.78      0.75      0.77       100
          5       0.69      0.60      0.64       100
          6       0.38      0.62      0.47       100
          7       0.88      0.86      0.87        35
          8       0.49      0.19      0.28       120
          9       0.61      0.49      0.55        91
         10       0.52      0.64      0.58       100

avg / total       0.59      0.56      0.55       888

============================================
Running  35  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 06:20:40
forest model fit end:  2018-04-14 06:25:42
forest model predict start:  2018-04-14 06:25:42
forest model predict end:  2018-04-14 06:25:44
accuracy:  0.564189189189   501 / 888
Testing folds:  [ 2.]
Training folds:  [1, 3, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.67      0.46      0.54       100
          2       0.70      0.38      0.49        42
          3       0.47      0.81      0.59       100
          4       0.77      0.73      0.75       100
          5       0.67      0.62      0.64       100
          6       0.38      0.62      0.47       100
          7       0.94      0.86      0.90        35
          8       0.57      0.20      0.30       120
          9       0.59      0.48      0.53        91
         10       0.52      0.63      0.57       100

avg / total       0.60      0.56      0.55       888

============================================
Running  36  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 06:25:44
forest model fit end:  2018-04-14 06:30:46
forest model predict start:  2018-04-14 06:30:46
forest model predict end:  2018-04-14 06:30:48
accuracy:  0.546171171171   485 / 888
Testing folds:  [ 2.]
Training folds:  [1, 3, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.56      0.35      0.43       100
          2       0.64      0.33      0.44        42
          3       0.47      0.82      0.60       100
          4       0.78      0.72      0.75       100
          5       0.69      0.61      0.65       100
          6       0.36      0.58      0.44       100
          7       0.88      0.86      0.87        35
          8       0.54      0.21      0.30       120
          9       0.54      0.49      0.52        91
         10       0.51      0.63      0.57       100

avg / total       0.57      0.55      0.54       888

============================================
Running  37  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 06:30:48
forest model fit end:  2018-04-14 06:35:50
forest model predict start:  2018-04-14 06:35:50
forest model predict end:  2018-04-14 06:35:52
accuracy:  0.551801801802   490 / 888
Testing folds:  [ 2.]
Training folds:  [1, 3, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.55      0.39      0.46       100
          2       0.71      0.40      0.52        42
          3       0.45      0.77      0.57       100
          4       0.78      0.76      0.77       100
          5       0.69      0.60      0.64       100
          6       0.36      0.59      0.45       100
          7       0.88      0.83      0.85        35
          8       0.53      0.21      0.30       120
          9       0.62      0.48      0.54        91
         10       0.52      0.64      0.57       100

avg / total       0.58      0.55      0.54       888

============================================
Running  38  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 06:35:52
forest model fit end:  2018-04-14 06:40:54
forest model predict start:  2018-04-14 06:40:54
forest model predict end:  2018-04-14 06:40:56
accuracy:  0.543918918919   483 / 888
Testing folds:  [ 2.]
Training folds:  [1, 3, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.58      0.37      0.45       100
          2       0.68      0.36      0.47        42
          3       0.45      0.78      0.57       100
          4       0.77      0.73      0.75       100
          5       0.68      0.60      0.64       100
          6       0.35      0.60      0.44       100
          7       0.88      0.83      0.85        35
          8       0.45      0.18      0.26       120
          9       0.63      0.51      0.56        91
         10       0.52      0.63      0.57       100

avg / total       0.57      0.54      0.53       888

============================================
Running  39  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 06:40:56
forest model fit end:  2018-04-14 06:45:58
forest model predict start:  2018-04-14 06:45:58
forest model predict end:  2018-04-14 06:46:00
accuracy:  0.557432432432   495 / 888
Testing folds:  [ 2.]
Training folds:  [1, 3, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.65      0.48      0.55       100
          2       0.65      0.36      0.46        42
          3       0.46      0.80      0.58       100
          4       0.79      0.73      0.76       100
          5       0.68      0.61      0.64       100
          6       0.37      0.61      0.46       100
          7       0.90      0.80      0.85        35
          8       0.56      0.18      0.28       120
          9       0.57      0.49      0.53        91
         10       0.52      0.62      0.56       100

avg / total       0.59      0.56      0.55       888

============================================
Running  40  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 06:46:00
forest model fit end:  2018-04-14 06:51:04
forest model predict start:  2018-04-14 06:51:04
forest model predict end:  2018-04-14 06:51:05
accuracy:  0.546171171171   485 / 888
Testing folds:  [ 2.]
Training folds:  [1, 3, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.61      0.42      0.50       100
          2       0.67      0.33      0.44        42
          3       0.46      0.78      0.58       100
          4       0.78      0.73      0.75       100
          5       0.66      0.61      0.63       100
          6       0.37      0.61      0.46       100
          7       0.91      0.83      0.87        35
          8       0.51      0.17      0.25       120
          9       0.57      0.48      0.52        91
         10       0.49      0.63      0.55       100

avg / total       0.57      0.55      0.53       888

============================================
Running  41  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 06:51:05
forest model fit end:  2018-04-14 06:56:08
forest model predict start:  2018-04-14 06:56:08
forest model predict end:  2018-04-14 06:56:10
accuracy:  0.540540540541   480 / 888
Testing folds:  [ 2.]
Training folds:  [1, 3, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.55      0.34      0.42       100
          2       0.71      0.40      0.52        42
          3       0.45      0.79      0.58       100
          4       0.80      0.72      0.76       100
          5       0.66      0.61      0.64       100
          6       0.36      0.59      0.45       100
          7       0.87      0.77      0.82        35
          8       0.46      0.21      0.29       120
          9       0.58      0.49      0.54        91
         10       0.51      0.61      0.56       100

avg / total       0.57      0.54      0.53       888

============================================
Running  42  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 06:56:10
forest model fit end:  2018-04-14 07:01:13
forest model predict start:  2018-04-14 07:01:13
forest model predict end:  2018-04-14 07:01:14
accuracy:  0.567567567568   504 / 888
Testing folds:  [ 2.]
Training folds:  [1, 3, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.66      0.50      0.57       100
          2       0.70      0.38      0.49        42
          3       0.46      0.77      0.58       100
          4       0.77      0.74      0.76       100
          5       0.66      0.59      0.62       100
          6       0.40      0.62      0.48       100
          7       0.93      0.77      0.84        35
          8       0.57      0.25      0.35       120
          9       0.62      0.49      0.55        91
         10       0.51      0.64      0.57       100

avg / total       0.60      0.57      0.56       888

============================================
Running  43  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 07:01:15
forest model fit end:  2018-04-14 07:06:17
forest model predict start:  2018-04-14 07:06:17
forest model predict end:  2018-04-14 07:06:18
accuracy:  0.557432432432   495 / 888
Testing folds:  [ 2.]
Training folds:  [1, 3, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.59      0.45      0.51       100
          2       0.70      0.38      0.49        42
          3       0.47      0.78      0.58       100
          4       0.80      0.74      0.77       100
          5       0.68      0.61      0.64       100
          6       0.38      0.59      0.46       100
          7       0.88      0.83      0.85        35
          8       0.48      0.18      0.27       120
          9       0.58      0.49      0.54        91
         10       0.52      0.66      0.58       100

avg / total       0.58      0.56      0.55       888

============================================
Running  44  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 07:06:18
forest model fit end:  2018-04-14 07:11:21
forest model predict start:  2018-04-14 07:11:21
forest model predict end:  2018-04-14 07:11:23
accuracy:  0.557432432432   495 / 888
Testing folds:  [ 2.]
Training folds:  [1, 3, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.62      0.43      0.51       100
          2       0.65      0.31      0.42        42
          3       0.45      0.79      0.58       100
          4       0.78      0.74      0.76       100
          5       0.68      0.61      0.64       100
          6       0.39      0.61      0.48       100
          7       0.88      0.80      0.84        35
          8       0.55      0.22      0.31       120
          9       0.57      0.48      0.52        91
         10       0.52      0.66      0.58       100

avg / total       0.59      0.56      0.55       888

============================================
Running  45  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 07:11:23
forest model fit end:  2018-04-14 07:16:24
forest model predict start:  2018-04-14 07:16:24
forest model predict end:  2018-04-14 07:16:26
accuracy:  0.557432432432   495 / 888
Testing folds:  [ 2.]
Training folds:  [1, 3, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.61      0.44      0.51       100
          2       0.68      0.36      0.47        42
          3       0.46      0.79      0.58       100
          4       0.78      0.73      0.75       100
          5       0.66      0.59      0.62       100
          6       0.40      0.61      0.48       100
          7       0.93      0.77      0.84        35
          8       0.55      0.24      0.34       120
          9       0.58      0.48      0.53        91
         10       0.50      0.64      0.56       100

avg / total       0.59      0.56      0.55       888

============================================
Running  46  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 07:16:26
forest model fit end:  2018-04-14 07:21:29
forest model predict start:  2018-04-14 07:21:29
forest model predict end:  2018-04-14 07:21:31
accuracy:  0.554054054054   492 / 888
Testing folds:  [ 2.]
Training folds:  [1, 3, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.64      0.42      0.51       100
          2       0.65      0.31      0.42        42
          3       0.45      0.79      0.57       100
          4       0.79      0.74      0.76       100
          5       0.68      0.61      0.64       100
          6       0.36      0.64      0.46       100
          7       0.91      0.86      0.88        35
          8       0.54      0.17      0.26       120
          9       0.62      0.48      0.54        91
         10       0.52      0.64      0.57       100

avg / total       0.59      0.55      0.54       888

============================================
Running  47  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 07:21:31
forest model fit end:  2018-04-14 07:26:34
forest model predict start:  2018-04-14 07:26:34
forest model predict end:  2018-04-14 07:26:35
accuracy:  0.548423423423   487 / 888
Testing folds:  [ 2.]
Training folds:  [1, 3, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.59      0.41      0.49       100
          2       0.67      0.33      0.44        42
          3       0.46      0.79      0.58       100
          4       0.78      0.73      0.75       100
          5       0.68      0.61      0.64       100
          6       0.37      0.64      0.47       100
          7       0.97      0.86      0.91        35
          8       0.45      0.15      0.23       120
          9       0.56      0.48      0.52        91
         10       0.53      0.63      0.57       100

avg / total       0.57      0.55      0.53       888

============================================
Running  48  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 07:26:35
forest model fit end:  2018-04-14 07:31:38
forest model predict start:  2018-04-14 07:31:38
forest model predict end:  2018-04-14 07:31:40
accuracy:  0.559684684685   497 / 888
Testing folds:  [ 2.]
Training folds:  [1, 3, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.61      0.45      0.52       100
          2       0.73      0.38      0.50        42
          3       0.47      0.79      0.59       100
          4       0.79      0.74      0.76       100
          5       0.67      0.61      0.64       100
          6       0.36      0.59      0.44       100
          7       0.88      0.80      0.84        35
          8       0.56      0.21      0.30       120
          9       0.60      0.48      0.54        91
         10       0.53      0.66      0.59       100

avg / total       0.59      0.56      0.55       888

============================================
Running  49  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 07:31:40
forest model fit end:  2018-04-14 07:36:41
forest model predict start:  2018-04-14 07:36:41
forest model predict end:  2018-04-14 07:36:43
accuracy:  0.556306306306   494 / 888
Testing folds:  [ 2.]
Training folds:  [1, 3, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.65      0.42      0.51       100
          2       0.67      0.38      0.48        42
          3       0.47      0.81      0.60       100
          4       0.78      0.74      0.76       100
          5       0.67      0.60      0.63       100
          6       0.38      0.64      0.48       100
          7       0.91      0.83      0.87        35
          8       0.39      0.17      0.23       120
          9       0.62      0.48      0.54        91
         10       0.52      0.64      0.58       100

avg / total       0.58      0.56      0.54       888

============================================
Running  50  iteration.
============================================
Parameters: n_estimator =  500 , max_depth =  20 , min_samples_leaf =  30
forest model fit start:  2018-04-14 07:36:43
forest model fit end:  2018-04-14 07:41:45
forest model predict start:  2018-04-14 07:41:45
forest model predict end:  2018-04-14 07:41:46
accuracy:  0.546171171171   485 / 888
Testing folds:  [ 2.]
Training folds:  [1, 3, 4, 5, 6, 7, 8, 9, 10]
             precision    recall  f1-score   support

          1       0.57      0.39      0.46       100
          2       0.73      0.38      0.50        42
          3       0.45      0.78      0.57       100
          4       0.77      0.74      0.76       100
          5       0.66      0.61      0.64       100
          6       0.38      0.63      0.47       100
          7       0.90      0.77      0.83        35
          8       0.45      0.17      0.24       120
          9       0.61      0.49      0.55        91
         10       0.51      0.62      0.56       100

avg / total       0.57      0.55      0.53       888

============================================
[0.55518018018018023, 0.54391891891891897, 0.54504504504504503, 0.55630630630630629, 0.54842342342342343, 0.56531531531531531, 0.55292792792792789, 0.5495495495495496, 0.55855855855855852, 0.55630630630630629, 0.55180180180180183, 0.55180180180180183, 0.55405405405405406, 0.5495495495495496, 0.5461711711711712, 0.54391891891891897, 0.54166666666666663, 0.54842342342342343, 0.55292792792792789, 0.55630630630630629, 0.55180180180180183, 0.55968468468468469, 0.5461711711711712, 0.55855855855855852, 0.55405405405405406, 0.5495495495495496, 0.55630630630630629, 0.5461711711711712, 0.54729729729729726, 0.55855855855855852, 0.54504504504504503, 0.55292792792792789, 0.55855855855855852, 0.56306306306306309, 0.56418918918918914, 0.5461711711711712, 0.55180180180180183, 0.54391891891891897, 0.55743243243243246, 0.5461711711711712, 0.54054054054054057, 0.56756756756756754, 0.55743243243243246, 0.55743243243243246, 0.55743243243243246, 0.55405405405405406, 0.54842342342342343, 0.55968468468468469, 0.55630630630630629, 0.5461711711711712]
Avg accuracy:  0.552612612613
